# Nginx reverse proxy configuration for LlamaIndex API

events {
    worker_connections 1024;
}

http {
    # Basic settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 100M;  # Allow large file uploads

    # Logging
    access_log /var/log/nginx/access.log;
    error_log /var/log/nginx/error.log;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript
               application/json application/javascript application/xml+rss;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=60r/m;
    limit_req_status 429;

    # Upstream backend
    upstream llamaindex_backend {
        server app:8000;
        # Add more servers for load balancing:
        # server app2:8000;
        # server app3:8000;
        keepalive 32;
    }

    # HTTP server (redirect to HTTPS in production)
    server {
        listen 80;
        server_name _;

        # For Let's Encrypt verification
        location /.well-known/acme-challenge/ {
            root /var/www/certbot;
        }

        # Redirect to HTTPS (uncomment in production)
        # location / {
        #     return 301 https://$host$request_uri;
        # }

        # Or proxy directly (for development)
        location / {
            proxy_pass http://llamaindex_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Timeouts
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 300s;  # Long timeout for LLM responses

            # WebSocket support (for streaming)
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";

            # Buffering settings for streaming
            proxy_buffering off;
            proxy_cache off;

            # Rate limiting
            limit_req zone=api_limit burst=10 nodelay;
        }

        # Health check endpoint (no rate limiting)
        location /health {
            proxy_pass http://llamaindex_backend;
            proxy_set_header Host $host;
            access_log off;
        }
    }

    # HTTPS server (for production)
    # Uncomment and configure after obtaining SSL certificates
    # server {
    #     listen 443 ssl http2;
    #     server_name yourdomain.com;
    #
    #     # SSL certificates (use Let's Encrypt)
    #     ssl_certificate /etc/nginx/ssl/fullchain.pem;
    #     ssl_certificate_key /etc/nginx/ssl/privkey.pem;
    #
    #     # SSL settings
    #     ssl_protocols TLSv1.2 TLSv1.3;
    #     ssl_ciphers HIGH:!aNULL:!MD5;
    #     ssl_prefer_server_ciphers on;
    #     ssl_session_cache shared:SSL:10m;
    #     ssl_session_timeout 10m;
    #
    #     # Security headers
    #     add_header Strict-Transport-Security "max-age=31536000" always;
    #     add_header X-Frame-Options "SAMEORIGIN" always;
    #     add_header X-Content-Type-Options "nosniff" always;
    #     add_header X-XSS-Protection "1; mode=block" always;
    #
    #     location / {
    #         proxy_pass http://llamaindex_backend;
    #         proxy_set_header Host $host;
    #         proxy_set_header X-Real-IP $remote_addr;
    #         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    #         proxy_set_header X-Forwarded-Proto https;
    #
    #         # Timeouts
    #         proxy_connect_timeout 60s;
    #         proxy_send_timeout 60s;
    #         proxy_read_timeout 300s;
    #
    #         # WebSocket support
    #         proxy_http_version 1.1;
    #         proxy_set_header Upgrade $http_upgrade;
    #         proxy_set_header Connection "upgrade";
    #
    #         # Streaming support
    #         proxy_buffering off;
    #         proxy_cache off;
    #
    #         # Rate limiting
    #         limit_req zone=api_limit burst=10 nodelay;
    #     }
    #
    #     location /health {
    #         proxy_pass http://llamaindex_backend;
    #         proxy_set_header Host $host;
    #         access_log off;
    #     }
    # }
}
