{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d48493a3",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/finetuning/router/router_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a6540-3f1b-46bb-b99a-cd0635b241e0",
   "metadata": {},
   "source": [
    "# Router Fine-tuning\n",
    "\n",
    "In this notebook, we experiment with fine-tuning an LLM-powered router. We try a few different approaches, with query + ground-truth \"choice\" as the training signal.\n",
    "\n",
    "1. Fine-tuning embeddings\n",
    "2. Fine-tuning a cross-encoder\n",
    "\n",
    "Our dataset will be Wikipedia articles of different cities. \n",
    "\n",
    "We will generate a synthetic dataset for each approach to fine-tune over. We will also run some basic evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ee0c1-513c-4091-a8e3-b0753b1777f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c8950cd",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32229516-bfc4-4e4a-a12e-d64cf1e23983",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbfc0d2-7491-4478-87c5-28325117bbb5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1799cd0a-3b7d-4bb2-9984-89d0381e5e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = [\n",
    "    \"Toronto\",\n",
    "    \"Seattle\",\n",
    "    \"Chicago\",\n",
    "    \"Boston\",\n",
    "    \"Houston\",\n",
    "    \"Tokyo\",\n",
    "    \"Berlin\",\n",
    "    \"Lisbon\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e23d3e-de38-476d-a753-3c3c2a2fc8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "for title in wiki_titles:\n",
    "    response = requests.get(\n",
    "        \"https://en.wikipedia.org/w/api.php\",\n",
    "        params={\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"titles\": title,\n",
    "            \"prop\": \"extracts\",\n",
    "            # 'exintro': True,\n",
    "            \"explaintext\": True,\n",
    "        },\n",
    "    ).json()\n",
    "    page = next(iter(response[\"query\"][\"pages\"].values()))\n",
    "    wiki_text = page[\"extract\"]\n",
    "\n",
    "    data_path = Path(\"data\")\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path / f\"{title}.txt\", \"w\") as fp:\n",
    "        fp.write(wiki_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8739b-eba0-47d3-9d2f-56218776be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "# Load all wiki documents\n",
    "city_docs = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    city_docs[wiki_title] = SimpleDirectoryReader(\n",
    "        input_files=[f\"data/{wiki_title}.txt\"]\n",
    "    ).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c78ce-7f34-41ba-8b85-f9169a8f5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "gpt_35_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f1e72-1418-44ea-9b1a-fcf3dc0baa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define descriptions/choices for tools\n",
    "city_descs_dict = {}\n",
    "# these choices will be passed to the router selector\n",
    "choices = []\n",
    "choice_to_id_dict = {}\n",
    "\n",
    "for idx, wiki_title in enumerate(wiki_titles):\n",
    "    vector_desc = (\n",
    "        \"Useful for questions related to specific aspects of\"\n",
    "        f\" {wiki_title} (e.g. the history, arts and culture,\"\n",
    "        \" sports, demographics, or more).\"\n",
    "    )\n",
    "    summary_desc = (\n",
    "        \"Useful for any requests that require a holistic summary\"\n",
    "        f\" of EVERYTHING about {wiki_title}. For questions about\"\n",
    "        \" more specific sections, please use the vector_tool.\"\n",
    "    )\n",
    "    doc_id_vector = f\"{wiki_title}_vector\"\n",
    "    doc_id_summary = f\"{wiki_title}_summary\"\n",
    "    city_descs_dict[doc_id_vector] = vector_desc\n",
    "    city_descs_dict[doc_id_summary] = summary_desc\n",
    "\n",
    "    choices.extend([vector_desc, summary_desc])\n",
    "    choice_to_id_dict[idx * 2] = f\"{wiki_title}_vector\"\n",
    "    choice_to_id_dict[idx * 2 + 1] = f\"{wiki_title}_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048f001-835a-4380-b600-5fa12b17a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "summary_q_tmpl = \"\"\"\\\n",
    "You are a summary question generator. Given an existing question which asks for a summary of a given topic, \\\n",
    "generate {num_vary} related queries that also ask for a summary of the topic.\n",
    "\n",
    "For example, assuming we're generating 3 related questions:\n",
    "Base Question: Can you tell me more about Boston?\n",
    "Question Variations:\n",
    "Give me an overview of Boston as a city.\n",
    "Can you describe different aspects of Boston, from the history to the sports scene to the food?\n",
    "Write a concise summary of Boston; I've never been.\n",
    "\n",
    "Now let's give it a shot! \n",
    "\n",
    "Base Question: {base_question}\n",
    "Question Variations:\n",
    "\"\"\"\n",
    "summary_q_prompt = PromptTemplate(summary_q_tmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f216e-1744-443f-ad03-f029579a5b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from llama_index.evaluation import DatasetGenerator\n",
    "from llama_index.finetuning import EmbeddingQAFinetuneDataset\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_dataset(\n",
    "    wiki_titles,\n",
    "    city_descs_dict,\n",
    "    llm,\n",
    "    summary_q_prompt,\n",
    "    num_vector_qs_per_node=2,\n",
    "    num_summary_qs=4,\n",
    "):\n",
    "    # generate dataset from each wikipedia page\n",
    "    queries = {}\n",
    "    corpus = {}\n",
    "    relevant_docs = defaultdict(list)\n",
    "    for idx, wiki_title in enumerate(tqdm(wiki_titles)):\n",
    "        doc_id_vector = f\"{wiki_title}_vector\"\n",
    "        doc_id_summary = f\"{wiki_title}_summary\"\n",
    "        corpus[doc_id_vector] = city_descs_dict[doc_id_vector]\n",
    "        corpus[doc_id_summary] = city_descs_dict[doc_id_summary]\n",
    "\n",
    "        # generate questions for semantic search\n",
    "        node_parser = SimpleNodeParser.from_defaults()\n",
    "        nodes = node_parser.get_nodes_from_documents(city_docs[wiki_title])\n",
    "\n",
    "        dataset_generator = DatasetGenerator(\n",
    "            nodes,\n",
    "            service_context=gpt_35_context,\n",
    "            num_questions_per_chunk=num_vector_qs_per_node,\n",
    "        )\n",
    "        doc_questions = dataset_generator.generate_questions_from_nodes(\n",
    "            num=len(nodes) * num_vector_qs_per_node\n",
    "        )\n",
    "        for query_idx, doc_question in enumerate(doc_questions):\n",
    "            query_id = f\"{wiki_title}_{query_idx}\"\n",
    "            relevant_docs[query_id] = [doc_id_vector]\n",
    "            queries[query_id] = doc_question\n",
    "\n",
    "        # generate questions for summarization\n",
    "        base_q = f\"Give me a summary of {wiki_title}\"\n",
    "        fmt_prompt = summary_q_prompt.format(\n",
    "            num_vary=num_summary_qs,\n",
    "            base_question=base_q,\n",
    "        )\n",
    "        raw_response = llm.complete(fmt_prompt)\n",
    "        raw_lines = str(raw_response).split(\"\\n\")\n",
    "        doc_summary_questions = [l for l in raw_lines if l != \"\"]\n",
    "        print(f\"[{idx}] Original Question: {base_q}\")\n",
    "        print(\n",
    "            f\"[{idx}] Generated Question Variations: {doc_summary_questions}\"\n",
    "        )\n",
    "        for query_idx, doc_summary_question in enumerate(\n",
    "            doc_summary_questions\n",
    "        ):\n",
    "            query_id = f\"{wiki_title}_{query_idx}\"\n",
    "            relevant_docs[query_id] = [doc_id_summary]\n",
    "            queries[query_id] = doc_summary_question\n",
    "\n",
    "    return EmbeddingQAFinetuneDataset(\n",
    "        queries=queries, corpus=corpus, relevant_docs=relevant_docs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fee20-c404-4028-ab66-136598d08221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_dataset(\n",
    "    wiki_titles,\n",
    "    city_descs_dict,\n",
    "    llm,\n",
    "    summary_q_prompt,\n",
    "    num_vector_qs_per_node=4,\n",
    "    num_summary_qs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a366ab-a144-4eed-bb50-fa0ad80f0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207c777-03e0-4eaf-80ad-e789f5fe74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] save\n",
    "dataset.save_json(\"dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc65028-92fc-40ff-8843-dfd23e736d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] load\n",
    "dataset = EmbeddingQAFinetuneDataset.from_json(\"dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d25a42-5531-41cd-bff2-d5c04ef41c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def split_train_val_by_query(dataset, split=0.7):\n",
    "    \"\"\"Split dataset by queries.\"\"\"\n",
    "    query_ids = list(dataset.queries.keys())\n",
    "    query_ids_shuffled = random.sample(query_ids, len(query_ids))\n",
    "    split_idx = int(len(query_ids) * split)\n",
    "    train_query_ids = query_ids_shuffled[:split_idx]\n",
    "    eval_query_ids = query_ids_shuffled[split_idx:]\n",
    "\n",
    "    train_queries = {qid: dataset.queries[qid] for qid in train_query_ids}\n",
    "    eval_queries = {qid: dataset.queries[qid] for qid in eval_query_ids}\n",
    "\n",
    "    train_rel_docs = {\n",
    "        qid: dataset.relevant_docs[qid] for qid in train_query_ids\n",
    "    }\n",
    "    eval_rel_docs = {qid: dataset.relevant_docs[qid] for qid in eval_query_ids}\n",
    "\n",
    "    train_dataset = EmbeddingQAFinetuneDataset(\n",
    "        queries=train_queries,\n",
    "        corpus=dataset.corpus,\n",
    "        relevant_docs=train_rel_docs,\n",
    "    )\n",
    "    eval_dataset = EmbeddingQAFinetuneDataset(\n",
    "        queries=eval_queries,\n",
    "        corpus=dataset.corpus,\n",
    "        relevant_docs=eval_rel_docs,\n",
    "    )\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bae267-9158-4663-9b23-49e7867161de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = split_train_val_by_query(dataset, split=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7aed0-bfc8-479f-8675-360a5ce27217",
   "metadata": {},
   "source": [
    "## Fine-tuning Embeddings\n",
    "\n",
    "In this section we try to fine-tune embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fde3a-ba3e-4380-9bbb-8a31e8a15bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings dataset\n",
    "from llama_index.finetuning import SentenceTransformersFinetuneEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248ead6-a7c3-459f-9277-921d8baedc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = SentenceTransformersFinetuneEngine(\n",
    "    train_dataset,\n",
    "    model_id=\"BAAI/bge-small-en\",\n",
    "    model_output_path=\"test_model3\",\n",
    "    val_dataset=eval_dataset,\n",
    "    epochs=30,  # can set to higher (haven't tested)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00493f-0485-4eb3-8223-e96c1f3a72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0889f9-4149-43c1-aacd-7073df52f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_embed_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bd7b2-d375-42c0-bcd1-323c3543d177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbedding(model_name='test_model3', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x2f5ccd210>, tokenizer_name='test_model3', max_length=512, pooling='cls', normalize='True', query_instruction=None, text_instruction=None, cache_folder=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3905e099-f8b0-4c54-9a8e-70d579924d7a",
   "metadata": {},
   "source": [
    "## Run Evaluations\n",
    "\n",
    "In this section we evaluate the quality of our fine-tuned embedding model vs. our base model in selecting the right choice.\n",
    "\n",
    "We plug both into our `EmbeddingSelector` abstraction.\n",
    "\n",
    "We also compare against a base `LLMSingleSelector` using GPT-4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d7d3b9-20a4-4e58-a8c5-3cdf74b2e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline embedding model\n",
    "from llama_index.embeddings import resolve_embed_model\n",
    "\n",
    "base_embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27da61-b87f-47ab-b4b8-55f55c39924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.selectors import EmbeddingSingleSelector, LLMSingleSelector\n",
    "\n",
    "ft_selector = EmbeddingSingleSelector.from_defaults(embed_model=ft_embed_model)\n",
    "base_selector = EmbeddingSingleSelector.from_defaults(\n",
    "    embed_model=base_embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0e37a-569b-43ac-9ee2-bfdafad66545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def run_evals(eval_dataset, selector, choices, choice_to_id_dict):\n",
    "    # we just measure accuracy\n",
    "    eval_pairs = eval_dataset.query_docid_pairs\n",
    "    matches = []\n",
    "    for query, relevant_doc_ids in tqdm(eval_pairs):\n",
    "        result = selector.select(choices, query)\n",
    "        # assume single selection for now\n",
    "        pred_doc_id = choice_to_id_dict[result.inds[0]]\n",
    "        gt_doc_id = relevant_doc_ids[0]\n",
    "        matches.append(gt_doc_id == pred_doc_id)\n",
    "    return np.array(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea6ffd-6b6f-4384-9198-8091bf3a6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_matches = run_evals(eval_dataset, ft_selector, choices, choice_to_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103fdb3-1add-407f-8c25-6a0f12dbf824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994413407821229"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ft_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063f926-80e9-4f38-a12a-9953f92d94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_matches = run_evals(\n",
    "    eval_dataset, base_selector, choices, choice_to_id_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129580ff-cfdd-43ee-a5dc-51dc84fae5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12849162011173185"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(base_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a481d-5baf-43bf-b0ba-912fc50611ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also try LLM\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "eval_llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "llm_selector = LLMSingleSelector.from_defaults(\n",
    "    service_context=ServiceContext.from_defaults(llm=eval_llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff25225-c1a7-4b68-aa1f-300892a7c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_matches = run_evals(eval_dataset, llm_selector, choices, choice_to_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26191c3a-4ceb-4476-8e84-11830cabff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.659217877094972"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(llm_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fd9aa-c856-47ef-a6cd-bb65b549e86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base embedding model</th>\n",
       "      <th>GPT-3.5</th>\n",
       "      <th>Fine-tuned embedding model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Match Rate</th>\n",
       "      <td>0.128492</td>\n",
       "      <td>0.659218</td>\n",
       "      <td>0.994413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Base embedding model   GPT-3.5  Fine-tuned embedding model\n",
       "Match Rate              0.128492  0.659218                    0.994413"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Base embedding model\": np.mean(base_matches),\n",
    "        \"GPT-3.5\": np.mean(llm_matches),\n",
    "        \"Fine-tuned embedding model\": np.mean(ft_matches),\n",
    "    },\n",
    "    index=[\"Match Rate\"],\n",
    ")\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f3492-0aad-4b15-947a-34da1289f0a8",
   "metadata": {},
   "source": [
    "## Plug into Router\n",
    "\n",
    "We plug this into our `RouterQueryEngine` as an `EmbeddingSelector` (by default, an `LLMSingleSelector` is used in our router query engine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f877aa0-7c3a-40f6-af0a-b0c2a29bf69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009592771530151367,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 36,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 8,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84030529e251412db444c746c9402fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.query_engine import RouterQueryEngine\n",
    "from llama_index import SummaryIndex, VectorStoreIndex\n",
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "\n",
    "# define indexes/tools for wikipedia entries\n",
    "tools = []\n",
    "for idx, wiki_title in enumerate(tqdm(wiki_titles)):\n",
    "    doc_id_vector = f\"{wiki_title}_vector\"\n",
    "    doc_id_summary = f\"{wiki_title}_summary\"\n",
    "\n",
    "    vector_index = VectorStoreIndex.from_documents(city_docs[wiki_title])\n",
    "    summary_index = SummaryIndex.from_documents(city_docs[wiki_title])\n",
    "    vector_tool = QueryEngineTool.from_defaults(\n",
    "        query_engine=vector_index.as_query_engine(),\n",
    "        description=city_descs_dict[doc_id_vector],\n",
    "    )\n",
    "    summary_tool = QueryEngineTool.from_defaults(\n",
    "        query_engine=summary_index.as_query_engine(),\n",
    "        description=city_descs_dict[doc_id_summary],\n",
    "    )\n",
    "    tools.extend([vector_tool, summary_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349ff2c-2dfb-4382-86f5-51efe806e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_query_engine = RouterQueryEngine.from_defaults(\n",
    "    selector=ft_selector.from_defaults(), query_engine_tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8552d-84be-45d6-884b-dec3d560eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = router_query_engine.query(\n",
    "    \"Tell me more about the sports teams in Toronto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2021e0-bbf6-4757-ad51-9948b89c533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto is home to several professional sports teams. In hockey, there is the Toronto Maple Leafs, one of the NHL's Original Six clubs, and the Toronto Marlies of the American Hockey League. The city also has a rich history of hockey championships, with the Maple Leafs winning 13 Stanley Cup titles and the Toronto Marlboros and St. Michael's College School-based Ontario Hockey League teams winning a combined 12 Memorial Cup titles.\n",
      "\n",
      "In baseball, Toronto is represented by the Toronto Blue Jays, who have won two World Series titles. The Blue Jays play their home games at the Rogers Centre. \n",
      "\n",
      "In basketball, there is the Toronto Raptors, who entered the NBA in 1995 and have achieved success in recent years, including winning their first NBA title in 2019. The Raptors play their home games at Scotiabank Arena.\n",
      "\n",
      "In Canadian football, there is the Toronto Argonauts, which was founded in 1873 and has won 18 Grey Cup Canadian championship titles. The Argonauts play their home games at BMO Field.\n",
      "\n",
      "In soccer, there is the Toronto FC, who have won seven Canadian Championship titles and the MLS Cup in 2017. They share BMO Field with the Toronto Argonauts.\n",
      "\n",
      "Other sports teams in Toronto include the Toronto Rock in the National Lacrosse League, the Toronto Wolfpack in rugby league, the Toronto Rush in ultimate disc, and the Toronto Six in the National Women's Hockey League.\n",
      "\n",
      "Toronto has also hosted various sporting events, such as the Canadian Open tennis tournament, the Toronto Waterfront Marathon, the Grand Prix of Toronto car race, and the Pan American Games in 2015. Additionally, Toronto was named as one of the host cities for the 2026 FIFA World Cup.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bdbc8-03e4-4626-ac7c-e229b24d0618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"=== Professional sports ===\\nToronto is home to the Toronto Maple Leafs, one of the NHL's Original Six clubs, and has also served as home to the Hockey Hall of Fame since 1958. The city had a rich history of hockey championships. Along with the Maple Leafs' 13 Stanley Cup titles, the Toronto Marlboros and St. Michael's College School-based Ontario Hockey League teams, combined, have won a record 12 Memorial Cup titles. The Toronto Marlies of the American Hockey League also play in Toronto at Coca-Cola Coliseum and are the farm team for the Maple Leafs. The Toronto Six, the first Canadian franchise in the National Women's Hockey League, began play with the 2020â€“21 season.\\nThe city is home to the Toronto Blue Jays MLB baseball team. The team has won two World Series titles (1992, 1993). The Blue Jays play their home games at the Rogers Centre in the downtown core. Toronto has a long history of minor-league professional baseball dating back to the 1800s, culminating in the Toronto Maple Leafs baseball team, whose owner first proposed an MLB team for Toronto.The Toronto Raptors basketball team entered the NBA in 1995, and have since earned eleven playoff spots and five Atlantic Division titles in 24 seasons. They won their first NBA title in 2019. The Raptors are the only NBA team with their own television channel, NBA TV Canada. They play their home games at Scotiabank Arena, which is shared with the Maple Leafs. In 2016, Toronto hosted the 65th NBA All-Star game, the first to be held outside the United States.\\nThe city is represented in Canadian football by the CFL's Toronto Argonauts, which was founded in 1873. The club has won 18 Grey Cup Canadian championship titles. The club's home games are played at BMO Field.\\n\\nToronto is represented in soccer by the Toronto FC MLS team, who have won seven Canadian Championship titles, as well as the MLS Cup in 2017 and the Supporters' Shield for best regular season record, also in 2017. They share BMO Field with the Toronto Argonauts. Toronto has a high level of participation in soccer across the city at several smaller stadiums and fields. Toronto FC had entered the league as an expansion team in 2007.The Toronto Rock is the city's National Lacrosse League team. They won five National Lacrosse League Cup titles in seven years in the late 1990s and the first decade of the 21st century, appearing in an NLL-record five straight championship games from 1999 to 2003, and are first all-time in the number of Champion's Cups won. The Rock formerly shared the Scotiabank Arena with the Maple Leafs and the Raptors, However, the Toronto Rock moved to the nearby city of Hamilton while retaining its Toronto name.\\nThe Toronto Wolfpack became Canada's first professional rugby league team and the world's first transatlantic professional sports team when they began play in the Rugby Football League's League One competition in 2017. Due to COVID-19 restrictions on international travel the team withdrew from the Super League in 2020 with its future uncertain. The rugby club's ownership changed in 2021, now 'Team Wolfpack' will play in the newly formed North American Rugby League tournament.Toronto is home to the Toronto Rush, a semi-professional ultimate team that competes in the American Ultimate Disc League (AUDL). Ultimate (disc), in Canada, has its beginning roots in Toronto, with 3300 players competing annually in the Toronto Ultimate Club (League).Toronto has hosted several National Football League (NFL) exhibition games at the Rogers Centre. Ted Rogers leased the Buffalo Bills from Ralph Wilson for the purposes of having the Bills play eight home games in the city between 2008 and 2013.\\n\\n\\n=== Collegiate sports ===\\nThe University of Toronto in downtown Toronto was where the first recorded college football game was held in November 1861. Many post-secondary institutions in Toronto are members of U Sports or the Canadian Collegiate Athletic Association, the former for universities and the latter for colleges.\\nToronto was home to the International Bowl, an NCAA sanctioned post-season college football game that pitted a Mid-American Conference team against a Big East Conference team. From 2007 to 2010, the game was played at Rogers Centre annually in January.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes[0].get_content()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
