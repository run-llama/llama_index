{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d8b66c",
   "metadata": {},
   "source": [
    "# WandbCallbackHandler Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77c13b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "612f35ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/Users/ayushthakur/integrations/llamaindex/apis.env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78a29d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.callbacks import CallbackManager, CBEventType\n",
    "from llama_index.callbacks import LlamaDebugHandler, WandbCallbackHandler\n",
    "from llama_index import (\n",
    "    GPTListIndex, GPTTreeIndex, GPTVectorStoreIndex,\n",
    "    ServiceContext, SimpleDirectoryReader, LLMPredictor,\n",
    "    GPTSimpleKeywordTableIndex, StorageContext\n",
    ")\n",
    "from llama_index.indices.composability import ComposableGraph\n",
    "from llama_index import load_index_from_storage, load_graph_from_storage\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6feb252",
   "metadata": {},
   "source": [
    "# Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d22fee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790f4c7",
   "metadata": {},
   "source": [
    "# W&B Callback Manager Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13f2b759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9be02ccc4d488bb8444f56c602572e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016752258331204455, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ayut/llamaindex-demo/runs/pvnznu1p\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
     ]
    }
   ],
   "source": [
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "\n",
    "# wandb.init args\n",
    "run_args = dict(\n",
    "    project=\"llamaindex-demo\",\n",
    ")\n",
    "\n",
    "wandb_callback = WandbCallbackHandler(run_args=run_args)\n",
    "\n",
    "callback_manager = CallbackManager([llama_debug, wandb_callback])\n",
    "# callback_manager = CallbackManager([llama_debug])\n",
    "service_context = ServiceContext.from_defaults(callback_manager=callback_manager, llm_predictor=llm_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf969a",
   "metadata": {},
   "source": [
    "> After running the above cell, you will get the W&B run page URL. Here you will find a trace table with all the events tracked using [Weights and Biases' Prompts](https://docs.wandb.ai/guides/prompts) feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a7c101",
   "metadata": {},
   "source": [
    "# 1. Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1011596",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader(\"../data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3d6975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.107289 seconds\n",
      "      |_chunking ->  0.106892 seconds\n",
      "    |_embedding ->  1.268913 seconds\n",
      "    |_embedding ->  1.612722 seconds\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 150182 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 154176 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 150182 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 154176 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 150112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "index = GPTVectorStoreIndex.from_documents(docs, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a948efc",
   "metadata": {},
   "source": [
    "## 1.1 Persist Index as W&B Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ad58e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/ayushthakur/integrations/llamaindex/llama_index/docs/examples/callbacks/wandb/run-20230605_151211-pvnznu1p/files/storage)... Done. 0.0s\n"
     ]
    }
   ],
   "source": [
    "wandb_callback.persist_index(index, index_name=\"simple_vector_store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed156a6",
   "metadata": {},
   "source": [
    "## 1.2 Download Index from W&B Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc35f448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "storage_context = wandb_callback.load_storage_context(artifact_url=\"ayut/llamaindex-demo/simple_vector_store:v6\")\n",
    "\n",
    "# Load the index and initialize a query engine\n",
    "index = load_index_from_storage(storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4de4a9",
   "metadata": {},
   "source": [
    "# 2. Query Over Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42221465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_query ->  4.626081 seconds\n",
      "      |_retrieve ->  0.449322 seconds\n",
      "        |_embedding ->  0.437637 seconds\n",
      "      |_synthesize ->  4.17655 seconds\n",
      "        |_llm ->  4.148625 seconds\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context information does not provide information about the author's upbringing or childhood. It mainly discusses the author's experiences and activities as an adult, including writing essays, working on various projects, and meeting his future wife.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7250272",
   "metadata": {},
   "source": [
    "# 3. Build Complex Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a5f2671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch \"New York City\" page from Wikipedia\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "response = requests.get(\n",
    "    'https://en.wikipedia.org/w/api.php',\n",
    "    params={\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'titles': 'New York City',\n",
    "        'prop': 'extracts',\n",
    "        'explaintext': True,\n",
    "    }\n",
    ").json()\n",
    "page = next(iter(response['query']['pages'].values()))\n",
    "nyc_text = page['extract']\n",
    "\n",
    "data_path = Path('data')\n",
    "if not data_path.exists():\n",
    "    Path.mkdir(data_path)\n",
    "\n",
    "with open('data/nyc_text.txt', 'w') as fp:\n",
    "    fp.write(nyc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0c0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NYC dataset\n",
    "nyc_documents = SimpleDirectoryReader('data/').load_data()\n",
    "# load PG's essay\n",
    "essay_documents = SimpleDirectoryReader('../paul_graham_essay/data/').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c2dbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While building a composable index, to correctly save the index,\n",
    "# the same `storage_context` needs to be passed to every index.\n",
    "storage_context = StorageContext.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d795f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.167983 seconds\n",
      "      |_chunking ->  0.167474 seconds\n",
      "    |_embedding ->  1.619968 seconds\n",
      "    |_embedding ->  1.516472 seconds\n",
      "    |_embedding ->  1.282341 seconds\n",
      "    |_embedding ->  0.85518 seconds\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 260488 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 267112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 260488 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 267112 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 260428 bytes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "# build NYC index\n",
    "nyc_index = GPTVectorStoreIndex.from_documents(\n",
    "    nyc_documents, service_context=service_context, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9a49c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  2.4e-05 seconds\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "# build essay index\n",
    "essay_index = GPTVectorStoreIndex.from_documents(\n",
    "    essay_documents, service_context=service_context, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa7e5f",
   "metadata": {},
   "source": [
    "## 3.1. Query Over Graph Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2704b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_index_summary = \"\"\"\n",
    "    New York, often called New York City or NYC, \n",
    "    is the most populous city in the United States. \n",
    "    With a 2020 population of 8,804,190 distributed over 300.46 square miles (778.2 km2), \n",
    "    New York City is also the most densely populated major city in the United States, \n",
    "    and is more than twice as populous as second-place Los Angeles. \n",
    "    New York City lies at the southern tip of New York State, and \n",
    "    constitutes the geographical and demographic center of both the \n",
    "    Northeast megalopolis and the New York metropolitan area, the \n",
    "    largest metropolitan area in the world by urban landmass.[8] With over \n",
    "    20.1 million people in its metropolitan statistical area and 23.5 million \n",
    "    in its combined statistical area as of 2020, New York is one of the world's \n",
    "    most populous megacities, and over 58 million people live within 250 mi (400 km) of \n",
    "    the city. New York City is a global cultural, financial, and media center with \n",
    "    a significant influence on commerce, health care and life sciences, entertainment, \n",
    "    research, technology, education, politics, tourism, dining, art, fashion, and sports. \n",
    "    Home to the headquarters of the United Nations, \n",
    "    New York is an important center for international diplomacy,\n",
    "    an established safe haven for global investors, and is sometimes described as the capital of the world.\n",
    "\"\"\"\n",
    "essay_index_summary = \"\"\"\n",
    "    Author: Paul Graham. \n",
    "    The author grew up painting and writing essays. \n",
    "    He wrote a book on Lisp and did freelance Lisp hacking work to support himself. \n",
    "    He also became the de facto studio assistant for Idelle Weber, an early photorealist painter. \n",
    "    He eventually had the idea to start a company to put art galleries online, but the idea was unsuccessful. \n",
    "    He then had the idea to write software to build online stores, which became the basis for his successful company, Viaweb. \n",
    "    After Viaweb was acquired by Yahoo!, the author returned to painting and started writing essays online. \n",
    "    He wrote a book of essays, Hackers & Painters, and worked on spam filters. \n",
    "    He also bought a building in Cambridge to use as an office. \n",
    "    He then had the idea to start Y Combinator, an investment firm that would \n",
    "    make a larger number of smaller investments and help founders remain as CEO. \n",
    "    He and his partner Jessica Livingston ran Y Combinator and funded a batch of startups twice a year. \n",
    "    He also continued to write essays, cook for groups of friends, and explore the concept of invented vs discovered in software. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "353a644b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: graph_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "from llama_index import StorageContext, load_graph_from_storage\n",
    "\n",
    "graph = ComposableGraph.from_indices(\n",
    "    GPTSimpleKeywordTableIndex,\n",
    "    [nyc_index, essay_index], \n",
    "    index_summaries=[nyc_index_summary, essay_index_summary],\n",
    "    max_keywords_per_chunk=50,\n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda70171",
   "metadata": {},
   "source": [
    "### 3.1.1 Persist Composable Index as W&B Artifacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c3ebaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/ayushthakur/integrations/llamaindex/llama_index/docs/examples/callbacks/wandb/run-20230605_144621-lxvq37gm/files/storage)... Done. 0.0s\n"
     ]
    }
   ],
   "source": [
    "wandb_callback.persist_index(graph, index_name=\"composable_graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60da73",
   "metadata": {},
   "source": [
    "### 3.1.2 Download Index from W&B Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ce7ecb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "storage_context = wandb_callback.load_storage_context(artifact_url=\"ayut/llamaindex-demo/composable_graph:v1\")\n",
    "\n",
    "# Load the graph and initialize a query engine\n",
    "graph = load_graph_from_storage(storage_context, root_id=graph.root_id, service_context=service_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30ddfc9",
   "metadata": {},
   "source": [
    "### 3.1.3 Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e852e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_query ->  2.67654 seconds\n",
      "      |_retrieve ->  0.640507 seconds\n",
      "        |_embedding ->  0.626605 seconds\n",
      "      |_synthesize ->  2.035826 seconds\n",
      "        |_llm ->  2.009867 seconds\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the climate of New York City like? How cold is it during the winter?\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ff101",
   "metadata": {},
   "source": [
    "### Close W&B Callback Handler\n",
    "\n",
    "When we are done tracking our events we can close the wandb run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28ef6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_callback.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e99f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
