{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13d2b729",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/callbacks/HoneyHiveLlamaIndexTracer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8b66c",
   "metadata": {},
   "source": [
    "# HoneyHive LlamaIndex Tracer\n",
    "\n",
    "[HoneyHive](https://honeyhive.ai) is a platform that helps developers monitor, evaluate and continuously improve their LLM-powered applications.\n",
    "\n",
    "The `HoneyHiveLlamaIndexTracer` is integrated with HoneyHive to help developers debug and analyze the execution flow of your LLM pipeline, or to let developers customize feedback on specific trace events to create evaluation or fine-tuning datasets from production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f35ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your OpenAI key from: https://platform.openai.com/account/api-keys\n",
      " Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\n",
    "        \"Paste your OpenAI key from:\"\n",
    "        \" https://platform.openai.com/account/api-keys\\n\"\n",
    "    )\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\n",
    "    \"sk-\"\n",
    "), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565e3ef-61cb-4196-81b3-71b4d724434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your HoneyHive key from: https://app.honeyhive.ai/settings/account\n",
      " Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HoneyHive API key configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if os.getenv(\"HONEYHIVE_API_KEY\") is None:\n",
    "    os.environ[\"HONEYHIVE_API_KEY\"] = getpass(\n",
    "        \"Paste your HoneyHive key from:\"\n",
    "        \" https://app.honeyhive.ai/settings/account\\n\"\n",
    "    )\n",
    "print(\"HoneyHive API key configured\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdd01a48",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a29d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.callbacks import CallbackManager\n",
    "from llama_index.callbacks import LlamaDebugHandler\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    "    SimpleKeywordTableIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.indices.composability import ComposableGraph\n",
    "from llama_index import load_index_from_storage, load_graph_from_storage\n",
    "from llama_index.llms import OpenAI\n",
    "from honeyhive.utils.llamaindex_tracer import HoneyHiveLlamaIndexTracer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6feb252",
   "metadata": {},
   "source": [
    "## Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cff711-8704-4db9-ba81-8160b7bd1447",
   "metadata": {},
   "source": [
    "## HoneyHive Callback Manager Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32b984-772e-4832-945e-cb6fc7be9e0b",
   "metadata": {},
   "source": [
    "**Option 1**: Set Global Evaluation Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b9d22-cd67-4fb5-9785-254e58179a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import set_global_handler\n",
    "\n",
    "set_global_handler(\n",
    "    \"honeyhive\",\n",
    "    project=\"My LlamaIndex Project\",\n",
    "    name=\"My LlamaIndex Pipeline\",\n",
    "    api_key=os.environ[\"HONEYHIVE_API_KEY\"],\n",
    ")\n",
    "hh_tracer = llama_index.global_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0645550-0585-4d3f-b075-32905552b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1755516-f8ad-458e-b52f-f7665c023e43",
   "metadata": {},
   "source": [
    "**Option 2**: Manually Configure Callback Handler\n",
    "\n",
    "Also configure a debugger handler for extra notebook visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa9155-daca-4a8f-8ca6-87d1ee98f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "\n",
    "hh_tracer = HoneyHiveLlamaIndexTracer(\n",
    "    project=\"My LlamaIndex Project\",\n",
    "    name=\"My LlamaIndex Pipeline\",\n",
    "    api_key=os.environ[\"HONEYHIVE_API_KEY\"],\n",
    ")\n",
    "\n",
    "callback_manager = CallbackManager([llama_debug, hh_tracer])\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    callback_manager=callback_manager, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a7c101",
   "metadata": {},
   "source": [
    "## 1. Indexing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81633478",
   "metadata": {},
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0aa69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1011596",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.080298 seconds\n",
      "      |_chunking ->  0.078948 seconds\n",
      "    |_embedding ->  1.117244 seconds\n",
      "    |_embedding ->  0.382624 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(docs, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4de4a9",
   "metadata": {},
   "source": [
    "## 2. Query Over Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42221465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_query ->  11.334982 seconds\n",
      "      |_retrieve ->  0.255016 seconds\n",
      "        |_embedding ->  0.247083 seconds\n",
      "      |_synthesize ->  11.079581 seconds\n",
      "        |_templating ->  5.7e-05 seconds\n",
      "        |_llm ->  11.065533 seconds\n",
      "**********\n",
      "Growing up, the author was involved in writing and programming. They wrote short stories and tried their hand at programming on an IBM 1401, using an early version of Fortran. Later, they started programming on a TRS-80 microcomputer that their father bought, creating simple games, a program to predict the flight of their model rockets, and a word processor. Despite their interest in programming, they initially planned to study philosophy in college, but eventually switched to AI.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7250272",
   "metadata": {},
   "source": [
    "## 3. Build Complex Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f2671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch \"New York City\" page from Wikipedia\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://en.wikipedia.org/w/api.php\",\n",
    "    params={\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": \"New York City\",\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "    },\n",
    ").json()\n",
    "page = next(iter(response[\"query\"][\"pages\"].values()))\n",
    "nyc_text = page[\"extract\"]\n",
    "\n",
    "data_path = Path(\"data\")\n",
    "if not data_path.exists():\n",
    "    Path.mkdir(data_path)\n",
    "\n",
    "with open(\"data/nyc_text.txt\", \"w\") as fp:\n",
    "    fp.write(nyc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c0307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NYC dataset\n",
    "nyc_documents = SimpleDirectoryReader(\"data/\").load_data()\n",
    "# load PG's essay\n",
    "essay_documents = SimpleDirectoryReader(\"../data/paul_graham\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2dbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While building a composable index, to correctly save the index,\n",
    "# the same `storage_context` needs to be passed to every index.\n",
    "storage_context = StorageContext.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d795f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.069026 seconds\n",
      "      |_chunking ->  0.066652 seconds\n",
      "    |_embedding ->  1.216197 seconds\n",
      "    |_embedding ->  0.413493 seconds\n",
      "    |_embedding ->  0.405327 seconds\n",
      "    |_embedding ->  0.191452 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# build NYC index\n",
    "nyc_index = VectorStoreIndex.from_documents(\n",
    "    nyc_documents,\n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a49c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.09018 seconds\n",
      "      |_chunking ->  0.088916 seconds\n",
      "    |_embedding ->  0.403542 seconds\n",
      "    |_embedding ->  0.378775 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# build essay index\n",
    "essay_index = VectorStoreIndex.from_documents(\n",
    "    essay_documents,\n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa7e5f",
   "metadata": {},
   "source": [
    "### 3.1. Query Over Graph Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2704b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_index_summary = \"\"\"\n",
    "    New York, often called New York City or NYC, \n",
    "    is the most populous city in the United States. \n",
    "    With a 2020 population of 8,804,190 distributed over 300.46 square miles (778.2 km2), \n",
    "    New York City is also the most densely populated major city in the United States, \n",
    "    and is more than twice as populous as second-place Los Angeles. \n",
    "    New York City lies at the southern tip of New York State, and \n",
    "    constitutes the geographical and demographic center of both the \n",
    "    Northeast megalopolis and the New York metropolitan area, the \n",
    "    largest metropolitan area in the world by urban landmass.[8] With over \n",
    "    20.1 million people in its metropolitan statistical area and 23.5 million \n",
    "    in its combined statistical area as of 2020, New York is one of the world's \n",
    "    most populous megacities, and over 58 million people live within 250 mi (400 km) of \n",
    "    the city. New York City is a global cultural, financial, and media center with \n",
    "    a significant influence on commerce, health care and life sciences, entertainment, \n",
    "    research, technology, education, politics, tourism, dining, art, fashion, and sports. \n",
    "    Home to the headquarters of the United Nations, \n",
    "    New York is an important center for international diplomacy,\n",
    "    an established safe haven for global investors, and is sometimes described as the capital of the world.\n",
    "\"\"\"\n",
    "essay_index_summary = \"\"\"\n",
    "    Author: Paul Graham. \n",
    "    The author grew up painting and writing essays. \n",
    "    He wrote a book on Lisp and did freelance Lisp hacking work to support himself. \n",
    "    He also became the de facto studio assistant for Idelle Weber, an early photorealist painter. \n",
    "    He eventually had the idea to start a company to put art galleries online, but the idea was unsuccessful. \n",
    "    He then had the idea to write software to build online stores, which became the basis for his successful company, Viaweb. \n",
    "    After Viaweb was acquired by Yahoo!, the author returned to painting and started writing essays online. \n",
    "    He wrote a book of essays, Hackers & Painters, and worked on spam filters. \n",
    "    He also bought a building in Cambridge to use as an office. \n",
    "    He then had the idea to start Y Combinator, an investment firm that would \n",
    "    make a larger number of smaller investments and help founders remain as CEO. \n",
    "    He and his partner Jessica Livingston ran Y Combinator and funded a batch of startups twice a year. \n",
    "    He also continued to write essays, cook for groups of friends, and explore the concept of invented vs discovered in software. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: graph_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "from llama_index import StorageContext, load_graph_from_storage\n",
    "\n",
    "graph = ComposableGraph.from_indices(\n",
    "    SimpleKeywordTableIndex,\n",
    "    [nyc_index, essay_index],\n",
    "    index_summaries=[nyc_index_summary, essay_index_summary],\n",
    "    max_keywords_per_chunk=50,\n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30ddfc9",
   "metadata": {},
   "source": [
    "### 3.2 Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_query ->  28.480834 seconds\n",
      "      |_retrieve ->  0.002333 seconds\n",
      "      |_query ->  15.367174 seconds\n",
      "        |_retrieve ->  0.171675 seconds\n",
      "          |_embedding ->  0.162042 seconds\n",
      "        |_synthesize ->  15.194969 seconds\n",
      "          |_templating ->  4.8e-05 seconds\n",
      "          |_llm ->  15.179017 seconds\n",
      "      |_synthesize ->  13.110327 seconds\n",
      "        |_templating ->  8.2e-05 seconds\n",
      "        |_llm ->  13.103851 seconds\n",
      "**********\n",
      "New York City has a humid subtropical climate, which makes it unique as the northernmost major city in North America with this type of climate. The city enjoys an average of 234 days of sunshine each year. During winter, the city is chilly and damp, with influences from the Atlantic Ocean and the Appalachian Mountains helping to keep it warmer than other inland cities at similar latitudes. The average daily temperature in January, which is the coldest month, is 33.3 Â°F (0.7 Â°C). However, temperatures can fluctuate significantly, dropping to 10 Â°F (âˆ’12 Â°C) on some days, and reaching up to 60 Â°F (16 Â°C) on others, even in the coldest winter month.\n"
     ]
    }
   ],
   "source": [
    "query_engine = graph.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What is the climate of New York City like? How cold is it during the\"\n",
    "    \" winter?\",\n",
    ")\n",
    "print(response, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ff101",
   "metadata": {},
   "source": [
    "## View HoneyHive Traces\n",
    "\n",
    "When we are done tracing our events we can view them via [the HoneyHive platform](https://app.honeyhive.ai). Simply login to HoneyHive, go to your `My LlamaIndex Project` project, click the `Data Store` tab and view your `Sessions`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
