{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7c3284",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/llm/apertis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07f0af-6f8b-4a4e-a984-5f0f161dd0c3",
   "metadata": {},
   "source": [
    "# Apertis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d66a7",
   "metadata": {},
   "source": [
    "Apertis provides a unified API gateway to access multiple LLM providers including OpenAI, Anthropic, Google, and more through an OpenAI-compatible interface. You can find out more on their [documentation](https://docs.stima.tech).\n",
    "\n",
    "**Supported Endpoints:**\n",
    "- `/v1/chat/completions` - OpenAI Chat Completions format (default)\n",
    "- `/v1/responses` - OpenAI Responses format compatible\n",
    "- `/v1/messages` - Anthropic format compatible\n",
    "\n",
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-apertis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfb427-2607-4322-bdaa-f012a87a0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.apertis import Apertis\n",
    "from llama_index.core.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3907f07b-a33a-46db-b799-fec83843ff60",
   "metadata": {},
   "source": [
    "## Call `chat` with ChatMessage List\n",
    "You need to either set env var `APERTIS_API_KEY` or set api_key in the class constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bec6d7-d5cc-4c23-aa95-a915e65220cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['APERTIS_API_KEY'] = '<your-api-key>'\n",
    "\n",
    "llm = Apertis(\n",
    "    api_key=\"<your-api-key>\",\n",
    "    max_tokens=256,\n",
    "    context_window=4096,\n",
    "    model=\"gpt-5.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135fe2a-b4ff-4352-a825-bdc3aca17b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = ChatMessage(role=\"user\", content=\"Tell me a joke\")\n",
    "resp = llm.chat([message])\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515c6b2-e691-4f89-baa2-4964abee9cc5",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f51ad-d585-4bf4-b0e1-95ed7ecf3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = ChatMessage(role=\"user\", content=\"Tell me a story in 250 words\")\n",
    "resp = llm.stream_chat([message])\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92c80f-5b82-4143-a6f9-549d6f5dfa70",
   "metadata": {},
   "source": [
    "## Call `complete` with Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290c9b1-3c37-4db0-aa94-dda1c90d4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Tell me a joke\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a7fe6-51b7-4e80-b60d-fbe3335610c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.stream_complete(\"Tell me a story in 250 words\")\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3a2018-89f1-4795-9b68-c06b8f104a69",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-info",
   "metadata": {},
   "source": [
    "Apertis supports models from multiple providers:\n",
    "\n",
    "| Provider | Example Models |\n",
    "|----------|---------------|\n",
    "| OpenAI | `gpt-5.2`, `gpt-5-mini-2025-08-07` |\n",
    "| Anthropic | `claude-sonnet-4.5` |\n",
    "| Google | `gemini-3-flash-preview` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2680d-5e21-4eba-a685-a30d64554b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Claude\n",
    "llm = Apertis(model=\"claude-sonnet-4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebd16b-1740-4f31-800d-9c9c8fcc0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Write a story about a dragon who can code in Rust\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gemini-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gemini\n",
    "llm = Apertis(model=\"gemini-3-flash-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gemini-complete",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Explain quantum computing in simple terms\")\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
