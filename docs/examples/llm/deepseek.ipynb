{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1b897a",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/deepseek.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e33dced-e587-4397-81b3-d6606aa1738a",
   "metadata": {},
   "source": [
    "# DeepSeek\n",
    "\n",
    "# LlamaIndex Llms Integration: DeepSeek\n",
    "\n",
    "This is the DeepSeek integration for LlamaIndex. Visit [DeepSeek](https://api-docs.deepseek.com/) for information on how to get an API key and which models are supported. \n",
    "\n",
    "At the time of writing, you can use:\n",
    "- `deepseek-chat`\n",
    "- `deepseek-reasoner`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5863dde9-84a0-4c33-ad52-cc767442f63f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833bdb2b",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad297f19-998f-4485-aa2f-d67020058b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.deepseek import DeepSeek\n",
    "\n",
    "# you can also set DEEPSEEK_API_KEY in your environment variables\n",
    "llm = DeepSeek(model=\"deepseek-reasoner\", api_key=\"you_api_key\")\n",
    "\n",
    "# You might also want to set deepseek as your default llm\n",
    "# from llama_index.core import Settings\n",
    "# Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b10bb-e911-47fb-8e84-19828cf224be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(\"Is 9.9 or 9.11 bigger?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd14f4e-c245-4384-a471-97e4ddfcb40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine whether 9.9 or 9.11 is larger, compare them by aligning their decimal places:\n",
      "\n",
      "1. **Write both numbers with the same number of decimal places**:  \n",
      "   - \\(9.9\\) becomes \\(9.90\\).  \n",
      "   - \\(9.11\\) remains \\(9.11\\).  \n",
      "\n",
      "2. **Compare digit by digit**:  \n",
      "   - **Units place**: Both have \\(9\\) (equal).  \n",
      "   - **Tenths place**: \\(9\\) (in \\(9.90\\)) vs. \\(1\\) (in \\(9.11\\)). Since \\(9 > 1\\), \\(9.90 > 9.11\\).  \n",
      "\n",
      "**Conclusion**:  \n",
      "\\(9.9\\) (or \\(9.90\\)) is greater than \\(9.11\\).  \n",
      "\n",
      "\\(\\boxed{9.9}\\)\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ba9503c-b440-43c6-a50c-676c79993813",
   "metadata": {},
   "source": [
    "#### Call `chat` with a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a4a55-5680-4dc6-a44c-fc8ad7892f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=\"user\", content=\"How many 'r's are in the word 'strawberry'?\"\n",
    "    ),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9bfe53-d15b-4e75-9d91-8c5d024f4eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Arrr, matey! Let's plunder the word \"strawberry\" fer them sneaky 'r's! Here be the breakdown:  \n",
      "\n",
      "**S - T - R - A - W - B - E - R - R - Y**  \n",
      "\n",
      "Shiver me timbers! There be **3 'r's** lurkin' in them letters! Aye, one in \"straw\" and two in \"berry\"—just like treasure buried in three chests! 🏴☠️🍓\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ad1b00-28fc-4bcd-96c4-d5b35605721a",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13c641fa-345a-4dce-87c5-ab1f6dcf4757",
   "metadata": {},
   "source": [
    "Using `stream_complete` endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da1ef1-2f6b-497c-847b-62dd2df11491",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.stream_complete(\"Is 9.9 or 9.11 bigger?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b851def-5160-46e5-a30c-5a3ef2356b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine whether 9.9 or 9.11 is bigger, we can compare them by converting both numbers to have the same number of decimal places. \n",
      "\n",
      "- 9.9 can be written as 9.90 (adding a zero to make it two decimal places).\n",
      "- 9.11 is already in two decimal places.\n",
      "\n",
      "Next, we compare the tenths place:\n",
      "- 9.90 has a 9 in the tenths place.\n",
      "- 9.11 has a 1 in the tenths place.\n",
      "\n",
      "Since 9 is greater than 1, 9.90 is larger than 9.11. \n",
      "\n",
      "To confirm, we can subtract:\n",
      "\\[ 9.90 - 9.11 = 0.79 \\]\n",
      "The positive result indicates that 9.90 is greater than 9.11.\n",
      "\n",
      "Another method is converting to fractions:\n",
      "- 9.9 is \\( \\frac{99}{10} \\) which is equivalent to \\( \\frac{990}{100} \\).\n",
      "- 9.11 is \\( \\frac{911}{100} \\).\n",
      "\n",
      "Comparing \\( \\frac{990}{100} \\) and \\( \\frac{911}{100} \\), we see 990 is greater than 911.\n",
      "\n",
      "Thus, the larger number is \\boxed{9.9}."
     ]
    }
   ],
   "source": [
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca52051d-6b28-49d7-98f5-82e266a1c7a6",
   "metadata": {},
   "source": [
    "Using `stream_chat` endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe553190-52a9-436d-84ae-4dd99a1808f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=\"user\", content=\"How many 'r's are in the word 'strawberry'?\"\n",
    "    ),\n",
    "]\n",
    "resp = llm.stream_chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c503c-f893-4b6b-8a65-a9a27b636046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, matey! Let's plunder the letters o' \"strawberry\" to count them sneaky 'r's! 🏴☠️\n",
      "\n",
      "**S-T-R-A-W-B-E-R-R-Y**  \n",
      "Yarrr, here be the breakdown:  \n",
      "\n",
      "1. **S** 🚫  \n",
      "2. **T** 🚫  \n",
      "3. **R** ✅ (1st 'r')  \n",
      "4. **A** 🚫  \n",
      "5. **W** 🚫  \n",
      "6. **B** 🚫  \n",
      "7. **E** 🚫  \n",
      "8. **R** ✅ (2nd 'r')  \n",
      "9. **R** ✅ (3rd 'r')  \n",
      "10. **Y** 🚫  \n",
      "\n",
      "**Total 'r's: 3**  \n",
      "Shiver me timbers! Three 'r's be lurkin' in \"strawberry\"! 🍓⚔️"
     ]
    }
   ],
   "source": [
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
