{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf320495",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/llm/helicone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603e8916",
   "metadata": {},
   "source": [
    "# Helicone AI Gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab1a09",
   "metadata": {},
   "source": [
    "Helicone is an OpenAI-compatible AI Gateway that routes requests to many providers with observability, control, and caching. Learn more on the [Helicone docs](https://docs.helicone.ai/) and see available [models](https://www.helicone.ai/models).\\n\\nIf you're opening this Notebook on Colab, you'll likely need to install the integration packages below.\\n\\nNotes:\\n- Only your Helicone API key is required (`HELICONE_API_KEY`); no provider keys are needed.\\n- Default base URL is `https://ai-gateway.helicone.ai/v1`. Override with `api_base` or `HELICONE_API_BASE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-helicone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05bc4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.helicone import Helicone\n",
    "from llama_index.core.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af2660",
   "metadata": {},
   "source": [
    "## Call `chat` with ChatMessage List\\nYou need to either set env var `HELICONE_API_KEY` or pass `api_key` in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554de62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"HELICONE_API_KEY\"] = \"<your-helicone-api-key>\"\n",
    "\n",
    "llm = Helicone(\n",
    "    api_key=\"<your-helicone-api-key>\",  # or set HELICONE_API_KEY\n",
    "    model=\"gpt-4o-mini\",              # routed via the Helicone AI Gateway\n",
    "    max_tokens=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = ChatMessage(role=\"user\", content=\"Tell me a joke\")\n",
    "resp = llm.chat([message])\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11e2ae",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = ChatMessage(role=\"user\", content=\"Tell me a story in 200 words\")\n",
    "resp = llm.stream_chat([message])\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa7199f",
   "metadata": {},
   "source": [
    "## Call `complete` with Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.complete(\"Give me a haiku about gateways\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ef1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = llm.stream_complete(\"Write a short poem about observability\")\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb7876",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc38964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose any OpenAI-compatible model routed by Helicone.\n",
    "# See https://www.helicone.ai/models for options.\n",
    "\n",
    "# If HELICONE_API_KEY is set in your environment, you can omit api_key here.\n",
    "llm = Helicone(model=\"gpt-4o-mini\")\n",
    "resp = llm.complete(\"Write one sentence about Rust dragons coding.\")\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
