{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VideoDB Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build RAG pipelines for Videos without ever thinking about the complexity of videos**\n",
    "\n",
    "Building RAG (Retrieval-Augmented Generation) models for text is quite straightforward, thanks to the ease of parsing, indexing, and retrieving text data. However, applying RAG models to video content is much more complex. Videos combine visual, auditory, and textual elements, requiring more processing power and sophisticated algorithms for effective use. Plus, video files are large, making them resource-intensive to handle.\n",
    "\n",
    "Enter [VideoDB](https://videodb.io), a database designed to simplify video complexity. It makes building RAG models for videos easier by addressing the challenges of video processing and indexing. Learn more about it at [videodb.io](https://videodb.io).\n",
    "\n",
    "In this notebook, we introduce `VideoDBRetriever`, a tool designed to streamline the creation of RAG pipelines for video content, without the hassle of dealing with video complexity.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## üõ†Ô∏èÔ∏è Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Requirements\n",
    "\n",
    "To use this notebook, you'll need API keys for both VideoDB and OpenAI. Follow these steps to set up your environment:\n",
    "\n",
    "- **VideoDB API Key**: Get your API key from [VideoDB dashboard](https://console.videodb.io)\n",
    "- **OpenAI API Key**: Get your API key from OpenAI platform.\n",
    "\n",
    "> Set the `OPENAI_API_KEY` & `VIDEO_DB_API_KEY` environment variable with your API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Dependencies\n",
    "\n",
    "To get started, we'll need to install the following packages:\n",
    "\n",
    "- llama-index\n",
    "- llama-index-retrievers-videodb\n",
    "- videodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --pre llama-index-retrievers-videodb videodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## ü¶ô Simple Video RAG Pipeline\n",
    "\n",
    "Let's get started by uploading a few video files to [VideoDB](https://videodb.io). Next, we'll use `VideoDBRetriever` to fetch relevant video segments based on our queries.\n",
    "\n",
    "Afterwards, we'll use these segments to create a context for LLM, which will then be augmented for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "\n",
    "We will upload our videos to VideoDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "# connect to VideoDB\n",
    "conn = connect()\n",
    "\n",
    "# upload videos to default collection in VideoDB \n",
    "video1 = conn.upload(url=\"https://www.youtube.com/watch?v=sAuvP68J6DQ\")\n",
    "video2 = conn.upload(url=\"https://www.youtube.com/watch?v=H2wBQ6CSPiY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "We will use VideoDB's managed index to index our data \n",
    "\n",
    "VideoDB offers following indexes\n",
    "- Semantic: Index on based of Spoken words\n",
    "- Scene: Index on the based of Scene Description & Visuals _(Note: This feature is currently available only to beta users)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video1.index_spoken_words()\n",
    "video2.index_spoken_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying\n",
    "\n",
    "Next, we'll employ `VideoDBRetriever` to fetch relevant nodes from the VideoDB database. Following that, we'll utilize `llama-index` to construct a straightforward RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers.videodb import VideoDBRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VideoDBRetriever by default uses the default collection in the VideoDB \n",
    "retriever = VideoDBRetriever()\n",
    "\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How did the hostages die\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How many hostages were there\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üéâ That's a Simple RAG Pipleine for Video**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## ‚ú® More with VideoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring `VideoDBRetriever`\n",
    "There are some configuration options available to `VideoDBRetriever`   \n",
    "  \n",
    "\n",
    "**Retriever for only one Video**:\n",
    "```python\n",
    "video1 = conn.upload(\"https://www.youtube.com/watch?v=sAuvP68J6DQ\")\n",
    "retriever_video1 = VideoDBRetriever(video=video1.id)\n",
    "```\n",
    "\n",
    "**Retriever for differnt types of Index**:\n",
    "```python\n",
    "# VideoDBRetriever that uses keyword search\n",
    "keyword_retriever = VideoDBRetriever(search_type=\"keyword\", video=\"my_video_id\")\n",
    "\n",
    "# VideoDBRetriever that uses semantic search\n",
    "semantic_retriever = VideoDBRetriever(search_type=\"semantic\")\n",
    "\n",
    "# VideoDBRetriever that uses scene search\n",
    "visual_retriever = VideoDBRetriever(search_type=\"scene\")\n",
    "```\n",
    "\n",
    "**Configure Results & Search Threshold**:  \n",
    "- `result_threshold`: is threshold for number of results returned by retriever; default value is `5`\n",
    "- `score_threshold`: only nodes with score higher than `score_threshold` will be returned by retriever; default value is `0.2`  \n",
    "\n",
    "```python\n",
    "custom_retriever = VideoDBRetriever(result_threshold=2, score_threshold=0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Your Nodes\n",
    "\n",
    "Although, The `Nodes` returned by Retriever are of type `TextNode`.\n",
    "But they do really work like a `VideoNode`, where you can view each node instantly as Video.\n",
    "Create Further Nodes from a Single Node, apply chunking techniques and all. without every worrying about complexity dealing with Video Data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation of all Retrieved Nodes\n",
    "\n",
    "You can create a compilation of all Nodes using VideoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect, play_stream \n",
    "from videodb.timeline import Timeline\n",
    "from videodb.asset import VideoAsset\n",
    "\n",
    "conn = connect()\n",
    "timeline = Timeline(conn)\n",
    "\n",
    "retriever = VideoDBRetriever()\n",
    "relevant_nodes = retriever.retrieve(\"How many hostages were there\")\n",
    "\n",
    "for node_obj in relevant_nodes:\n",
    "    node = node_obj.node\n",
    "    # create a video asset for each node\n",
    "    node_asset = VideoAsset(asset_id=node.metadata[\"video_id\"], start=node.metadata[\"start\"], end=node.metadata[\"end\"])\n",
    "    # add the asset to timeline\n",
    "    timeline.add_inline(node_asset)\n",
    "\n",
    "stream_url = timeline.generate_stream()\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can also get relevant node using query engine too\n",
    ">``` python \n",
    ">response = query_engine.query(\"my query\")\n",
    ">relevant_nodes = query_engine.source_nodes\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Specific Node\n",
    "\n",
    "That was a compilation of retrieved nodes, but you can view each retrieved node as a individual too.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from videodb import connect\n",
    "\n",
    "retriever = VideoDBRetriever()\n",
    "\n",
    "relevant_nodes = retriever.retrieve(\"How many hostages were there\")\n",
    "video_node = relevant_nodes[0].node\n",
    "\n",
    "conn = connect()\n",
    "coll = conn.get_collection()\n",
    "\n",
    "video = coll.get_video(video_node.metadata[\"video_id\"])\n",
    "start = video_node.metadata[\"start\"]\n",
    "end = video_node.metadata[\"end\"]\n",
    "\n",
    "stream_url = video.generate_stream(timeline=[(start, end)])\n",
    "play_stream(stream_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video1.delete()\n",
    "video2.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Support & Community\n",
    "\n",
    "If you have any questions or feedback.  \n",
    "Please feel free to reach out to us\n",
    "\n",
    "- [Discord](https://discord.gg/py9P639jGz)  \n",
    "- [Github](https://videodb.io)  \n",
    "- [VideoDB](https://videodb.io)  \n",
    "- [Mail](mailto:contact@videodb.io)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
