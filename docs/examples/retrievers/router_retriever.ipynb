{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2df12876",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/retrievers/router_retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1de44-4047-46cf-a04c-dbf910d9e179",
   "metadata": {},
   "source": [
    "# Router Retriever\n",
    "In this guide, we define a custom router retriever that selects one or more candidate retrievers in order to execute a given query.\n",
    "\n",
    "The router (`BaseSelector`) module uses the LLM to dynamically make decisions on which underlying retrieval tools to use. This can be helpful to select one out of a diverse range of data sources. This can also be helpful to aggregate retrieval results across a variety of data sources (if a multi-selector module is used).\n",
    "\n",
    "This notebook is very similar to the RouterQueryEngine notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e73fead-ec2c-4346-bd08-e183c13c7e29",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19b24c3d",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e706656",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3112794",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d59778-4cda-47b5-8cd0-b80fee91d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes.\n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c628448c-573c-4eeb-a7e1-707fe8cc575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().handlers = []\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    SimpleKeywordTableIndex,\n",
    ")\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dffaa7db",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787174ed-10ce-47d7-82fd-9ca7f891eea7",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "We first show how to convert a Document into a set of Nodes, and insert into a DocumentStore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1b8ac-bf55-4d60-841c-61698663322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081194a-ede7-478e-bff2-23e89e23ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize LLM + splitter\n",
    "llm = OpenAI(model=\"gpt-4\")\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61bca2-c3b4-4ef0-a8f1-367933aa6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize storage context (by default it's in-memory)\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5c44f-11d2-47a2-a566-c6dc0fd5a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define\n",
    "summary_index = SummaryIndex(nodes, storage_context=storage_context)\n",
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "keyword_index = SimpleKeywordTableIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6162df-9da7-4aad-a2ca-eb318f67daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_retriever = summary_index.as_retriever()\n",
    "vector_retriever = vector_index.as_retriever()\n",
    "keyword_retriever = keyword_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f7c3b-69b4-48d5-bf22-ac51a4e3179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import RetrieverTool\n",
    "\n",
    "list_tool = RetrieverTool.from_defaults(\n",
    "    retriever=list_retriever,\n",
    "    description=(\n",
    "        \"Will retrieve all context from Paul Graham's essay on What I Worked\"\n",
    "        \" On. Don't use if the question only requires more specific context.\"\n",
    "    ),\n",
    ")\n",
    "vector_tool = RetrieverTool.from_defaults(\n",
    "    retriever=vector_retriever,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from Paul Graham essay on What\"\n",
    "        \" I Worked On.\"\n",
    "    ),\n",
    ")\n",
    "keyword_tool = RetrieverTool.from_defaults(\n",
    "    retriever=keyword_retriever,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from Paul Graham essay on What\"\n",
    "        \" I Worked On (using entities mentioned in query)\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba2d68-13f9-4519-87ec-40511da7abdd",
   "metadata": {},
   "source": [
    "### Define Selector Module for Routing\n",
    "\n",
    "There are several selectors available, each with some distinct attributes.\n",
    "\n",
    "The LLM selectors use the LLM to output a JSON that is parsed, and the corresponding indexes are queried.\n",
    "\n",
    "The Pydantic selectors (currently only supported by `gpt-4-0613` and `gpt-3.5-turbo-0613` (the default)) use the OpenAI Function Call API to produce pydantic selection objects, rather than parsing raw JSON.\n",
    "\n",
    "Here we use PydanticSingleSelector/PydanticMultiSelector but you can use the LLM-equivalents as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb64a55-05b7-4565-949b-025b8d19c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.selectors import LLMSingleSelector, LLMMultiSelector\n",
    "from llama_index.core.selectors import (\n",
    "    PydanticMultiSelector,\n",
    "    PydanticSingleSelector,\n",
    ")\n",
    "from llama_index.core.retrievers import RouterRetriever\n",
    "from llama_index.core.response.notebook_utils import display_source_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513ca57-bef9-47d3-aa17-3cf72a6eb318",
   "metadata": {},
   "source": [
    "#### PydanticSingleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb1c95-0096-4036-ad32-2337d844bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = RouterRetriever(\n",
    "    selector=PydanticSingleSelector.from_defaults(llm=llm),\n",
    "    retriever_tools=[\n",
    "        list_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c4c12-1a30-425e-8312-04be050b2101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting retriever 0: This choice is most relevant as it mentions retrieving all context from the essay, which could include information about the author's life..\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 7d07d325-489e-4157-a745-270e2066a643<br>**Similarity:** None<br>**Text:** What I Worked On\n",
       "\n",
       "February 2021\n",
       "\n",
       "Before college the two main things I worked on, outside of schoo...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 01f0900b-db83-450b-a088-0473f16882d7<br>**Similarity:** None<br>**Text:** showed Terry Winograd using SHRDLU. I haven't tried rereading The Moon is a Harsh Mistress, so I ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b2549a68-5fef-4179-b027-620ebfa6e346<br>**Similarity:** None<br>**Text:** Science is an uneasy alliance between two halves, theory and systems. The theory people prove thi...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 4f1e9f0d-9bc6-4169-b3b6-4f169bbfa391<br>**Similarity:** None<br>**Text:** been explored. But all I wanted was to get out of grad school, and my rapidly written dissertatio...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e20c99f9-5e80-4c92-8cc0-03d2a527131e<br>**Similarity:** None<br>**Text:** stop there, of course, or you get merely photographic accuracy, and what makes a still life inter...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** dbdf341a-f340-49f9-961f-16b9a51eea2d<br>**Similarity:** None<br>**Text:** that big, bureaucratic customers are a dangerous source of money, and that there's not much overl...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** ed341d3a-9dda-49c1-8611-0ab40d04f08a<br>**Similarity:** None<br>**Text:** about money, because I could sense that Interleaf was on the way down. Freelance Lisp hacking wor...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d69e02d3-2732-4567-a360-893c14ae157b<br>**Similarity:** None<br>**Text:** a web app, is common now, but at the time it wasn't clear that it was even possible. To find out,...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** df9e00a5-e795-40a1-9a6b-8184d1b1e7c0<br>**Similarity:** None<br>**Text:** have to integrate with any other software except Robert's and Trevor's, so it was quite fun to wo...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 38f2699b-0878-499b-90ee-821cb77e387b<br>**Similarity:** None<br>**Text:** all too keenly aware of the near-death experiences we seemed to have every few months. Nor had I ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** be04d6a9-1fc7-4209-9df2-9c17a453699a<br>**Similarity:** None<br>**Text:** for a second still life, painted from the same objects (which hopefully hadn't rotted yet).\n",
       "\n",
       "Mean...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 42344911-8a7c-4e9b-81a8-0fcf40ab7690<br>**Similarity:** None<br>**Text:** which I'd created years before using Viaweb but had never used for anything. In one day it got 30...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 9ec3df49-abf9-47f4-b0c2-16687882742a<br>**Similarity:** None<br>**Text:** I didn't know but would turn out to like a lot: a woman called Jessica Livingston. A couple days ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d0cf6975-5261-4fb2-aae3-f3230090fb64<br>**Similarity:** None<br>**Text:** of readers, but professional investors are thinking \"Wow, that means they got all the returns.\" B...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 607d0480-7eee-4fb4-965d-3cb585fda62c<br>**Similarity:** None<br>**Text:** to the \"YC GDP,\" but as YC grows this becomes less and less of a joke. Now lots of startups get t...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 730a49c9-55f7-4416-ab91-1d0c96e704c8<br>**Similarity:** None<br>**Text:** So this set me thinking. It was true that on my current trajectory, YC would be the last thing I ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** edbe8c67-e373-42bf-af98-276b559cc08b<br>**Similarity:** None<br>**Text:** operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an an...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 175a4375-35ec-45a0-a90c-15611505096b<br>**Similarity:** None<br>**Text:** Like McCarthy's original Lisp, it's a spec rather than an implementation, although like McCarthy'...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0cb367f9-0aac-422b-9243-0eaa7be15090<br>**Similarity:** None<br>**Text:** must tell readers things they don't already know, and some people dislike being told such things....<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 67afd4f1-9fa1-4e76-87ac-23b115823e6c<br>**Similarity:** None<br>**Text:** 1960 paper.\n",
       "\n",
       "But if so there's no reason to suppose that this is the limit of the language that m...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# will retrieve all context from the author's life\n",
    "nodes = retriever.retrieve(\n",
    "    \"Can you give me all the context regarding the author's life?\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749c34e-97c0-4bd5-8358-377a94b8b2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting retriever 1: The question asks for a specific detail from Paul Graham's essay on 'What I Worked On'. Therefore, the second choice, which is useful for retrieving specific context, is the most relevant..\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 22d20835-7de6-4cf7-92de-2bee339f3157<br>**Similarity:** 0.8017176790752668<br>**Text:** that big, bureaucratic customers are a dangerous source of money, and that there's not much overl...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** bf818c58-5d5b-4458-acbc-d87cc67a36ca<br>**Similarity:** 0.7935885352785799<br>**Text:** So this set me thinking. It was true that on my current trajectory, YC would be the last thing I ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\"What did Paul Graham do after RISD?\")\n",
    "for node in nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae962a0-55c3-42e4-8f90-8332499952b5",
   "metadata": {},
   "source": [
    "#### PydanticMultiSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cd132-fa4d-431f-9b02-0fc7482f097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = RouterRetriever(\n",
    "    selector=PydanticMultiSelector.from_defaults(llm=llm),\n",
    "    retriever_tools=[list_tool, vector_tool, keyword_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b877dc-50d9-4841-9747-d902a60b767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting retriever 1: This choice is relevant as it allows for retrieving specific context from the essay, which is needed to answer the question about notable events at Interleaf and YC..\n",
      "Selecting retriever 2: This choice is also relevant as it allows for retrieving specific context using entities mentioned in the query, which in this case are 'Interleaf' and 'YC'..\n",
      "> Starting query: What were noteable events from the authors time at Interleaf and YC?\n",
      "query keywords: ['interleaf', 'events', 'noteable', 'yc']\n",
      "> Extracted keywords: ['interleaf', 'yc']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** fbdd25ed-1ecb-4528-88da-34f581c30782<br>**Similarity:** None<br>**Text:** So this set me thinking. It was true that on my current trajectory, YC would be the last thing I ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 4ce91b17-131f-4155-b7b5-8917cdc612b1<br>**Similarity:** None<br>**Text:** to the \"YC GDP,\" but as YC grows this becomes less and less of a joke. Now lots of startups get t...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 9fe6c152-28d4-4006-8a1a-43bb72655438<br>**Similarity:** None<br>**Text:** stop there, of course, or you get merely photographic accuracy, and what makes a still life inter...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d11cd2e2-1dd2-4c3b-863f-246fe3856f49<br>**Similarity:** None<br>**Text:** of readers, but professional investors are thinking \"Wow, that means they got all the returns.\" B...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 2bfbab04-cb71-4641-9bd9-52c75b3a9250<br>**Similarity:** None<br>**Text:** must tell readers things they don't already know, and some people dislike being told such things....<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\n",
    "    \"What were noteable events from the authors time at Interleaf and YC?\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51424b-d0b1-4c07-acf3-53e398a7d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting retriever 1: This choice is relevant as it allows for retrieving specific context from the essay, which is needed to answer the question about notable events at Interleaf and YC..\n",
      "Selecting retriever 2: This choice is also relevant as it allows for retrieving specific context using entities mentioned in the query, which in this case are 'Interleaf' and 'YC'..\n",
      "> Starting query: What were noteable events from the authors time at Interleaf and YC?\n",
      "query keywords: ['interleaf', 'yc', 'events', 'noteable']\n",
      "> Extracted keywords: ['interleaf', 'yc']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 49882a2c-bb95-4ff3-9df1-2a40ddaea408<br>**Similarity:** None<br>**Text:** So this set me thinking. It was true that on my current trajectory, YC would be the last thing I ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** d11aced1-e630-4109-8ec8-194e975b9851<br>**Similarity:** None<br>**Text:** to the \"YC GDP,\" but as YC grows this becomes less and less of a joke. Now lots of startups get t...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8aa6cc91-8e9c-4470-b6d5-4360ed13fefd<br>**Similarity:** None<br>**Text:** stop there, of course, or you get merely photographic accuracy, and what makes a still life inter...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e37465de-c79a-4714-a402-fbd5f52800a2<br>**Similarity:** None<br>**Text:** must tell readers things they don't already know, and some people dislike being told such things....<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e0ac7fb6-84fc-4763-bca6-b68f300ec7b7<br>**Similarity:** None<br>**Text:** of readers, but professional investors are thinking \"Wow, that means they got all the returns.\" B...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\n",
    "    \"What were noteable events from the authors time at Interleaf and YC?\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1398d-cc34-44d3-a8a1-fc521e3ba009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting retriever 1: This choice is relevant as it allows for retrieving specific context from the essay, which is needed to answer the question about notable events at Interleaf and YC..\n",
      "Selecting retriever 2: This choice is also relevant as it allows for retrieving specific context using entities mentioned in the query, which in this case are 'Interleaf' and 'YC'..\n",
      "> Starting query: What were noteable events from the authors time at Interleaf and YC?\n",
      "query keywords: ['events', 'interleaf', 'yc', 'noteable']\n",
      "> Extracted keywords: ['interleaf', 'yc']\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=25 request_id=95c73e9360e6473daab85cde93ca4c42 response_code=200\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 76d76348-52fb-49e6-95b8-2f7a3900fa1a<br>**Similarity:** None<br>**Text:** So this set me thinking. It was true that on my current trajectory, YC would be the last thing I ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 61e1908a-79d2-426b-840e-926df469ac49<br>**Similarity:** None<br>**Text:** to the \"YC GDP,\" but as YC grows this becomes less and less of a joke. Now lots of startups get t...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** cac03004-5c02-4145-8e92-c320b1803847<br>**Similarity:** None<br>**Text:** stop there, of course, or you get merely photographic accuracy, and what makes a still life inter...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** f0d55e5e-5349-4243-ab01-d9dd7b12cd0a<br>**Similarity:** None<br>**Text:** of readers, but professional investors are thinking \"Wow, that means they got all the returns.\" B...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 1516923c-0dee-4af2-b042-3e1f38de7e86<br>**Similarity:** None<br>**Text:** must tell readers things they don't already know, and some people dislike being told such things....<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = await retriever.aretrieve(\n",
    "    \"What were noteable events from the authors time at Interleaf and YC?\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
