{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e37307f",
   "metadata": {},
   "source": [
    "# Moss + LlamaIndex\n",
    "\n",
    "[Moss](https://moss.dev) is a search runtime for voice agents, copilots, and multimodal apps. Sub-10ms lookups, zero infrastructure. Built in Rust and WebAssembly. Moss runs search inside your agent runtime. Sub-10ms lookups, always-current data, without rebuilding your infra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4f9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-tools-moss llama-index-core llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e189ab0",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the necessary classes and initialize the Moss client with your project credentials. We'll configure query options to tune the search behavior (`top_k` for result count, `alpha` for the semantic/keyword blend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MossToolSpec...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.tools.moss import MossToolSpec, QueryOptions\n",
    "from inferedge_moss import MossClient, DocumentInfo\n",
    "\n",
    "# Initialize Moss Client\n",
    "MOSS_PROJECT_KEY = os.getenv(\"MOSS_PROJECT_KEY\")\n",
    "MOSS_PROJECT_ID = os.getenv(\"MOSS_PROJECT_ID\")\n",
    "client = MossClient(project_id=MOSS_PROJECT_ID, project_key=MOSS_PROJECT_KEY)\n",
    "\n",
    "# 2. Configure query settings - Instantiate QueryOptions (Optional)\n",
    "# If skipped, the tool will use its own defaults.\n",
    "query_options = QueryOptions(top_k=3, alpha=0.5)\n",
    "# 3. Initialize Tool\n",
    "print(\"Initializing MossToolSpec...\")\n",
    "moss_tool = MossToolSpec(\n",
    "    client=client, index_name=\"moss-cookbook\", query_options=query_options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3bbaaa",
   "metadata": {},
   "source": [
    "## Indexing Data\n",
    "\n",
    "Create sample documents with `DocumentInfo` (each with `id`, `text`, and `metadata`). Then call `index_docs()` to build the Moss index â€” this creates or replaces the index with your documents and makes them searchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    DocumentInfo(\n",
    "        id=\"123\",\n",
    "        text=\"LlamaIndex connects your data to LLMs.\",\n",
    "        metadata={\"topic\": \"AI\"},\n",
    "    ),\n",
    "    DocumentInfo(\n",
    "        id=\"456\",\n",
    "        text=\"Moss provides fast semantic search integration.\",\n",
    "        metadata={\"topic\": \"Search\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Index the documents\n",
    "await moss_tool.index_docs(docs)\n",
    "await moss_tool._load_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e62e5",
   "metadata": {},
   "source": [
    "## Using with an Agent\n",
    "\n",
    "Now we'll expose the Moss tool's methods (`query`, `list_indexes`, `delete_index`) to a `ReActAgent`. The agent will autonomously decide which tool to call based on the user's question and the search results it retrieves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generally, a return policy allows customers to return products within a specified period, usually 30 days, for a refund, exchange, or store credit, provided the items are in their original condition and packaging. However, specific return policies can vary by company, so it's best to check the exact terms on the company's website or contact their customer service for detailed information.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# Convert to tool list\n",
    "tools = moss_tool.to_tool_list()\n",
    "\n",
    "# Create an agent (Using OpenAI llm for demonstration)\n",
    "# os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "llm = OpenAI(model=\"gpt-4.1-mini\", api_key=api_key)\n",
    "agent = ReActAgent(tools=tools, llm=llm, verbose=True)\n",
    "\n",
    "# Chat with the agent\n",
    "response = await agent.run(user_msg=\"What is your return policy?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
