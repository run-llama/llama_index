{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6537c4",
   "metadata": {},
   "source": [
    "# ResponseEvaluator\n",
    "\n",
    "This notebook uses the `ResponseEvaluator` module to measure if the response from a query engine matches any response nodes. This is useful for measuring if the response was hallucinated. The data is extracted from the [New York City](https://en.wikipedia.org/wiki/New_York_City) wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8304f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9080b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring logger to INFO level\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0b2364-4806-4656-81e7-3f6e4b910b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import (\n",
    "    TreeIndex,\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    Response,\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.evaluation import ResponseEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe66f2a",
   "metadata": {},
   "source": [
    "Using GPT-4 here for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b98f89-d5b8-4d29-92f6-ad76d5060e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gpt-4\n",
    "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n",
    "\n",
    "evaluator_gpt4 = ResponseEvaluator(service_context=service_context_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1298bbb4-c99e-431e-93ef-eb32c0a2fc2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./test_wiki_data/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca06a5b-8a15-40b4-8c7f-dae5407c674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.common_tree.base:> Building index from nodes: 3 chunks\n",
      "> Building index from nodes: 3 chunks\n"
     ]
    }
   ],
   "source": [
    "# create tree index\n",
    "tree_index = TreeIndex.from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f0e53f-77a6-40d5-94ae-3f81b01af75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector index\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=ServiceContext.from_defaults(chunk_size=512)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af730b2e-6949-4865-b7af-bb2bc60a9173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define jupyter display function\n",
    "\n",
    "\n",
    "def display_eval_df(response: Response, eval_result: str) -> None:\n",
    "    if response.source_nodes == []:\n",
    "        print(\"no response!\")\n",
    "        return\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Response\": str(response),\n",
    "            \"Source\": response.source_nodes[0].node.text[:1000] + \"...\",\n",
    "            \"Evaluation Result\": eval_result,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Response\", \"Source\"]\n",
    "    )\n",
    "    display(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f486d",
   "metadata": {},
   "source": [
    "To run evaluations you can call the `.evaluate()` function on the `Response` object return from the query to run the evaluations. Lets evaluate the outputs of both the tree_index and vector_index to see if there is any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68c9ebfe-b1b6-4f4e-9278-174346de8c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [4]/[4]\n",
      ">[Level 1] Selected node: [4]/[4]\n"
     ]
    }
   ],
   "source": [
    "query_engine = tree_index.as_query_engine()\n",
    "response_tree = query_engine.query(\n",
    "    \"How did New York City get its name?\"\n",
    ")\n",
    "eval_result = evaluator_gpt4.evaluate(response_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db9d00bc-8428-4a08-b48e-248ad7570923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a35be_row0_col0, #T_a35be_row0_col1 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a35be\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a35be_level0_col0\" class=\"col_heading level0 col0\" >Response</th>\n",
       "      <th id=\"T_a35be_level0_col1\" class=\"col_heading level0 col1\" >Source</th>\n",
       "      <th id=\"T_a35be_level0_col2\" class=\"col_heading level0 col2\" >Evaluation Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a35be_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a35be_row0_col0\" class=\"data row0 col0\" >\n",
       "New York City got its name after the Duke of York (the future King James II and VII), who was given part of the colony by proprietors George Carteret and John Berkeley. The settlement was promptly renamed \"New York\" after the Duke of York.</td>\n",
       "      <td id=\"T_a35be_row0_col1\" class=\"data row0 col1\" >settlement was promptly renamed \"New York\" after the Duke of York (the future King James II and VII), who would eventually be deposed in the Glorious Revolution. After the founding, the duke gave part of the colony to proprietors George Carteret and John Berkeley. Fort Orange, 150 miles (240 km) north on the Hudson River, was renamed Albany after James's Scottish title. The transfer was confirmed in 1667 by the Treaty of Breda, which concluded the Second Anglo-Dutch War.On August 24, 1673, during the Third Anglo-Dutch War, Dutch captain Anthony Colve seized the colony of New York from the English at the behest of Cornelis Evertsen the Youngest and rechristened it \"New Orange\" after William III, the Prince of Orange. The Dutch would soon return the island to England under the Treaty of Westminster of November 1674.Several intertribal wars among the Native Americans and some epidemics brought on by contact with the Europeans caused sizeable population losses for the Lenape between the ye...</td>\n",
       "      <td id=\"T_a35be_row0_col2\" class=\"data row0 col2\" >YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2493249870>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_eval_df(response_tree, eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "180a5d2e-9286-477b-9cd0-a5976d18d845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine()\n",
    "response_vector = query_engine.query(\n",
    "    \"How did New York City get its name?\"\n",
    ")\n",
    "eval_result = evaluator_gpt4.evaluate(response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c764b8b3-69b1-4ac8-b88b-3f9e204b8bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ed79a_row0_col0, #T_ed79a_row0_col1 {\n",
       "  inline-size: 600px;\n",
       "  overflow-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ed79a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ed79a_level0_col0\" class=\"col_heading level0 col0\" >Response</th>\n",
       "      <th id=\"T_ed79a_level0_col1\" class=\"col_heading level0 col1\" >Source</th>\n",
       "      <th id=\"T_ed79a_level0_col2\" class=\"col_heading level0 col2\" >Evaluation Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ed79a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ed79a_row0_col0\" class=\"data row0 col0\" >\n",
       "New York City was named in honor of the Duke of York, who would become King James II of England. In 1664, King Charles II appointed the Duke as proprietor of the former territory of New Netherland, including the city of New Amsterdam, when England seized it from Dutch control. The city was then renamed New York in his honor.</td>\n",
       "      <td id=\"T_ed79a_row0_col1\" class=\"data row0 col1\" >a US$1 billion research and education center as a leader the climate crisis.\n",
       "\n",
       "\n",
       "== Etymology ==\n",
       "\n",
       "In 1664, New York was named in honor of the Duke of York, who would become King James II of England. James's elder brother, King Charles II, appointed the Duke as proprietor of the former territory of New Netherland, including the city of New Amsterdam, when England seized it from Dutch control.\n",
       "\n",
       "\n",
       "== History ==\n",
       "\n",
       "\n",
       "=== Early history ===\n",
       "In the pre-Columbian era, the area of present-day New York City was inhabited by Algonquian Native Americans, including the Lenape. Their homeland, known as Lenapehoking, included the present-day areas of Staten Island, Manhattan, the Bronx, the western portion of Long Island (including the areas that would later become the boroughs of Brooklyn and Queens), and the Lower Hudson Valley.The first documented visit into New York Harbor by a European was in 1524 by Italian Giovanni da Verrazzano, an explorer from Florence in the service of the French crown. He claim...</td>\n",
       "      <td id=\"T_ed79a_row0_col2\" class=\"data row0 col2\" >YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2490543460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_eval_df(response_vector, eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50895fe4",
   "metadata": {},
   "source": [
    "## Benchmark on Generated Question\n",
    "\n",
    "Now lets generate a few more questions so that we have more to evaluate with and run a small benchmark. In practic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90a8cd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.indices.service_context:chunk_size_limit is deprecated, please specify chunk_size instead\n",
      "chunk_size_limit is deprecated, please specify chunk_size instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is the population of New York City as of 2020?',\n",
       " 'Which borough of New York City has the highest population?',\n",
       " 'What is the economic significance of New York City?',\n",
       " 'How did New York City get its name?',\n",
       " 'What is the significance of the Statue of Liberty in New York City?']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.evaluation import DatasetGenerator\n",
    "\n",
    "question_generator = DatasetGenerator.from_documents(documents)\n",
    "eval_questions = question_generator.generate_questions_from_nodes(5)\n",
    "\n",
    "eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "810ee913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "def evaluate_query_engine(query_engine, questions):\n",
    "    c = [query_engine.aquery(q) for q in questions]\n",
    "    results = asyncio.run(asyncio.gather(*c))\n",
    "    print(\"finished query\")\n",
    "\n",
    "    total_correct = 0\n",
    "    for r in results:\n",
    "        # evaluate with gpt 4\n",
    "        eval_result = 1 if evaluator_gpt4.evaluate(r) == \"YES\" else 0\n",
    "        total_correct += eval_result\n",
    "\n",
    "    return total_correct, len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7ca4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=681 request_id=f587e4f416ad0d995a4400bc0a3be400 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=681 request_id=f587e4f416ad0d995a4400bc0a3be400 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1128 request_id=9af1677bef53dc66d8824900c8958b27 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1128 request_id=9af1677bef53dc66d8824900c8958b27 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2529 request_id=a58de27cf52038d452c2df03dd9251cb response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2529 request_id=a58de27cf52038d452c2df03dd9251cb response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=3697 request_id=431e660bf0414265427e4a9728ac9d49 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=3697 request_id=431e660bf0414265427e4a9728ac9d49 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4373 request_id=7950dfcc95958d4f77f42f894a95f814 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=4373 request_id=7950dfcc95958d4f77f42f894a95f814 response_code=200\n",
      "finished query\n",
      "score: 4/5\n"
     ]
    }
   ],
   "source": [
    "vector_query_engine = vector_index.as_query_engine()\n",
    "correct, total = evaluate_query_engine(vector_query_engine, eval_questions[:5])\n",
    "\n",
    "print(f\"score: {correct}/{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "983503e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [1]/[1]\n",
      ">[Level 1] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [2]/[2]\n",
      ">[Level 1] Selected node: [2]/[2]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [3]/[3]\n",
      ">[Level 0] Selected node: [3]/[3]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [5]/[5]\n",
      ">[Level 1] Selected node: [5]/[5]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [1]/[1]\n",
      ">[Level 0] Selected node: [1]/[1]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [4]/[4]\n",
      ">[Level 1] Selected node: [4]/[4]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 0] Selected node: [2]/[2]\n",
      ">[Level 0] Selected node: [2]/[2]\n",
      "INFO:llama_index.indices.tree.select_leaf_retriever:>[Level 1] Selected node: [6]/[6]\n",
      ">[Level 1] Selected node: [6]/[6]\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=986 request_id=61f22f53224cc69e668a3cd0a0481e55 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=986 request_id=61f22f53224cc69e668a3cd0a0481e55 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1856 request_id=1a8bda32900f3479b502478a05e393fb response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=1856 request_id=1a8bda32900f3479b502478a05e393fb response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2182 request_id=028285e91044f7a6aa3f6111a2939d64 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2182 request_id=028285e91044f7a6aa3f6111a2939d64 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2263 request_id=48b050e0379258a500502520b062f4f1 response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=2263 request_id=48b050e0379258a500502520b062f4f1 response_code=200\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=9699 request_id=df7b807d143c1d89fbdd62cdd8874add response_code=200\n",
      "message='OpenAI API response' path=https://api.openai.com/v1/completions processing_ms=9699 request_id=df7b807d143c1d89fbdd62cdd8874add response_code=200\n",
      "finished query\n",
      "score: 2/5\n"
     ]
    }
   ],
   "source": [
    "tree_query_engine = tree_index.as_query_engine()\n",
    "correct, total = evaluate_query_engine(tree_query_engine, eval_questions[:5])\n",
    "\n",
    "print(f\"score: {correct}/{total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
