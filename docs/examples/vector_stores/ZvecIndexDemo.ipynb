{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "600e8429",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/vector_stores/DashvectorIndexDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
   "metadata": {},
   "source": [
    "# Zvec Vector Store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47bbdd33",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-zvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48af8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "import openai\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.zvec import ZvecVectorStore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b00ea0d",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
   "metadata": {},
   "source": [
    "#### Load documents, build the ZvecVectorStore and VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1558b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "vector_store = ZvecVectorStore(\n",
    "    path=\"zvec_demo.zvec\", collection_name=\"zvec_demo\", embed_dim=384\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04304299-fc3e-40a0-8600-f50c3292767e",
   "metadata": {},
   "source": [
    "#### Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = index.as_retriever()\n",
    "# search\n",
    "source_nodes = vector_retriever.retrieve(\"What did the author do growing up?\")\n",
    "# check source_nodes\n",
    "for node in source_nodes:\n",
    "    print(f\"---------------------------------------------\")\n",
    "    print(\"Search Test\")\n",
    "    print(f\"---------------------------------------------\")\n",
    "    print(f\"Score: {node.score:.3f}\")\n",
    "    print(node.get_content())\n",
    "    print(f\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35369eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681357e5",
   "metadata": {},
   "source": [
    "### Metadata filter example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab1308",
   "metadata": {},
   "source": [
    "It is possible to narrow down the search space by filter with metadata. Below is an example to show that in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import Document\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.zvec import ZvecVectorStore\n",
    "\n",
    "test_documents = [\n",
    "    Document(\n",
    "        text=\"Artificial intelligence is a branch of computer science that aims to create software or machines that exhibit human-like intelligence.\",\n",
    "        metadata={\n",
    "            \"title\": \"Introduction to Artificial Intelligence\",\n",
    "            \"author\": \"Dr. Smith\",\n",
    "            \"category\": \"Technology\",\n",
    "            \"year\": 2023,\n",
    "        },\n",
    "        id_=\"ai_intro_001\",\n",
    "    ),\n",
    "    Document(\n",
    "        text=\"Machine learning is a method of data analysis that automates analytical model building.\",\n",
    "        metadata={\n",
    "            \"title\": \"Understanding Machine Learning\",\n",
    "            \"author\": \"Prof. Johnson\",\n",
    "            \"category\": \"Technology\",\n",
    "            \"year\": 2024,\n",
    "        },\n",
    "        id_=\"ml_basics_002\",\n",
    "    ),\n",
    "    Document(\n",
    "        text=\"Big data refers to extremely large datasets that can be analyzed computationally to reveal patterns and trends.\",\n",
    "        metadata={\n",
    "            \"title\": \"Big Data Concepts\",\n",
    "            \"author\": \"Analyst Wilson\",\n",
    "            \"category\": \"Business\",\n",
    "            \"year\": 2023,\n",
    "        },\n",
    "        id_=\"big_data_003\",\n",
    "    ),\n",
    "    Document(\n",
    "        text=\"Blockchain is a system of recording information in a way that makes it difficult to change or hack.\",\n",
    "        metadata={\n",
    "            \"title\": \"Blockchain Technology Overview\",\n",
    "            \"author\": \"Expert Taylor\",\n",
    "            \"category\": \"Finance\",\n",
    "            \"year\": 2024,\n",
    "        },\n",
    "        id_=\"blockchain_004\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "metadata = {\n",
    "    \"title\": \"str\",\n",
    "    \"author\": \"str\",\n",
    "    \"category\": \"str\",\n",
    "    \"year\": \"int\",\n",
    "}\n",
    "\n",
    "vector_store = ZvecVectorStore(\n",
    "    path=\"zvec_filter_demo.zvec\",\n",
    "    collection_name=\"zvec_filter_demo\",\n",
    "    embed_dim=384,\n",
    "    collection_metadata=metadata,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    test_documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224412cf",
   "metadata": {},
   "source": [
    "Define the metadata filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    ExactMatchFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[ExactMatchFilter(key=\"category\", value=\"Technology\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84040560",
   "metadata": {},
   "source": [
    "Use the index as a retriever to use the metadatafilter option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bf01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(filters=filters)\n",
    "retriever.retrieve(\"What is computationally about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416f384",
   "metadata": {},
   "source": [
    "### Query Index with Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e286f",
   "metadata": {},
   "source": [
    "Use hybrid search with bm25 and vector.  \n",
    "`alpha` parameter determines weighting (alpha = 0 -> bm25, alpha=1 -> vector search).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.zvec import ZvecVectorStore\n",
    "\n",
    "vector_store = ZvecVectorStore(\n",
    "    path=\"zvec_hybrid_demo.zvec\",\n",
    "    collection_name=\"zvec_hybrid_demo\",\n",
    "    embed_dim=384,\n",
    "    support_sparse_vector=True,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3cea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    vector_store_query_mode=\"hybrid\", alpha=0.7\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"What did the author do growing up?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92544798",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
