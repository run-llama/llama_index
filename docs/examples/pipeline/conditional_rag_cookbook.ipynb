{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a7916e-5c8f-41d5-a188-7c1cd0aea568",
   "metadata": {},
   "source": [
    "# Conditional RAG Cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67888167-75ed-41b1-bd13-ef9a7d3f9f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ To view the Phoenix app in your browser, visit http://127.0.0.1:6006/\n",
      "ðŸ“º To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "ðŸ“– For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "# setup Arize Phoenix for logging/observability\n",
    "import phoenix as px\n",
    "\n",
    "px.launch_app()\n",
    "import llama_index\n",
    "\n",
    "llama_index.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef003883-4323-4a7a-9956-b3ce2aa57f7e",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371eb814-0037-424b-99b1-2af307f1e6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-08 18:06:00--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: â€˜pg_essay.txtâ€™\n",
      "\n",
      "pg_essay.txt        100%[===================>]  73.28K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-02-08 18:06:00 (6.68 MB/s) - â€˜pg_essay.txtâ€™ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt' -O pg_essay.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e002b608-ccc7-4fa2-a4d5-c315b16c834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(\"../data/paul_graham\")\n",
    "docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97dfc9f-3d0c-4069-a8c7-02055c62019c",
   "metadata": {},
   "source": [
    "## Build Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31374b8c-b096-43a3-9992-aa3b4af14035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SummaryIndex,\n",
    "    load_index_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc9e98a-a702-4ada-9b5f-7be5e80e7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.storage import StorageContext\n",
    "\n",
    "if not os.path.exists(\"storage\"):\n",
    "    index = VectorStoreIndex.from_documents(docs)\n",
    "    # save index to disk\n",
    "    index.set_index_id(\"vector_index\")\n",
    "    index.storage_context.persist(\"./storage\")\n",
    "else:\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"storage\")\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context, index_id=\"vector_index\")\n",
    "\n",
    "\n",
    "summary_index = SummaryIndex.from_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18e34ff-18d1-4f49-b7a2-52fd18b189a7",
   "metadata": {},
   "source": [
    "## Demonstrate Routing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b348b374-f28c-4010-bd3c-5ef31587ab99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ConditionalLinks' from 'llama_index.query_pipeline' (/Users/jerryliu/Programming/gpt_index/llama_index/query_pipeline/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_pipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QueryPipeline, InputComponent, Link, ConditionalLinks, FunctionComponent\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMSingleSelector\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ConditionalLinks' from 'llama_index.query_pipeline' (/Users/jerryliu/Programming/gpt_index/llama_index/query_pipeline/__init__.py)"
     ]
    }
   ],
   "source": [
    "from llama_index.query_pipeline import QueryPipeline, InputComponent, Link, ConditionalLinks, FunctionComponent\n",
    "from llama_index.selectors import LLMSingleSelector\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9aa30-7009-4923-abf2-5e8f26b09b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [\n",
    "    \"This tool answers specific questions about the document (not summary questions across the document)\",\n",
    "    \"This tool answers summary questions about the document (not specific questions)\",\n",
    "]\n",
    "\n",
    "def select_choice(query: str) -> Dict:\n",
    "    selector = LLMSingleSelector.from_defaults()\n",
    "    output = selector.select(choices, query)\n",
    "    return {\"query\": query, \"index\": output.ind}\n",
    "\n",
    "qp = QueryPipeline(modules={\n",
    "    \"input\": InputComponent(),\n",
    "    \"selector\": FunctionComponent(fn=select_choice),\n",
    "    \"vector_query_engine\": vector_query_engine,\n",
    "    \"summary_query_engine\": summary_query_engine\n",
    "})\n",
    "\n",
    "qp.add_link(\"input\", \"selector\")\n",
    "qp.add_conditional_links(\n",
    "    \"selector\", \n",
    "    lambda x: (x[\"index\"], x[\"query\"]),\n",
    "    {\n",
    "        0: vector_query_engine,\n",
    "        1: summary_query_engine\n",
    "    }   \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
