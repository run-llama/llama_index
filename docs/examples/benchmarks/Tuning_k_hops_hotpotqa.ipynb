{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6O-cstGrYsc4",
   "metadata": {},
   "source": [
    "# ü¶ô Using `MultiStepQueryEngine`: Tuning Context (k) vs. Hops with Arize Phoenix\n",
    "\n",
    "**Objective:**\n",
    "This notebook optimizes the LlamaIndex `MultiStepQueryEngine` for complex reasoning tasks. We perform a sensitivity analysis using a **subset of the HotpotQA dataset ** to understand the trade-offs between retrieval depth and reasoning steps.\n",
    "\n",
    "**Tools Used:**\n",
    "* **Engine:** `MultiStepQueryEngine` (Sequential multi-hop reasoning)\n",
    "* **Dataset:** HotpotQA (Wiki-based complex QA)\n",
    "* **Observability:** Arize Phoenix (Trace analysis & Evaluation)\n",
    "\n",
    "**The Experiment:**\n",
    "We sweep through different values of `similarity_top_k` (context amount) and `num_steps` (reasoning depth) to find the \"sweet spot\" where the agent answers correctly without unnecessary latency.\n",
    "\n",
    "**Results:**\n",
    "Model: llama3.2:3b\n",
    "Samples: 30\n",
    "Scores (your scores may vary)\n",
    "--- FINAL GRID SEARCH RESULTS ---\n",
    "|   Hops |    1 |    3 |    5 |\n",
    "|-------:|-----:|-----:|-----:|\n",
    "|      1 | 2.50 | 3.67 | 4.03 |\n",
    "|      2 | 3.00 | 3.90 | 3.07 |\n",
    "|      3 | 2.90 | 3.23 | 3.53 |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NgF_xT9EmCOj",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup\n",
    "\n",
    "We begin by installing the necessary libraries. This includes:\n",
    "* **`llama-index`**: The framework for building our Agentic RAG system.\n",
    "* **`arize-phoenix`**: For observability, tracing, and evaluation.\n",
    "* **`pandas`**: For analyzing the benchmark results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6e3b2-db3b-48fb-9d30-dc288df48ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /usr/local/lib/python3.12/dist-packages (0.14.10)\n",
      "Requirement already satisfied: llama-index-llms-google-genai in /usr/local/lib/python3.12/dist-packages (0.8.2)\n",
      "Requirement already satisfied: llama-index-embeddings-google-genai in /usr/local/lib/python3.12/dist-packages (0.3.1)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
      "Requirement already satisfied: arize-phoenix in /usr/local/lib/python3.12/dist-packages (12.25.1)\n",
      "Requirement already satisfied: openinference-instrumentation-llama-index in /usr/local/lib/python3.12/dist-packages (4.3.9)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
      "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.10 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.14.10)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.9.4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.6.12)\n",
      "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.5)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: google-genai<2,>=1.52.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-google-genai) (1.54.0)\n",
      "Requirement already satisfied: pillow>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-google-genai) (11.3.0)\n",
      "Requirement already satisfied: ollama>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-ollama) (0.6.1)\n",
      "Requirement already satisfied: aioitertools in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.13.0)\n",
      "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.21.0)\n",
      "Requirement already satisfied: alembic<2,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.17.2)\n",
      "Requirement already satisfied: arize-phoenix-client>=1.27.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.27.0)\n",
      "Requirement already satisfied: arize-phoenix-evals>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.7.1)\n",
      "Requirement already satisfied: arize-phoenix-otel>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.14.0)\n",
      "Requirement already satisfied: authlib in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.6.5)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (6.2.2)\n",
      "Requirement already satisfied: email-validator in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.3.0)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.118.3)\n",
      "Requirement already satisfied: grpc-interceptor in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.15.4)\n",
      "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.76.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.28.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (3.1.6)\n",
      "Requirement already satisfied: jmespath in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.0.1)\n",
      "Requirement already satisfied: ldap3 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.9.1)\n",
      "Requirement already satisfied: numpy!=2.0.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.0.2)\n",
      "Requirement already satisfied: openinference-instrumentation>=0.1.32 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.1.42)\n",
      "Requirement already satisfied: openinference-semantic-conventions>=0.1.20 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.1.25)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.60b1)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (3.11.5)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.23.1)\n",
      "Requirement already satisfied: protobuf>=4.25.8 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (5.29.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (5.9.5)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (18.1.0)\n",
      "Requirement already satisfied: pydantic>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.12.3)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.9.0.post0)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.0.20)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.16.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (2.0.44)\n",
      "Requirement already satisfied: sqlean-py>=3.45.1 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (3.50.4.5)\n",
      "Requirement already satisfied: starlette in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.48.0)\n",
      "Requirement already satisfied: strawberry-graphql==0.270.1 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.270.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (4.15.0)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.38.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.17.2 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.17.3)\n",
      "Requirement already satisfied: graphql-core<3.4.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from strawberry-graphql==0.270.1->arize-phoenix) (3.2.7)\n",
      "Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.12/dist-packages (from strawberry-graphql==0.270.1->arize-phoenix) (25.0)\n",
      "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.12/dist-packages (from openinference-instrumentation-llama-index) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in /usr/local/lib/python3.12/dist-packages (from openinference-instrumentation-llama-index) (0.60b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic<2,>=1.3.0->arize-phoenix) (1.3.10)\n",
      "Requirement already satisfied: jsonpath-ng in /usr/local/lib/python3.12/dist-packages (from arize-phoenix-evals>=2.7.1->arize-phoenix) (1.7.0)\n",
      "Requirement already satisfied: pystache in /usr/local/lib/python3.12/dist-packages (from arize-phoenix-evals>=2.7.1->arize-phoenix) (0.6.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (4.12.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (2.43.0)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2,>=1.52.0->llama-index-llms-google-genai) (15.0.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->arize-phoenix) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->arize-phoenix) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->arize-phoenix) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->arize-phoenix) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.2.0)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.11.5)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (3.6.1)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.5.1)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (80.9.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.12.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.9.0)\n",
      "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.9.0)\n",
      "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: pypdf<7,>=6.1.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.4.2)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2025.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.0->arize-phoenix) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.0->arize-phoenix) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.0->arize-phoenix) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->arize-phoenix) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=2.0.4->sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (3.3.0)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib->arize-phoenix) (43.0.3)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator->arize-phoenix) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->arize-phoenix) (3.0.3)\n",
      "Requirement already satisfied: pyasn1>=0.4.6 in /usr/local/lib/python3.12/dist-packages (from ldap3->arize-phoenix) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api->openinference-instrumentation-llama-index) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.39.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp->arize-phoenix) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.39.1->opentelemetry-exporter-otlp->arize-phoenix) (1.39.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->arize-phoenix) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai<2,>=1.52.0->llama-index-llms-google-genai) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api->openinference-instrumentation-llama-index) (3.23.0)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.2)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib->arize-phoenix) (2.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.26.1)\n",
      "Requirement already satisfied: ply in /usr/local/lib/python3.12/dist-packages (from jsonpath-ng->arize-phoenix-evals>=2.7.1->arize-phoenix) (3.11)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix) (2.23)\n",
      "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install llama-index llama-index-llms-google-genai llama-index-embeddings-google-genai llama-index-llms-ollama arize-phoenix openinference-instrumentation-llama-index pandas python-dotenv datasets nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6082b2-960c-4586-b45d-e16bfe5a39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from datasets import load_dataset\n",
    "from llama_index.core import Document, VectorStoreIndex, Settings\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.core.evaluation import CorrectnessEvaluator\n",
    "from llama_index.core.query_engine import MultiStepQueryEngine\n",
    "from llama_index.core.indices.query.query_transform import (\n",
    "    StepDecomposeQueryTransform,\n",
    ")\n",
    "\n",
    "import phoenix as px\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uice87CqmbjY",
   "metadata": {},
   "source": [
    "## 2.  Configuration (API Keys)\n",
    "\n",
    "The below cell uses the Google Colab Secrets feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2fbc3-4906-4cd1-8274-60366a70e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "\n",
    "# Uncomment if your\n",
    "# load_dotenv()\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "\n",
    "# comment the following out if using load_dotenv\n",
    "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
    "HF_TOKEN = userdata.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wm2YGcDnmrfF",
   "metadata": {},
   "source": [
    "## 3. Helper Function for embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82c9b0-02f7-45e9-9252-aacd5d5e0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_global_settings():\n",
    "    \"\"\"\n",
    "    Sets up the Embedding model globally.\n",
    "    We use Google Embeddings for ALL runs to ensure retrieval quality is consistent.\n",
    "    \"\"\"\n",
    "    print(\"üåç Setting up Global Embeddings (Google text-embedding-004)...\")\n",
    "    Settings.embed_model = GoogleGenAIEmbedding(\n",
    "        model_name=\"models/text-embedding-004\", api_key=GEMINI_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VQypQlQioKlj",
   "metadata": {},
   "source": [
    "## 4. Function for prepping the data\n",
    "\n",
    "* Uses hotpotqa dataset from HuggingFace\n",
    "* The dataset is suited for Multi Hop reasoning unlike standard QA tasks where the answer is contained in a single document.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd0f3f-1b98-4c5e-9b32-5e3713df08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA PREP (Run Once) ---\n",
    "def load_and_prep_data(num_samples=5):\n",
    "    \"\"\"Loads HotpotQA data and returns Documents and Ground Truth list.\"\"\"\n",
    "    if str(num_samples).upper() == \"ALL\":\n",
    "        print(\"üì• Downloading ALL samples...\")\n",
    "        split = \"validation\"\n",
    "    else:\n",
    "        print(f\"üì• Downloading top {num_samples} samples...\")\n",
    "        split = f\"validation[:{num_samples}]\"\n",
    "\n",
    "    dataset = load_dataset(\"hotpot_qa\", \"distractor\", split=split)\n",
    "    documents = []\n",
    "    ground_truth = []\n",
    "\n",
    "    for row in dataset:\n",
    "        titles = row[\"context\"][\"title\"]\n",
    "        sentences_list = row[\"context\"][\"sentences\"]\n",
    "        for title, sentences in zip(titles, sentences_list):\n",
    "            doc = Document(\n",
    "                text=f\"Title: {title}\\nContent: {''.join(sentences)}\",\n",
    "                metadata={\"title\": title, \"question_id\": row[\"id\"]},\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        ground_truth.append(\n",
    "            {\"question\": row[\"question\"], \"reference_answer\": row[\"answer\"]}\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"‚úÖ Loaded {len(documents)} docs from {len(ground_truth)} questions.\"\n",
    "    )\n",
    "    return documents, ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rl5a36ekpeS3",
   "metadata": {},
   "source": [
    "## 5. Helper Function to initialize LLM instance\n",
    "\n",
    "Here there's 2 options for the model_name, the test of 30 samples with results at the beginning was done with:\n",
    "\n",
    "model_name = \"llama3.2:3b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8484e63-3a5e-4fde-a57d-c6d6ae1e6920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DYNAMIC LLM FACTORY ---\n",
    "def get_student_llm(model_name):\n",
    "    \"\"\"\n",
    "    Creates a FRESH instance of the LLM for every single question.\n",
    "    This ensures no 'context' or 'memory' leaks between benchmark questions.\n",
    "    \"\"\"\n",
    "    # Option A: Google Gemini\n",
    "    if \"gemini\" in model_name.lower():\n",
    "        return GoogleGenAI(\n",
    "            model=model_name, temperature=0, api_key=GEMINI_API_KEY\n",
    "        )\n",
    "\n",
    "    # Option B: Local Ollama\n",
    "    else:\n",
    "        # request_timeout=300 protects against slow local generations\n",
    "        return Ollama(model=model_name, request_timeout=300.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6Cn0z3PBYlAD",
   "metadata": {},
   "source": [
    "## 6. Function to execute a full evaluation pass on all data samples.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d649141-8768-43c7-8c7c-e880d542e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BENCHMARK ENGINE ---\n",
    "def run_benchmark_iteration(index, data_samples, k, hops, model_name):\n",
    "    \"\"\"\n",
    "    Runs a benchmark pass where the LLM is reset for every question.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüß™ STARTING RUN: k={k} | hops={hops} | model={model_name}\")\n",
    "\n",
    "    # Initialize Judge ONCE\n",
    "    judge_llm = GoogleGenAI(\n",
    "        model=\"models/gemini-2.5-pro\", temperature=0.0, api_key=GEMINI_API_KEY\n",
    "    )\n",
    "    evaluator = CorrectnessEvaluator(llm=judge_llm)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for i, sample in enumerate(data_samples):\n",
    "        try:\n",
    "            # A. FRESH LLM INSTANCE\n",
    "            student_llm = get_student_llm(model_name)\n",
    "\n",
    "            # --- FIX: SET GLOBAL SETTINGS FOR THIS ITERATION ---\n",
    "            Settings.llm = student_llm\n",
    "            # ---------------------------------------------------\n",
    "\n",
    "            # B. Configure Base Engine (k)\n",
    "            base_query_engine = index.as_query_engine(\n",
    "                similarity_top_k=k, llm=student_llm\n",
    "            )\n",
    "\n",
    "            # C. Configure Logic (Hops)\n",
    "            if hops > 1:\n",
    "                step_decompose = StepDecomposeQueryTransform(\n",
    "                    llm=student_llm, verbose=True\n",
    "                )\n",
    "                query_engine = MultiStepQueryEngine(\n",
    "                    query_engine=base_query_engine,\n",
    "                    query_transform=step_decompose,\n",
    "                    index_summary=\"Contains detailed encyclopedia articles about specific people, places, and things. RESTRICTION: This search engine CANNOT compare items. You must query for one entity at a time. If the user asks for a comparison, break it down into single questions about each entity.\",\n",
    "                    num_steps=hops,\n",
    "                    early_stopping=True,\n",
    "                )\n",
    "            else:\n",
    "                query_engine = base_query_engine\n",
    "\n",
    "            # D. Run Query\n",
    "            response = query_engine.query(sample[\"question\"])\n",
    "\n",
    "            # E. Evaluate\n",
    "            eval_result = evaluator.evaluate(\n",
    "                query=sample[\"question\"],\n",
    "                response=response.response,\n",
    "                reference=sample[\"reference_answer\"],\n",
    "            )\n",
    "            scores.append(eval_result.score)\n",
    "\n",
    "            # F. Rate Limit Safety\n",
    "            time.sleep(1.0)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error on sample {i}: {e}\")\n",
    "            scores.append(0.0)\n",
    "\n",
    "    avg_score = sum(scores) / len(scores) if scores else 0\n",
    "    print(f\"üèÅ END RUN: Score: {avg_score:.2f}\")\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dEcDMcoQrNqt",
   "metadata": {},
   "source": [
    "## 6. Function that loops through k and hops (nested)\n",
    "\n",
    "And instruments in Arize Phoenix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e3d2d-75aa-4367-beae-f1d3f1926c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GRID SEARCH CONTROLLER ---\n",
    "def run_grid_search(index, data_samples, max_k, max_hops, model_name):\n",
    "    \"\"\"\n",
    "    Grid search loop. Note: We now pass in the index and data,\n",
    "    so we don't reload them every time.\n",
    "    \"\"\"\n",
    "    k_values = range(1, max_k + 1, 2)\n",
    "    hop_values = range(1, max_hops + 1)\n",
    "\n",
    "    all_results = []\n",
    "    total_combinations = len(k_values) * len(hop_values)\n",
    "\n",
    "    print(\n",
    "        f\"\\nüöÄ Starting Grid Search over {total_combinations} combinations...\"\n",
    "    )\n",
    "\n",
    "    for hops in hop_values:\n",
    "        for k in k_values:\n",
    "            # 1. DEFINE DYNAMIC PROJECT NAME\n",
    "            current_project = datetime.now().strftime(\n",
    "                f\"run-grid-k{k}-hops{hops}-%Y-%m-%d-%H-%M\"\n",
    "            )\n",
    "            print(f\"üîÑ Switching Phoenix Project to: {current_project}\")\n",
    "\n",
    "            # 2. RESET INSTRUMENTATION\n",
    "            LlamaIndexInstrumentor().uninstrument()\n",
    "\n",
    "            # 3. REGISTER NEW TRACER\n",
    "            tracer_provider = register(\n",
    "                project_name=current_project,\n",
    "                endpoint=\"http://localhost:6006/v1/traces\",\n",
    "            )\n",
    "\n",
    "            # 4. RE-INSTRUMENT\n",
    "            LlamaIndexInstrumentor().instrument(\n",
    "                tracer_provider=tracer_provider\n",
    "            )\n",
    "\n",
    "            # 5. RUN ITERATION\n",
    "            score = run_benchmark_iteration(\n",
    "                index, data_samples, k, hops, model_name\n",
    "            )\n",
    "\n",
    "            all_results.append({\"Hops\": hops, \"Top-k\": k, \"Score\": score})\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "\n",
    "    print(\"\\nüèÜ --- FINAL GRID SEARCH RESULTS ---\")\n",
    "    if not df.empty:\n",
    "        pivot_df = df.pivot(index=\"Hops\", columns=\"Top-k\", values=\"Score\")\n",
    "        print(pivot_df.to_markdown(floatfmt=\".2f\"))\n",
    "\n",
    "    csv_filename = f\"grid_results_{model_name.replace(':','-')}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"\\nüíæ Results saved to '{csv_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sdbLWSDVsanz",
   "metadata": {},
   "source": [
    "\n",
    "This replaces the standard arguments in a command line.\n",
    "\n",
    "Replace with the parameters of your choice.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f01e42-6eb5-479f-8510-0ac0f9d72a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to simulate arguments\n",
    "class args:\n",
    "    mode = \"single\"\n",
    "    k = 1\n",
    "    hops = 1\n",
    "    num_samples = \"1\"\n",
    "    model = \"gemini-2.5-flash-lite\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46i5Q0n-YiJi",
   "metadata": {},
   "source": [
    "\n",
    "Importing nest_asyncio to get around the known issue of aync event loops run by Jupyter.\n",
    "\n",
    "Llama-index and Arizer Phoenix using async and thus would run into a bug without the nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yM3FzkViEt-f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:phoenix.session.session:Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit https://0rhnsdbge17a5-496ff2e9c6d22116-6006-colab.googleusercontent.com/\n",
      "üìñ For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n",
      "üåç Setting up Global Embeddings (Google text-embedding-004)...\n",
      "üì• Downloading top 1 samples...\n",
      "‚úÖ Loaded 10 docs from 1 questions.\n",
      "\n",
      "‚öôÔ∏è  Building Master Index (Reused for all runs)...\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "# This allows nested event loops (fixes the \"asyncio.run()\" error)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "session = px.launch_app()\n",
    "# if you want to see the Arize Phoenix Dashboard\n",
    "# session = px.active_session()\n",
    "# session.view()\n",
    "\n",
    "# --- A. CONSOLIDATED SETUP (RUNS ONCE FOR BOTH MODES) ---\n",
    "configure_global_settings()\n",
    "\n",
    "# Load Data & Prep Index\n",
    "# This is now done exactly once, regardless of mode.\n",
    "documents, data_samples = load_and_prep_data(args.num_samples)\n",
    "\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  Building Master Index (Reused for all runs)...\")\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XMmw4gk6vJRQ",
   "metadata": {},
   "source": [
    "Execute one run for k X hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4RVHnXZoFIRC",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting Grid Search over 1 combinations...\n",
      "üîÑ Switching Phoenix Project to: run-grid-k1-hops1-2025-12-16-20-04\n",
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: run-grid-k1-hops1-2025-12-16-20-04\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "\n",
      "üß™ STARTING RUN: k=1 | hops=1 | model=gemini-2.5-flash-lite\n",
      "üèÅ END RUN: Score: 2.00\n",
      "\n",
      "üèÜ --- FINAL GRID SEARCH RESULTS ---\n",
      "|   Hops |    1 |\n",
      "|-------:|-----:|\n",
      "|      1 | 2.00 |\n",
      "\n",
      "üíæ Results saved to 'grid_results_gemini-2.5-flash-lite.csv'\n"
     ]
    }
   ],
   "source": [
    "# Pass the pre-built index and data to the grid runner\n",
    "run_grid_search(\n",
    "    index,\n",
    "    data_samples,\n",
    "    max_k=args.k,\n",
    "    max_hops=args.hops,\n",
    "    model_name=args.model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Cq1MELUwvaIX",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Execute a singular run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DN4f5IudFLc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n",
      "WARNING:opentelemetry.instrumentation.instrumentor:Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: run-single-k1-hops1-2025-12-16-20-04\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n",
      "\n",
      "üß™ STARTING RUN: k=1 | hops=1 | model=gemini-2.5-flash-lite\n",
      "üèÅ END RUN: Score: 2.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_project = datetime.now().strftime(\n",
    "    f\"run-single-k{args.k}-hops{args.hops}-%Y-%m-%d-%H-%M\"\n",
    ")\n",
    "\n",
    "tracer_provider = register(\n",
    "    project_name=current_project, endpoint=\"http://localhost:6006/v1/traces\"\n",
    ")\n",
    "\n",
    "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)\n",
    "\n",
    "# Run the single iteration\n",
    "run_benchmark_iteration(index, data_samples, args.k, args.hops, args.model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
