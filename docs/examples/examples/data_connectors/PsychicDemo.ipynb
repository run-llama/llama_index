{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c35f3c4",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/data_connectors/PsychicDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effeb5a7-8544-4ee4-8c11-bad0d8165394",
   "metadata": {},
   "source": [
    "# Psychic Reader\n",
    "Demonstrates the Psychic data connector. Used to query data from many SaaS tools from a single LlamaIndex-compatible API.\n",
    "\n",
    "## Prerequisites\n",
    "Connections must first be established from the Psychic dashboard or React hook before documents can be loaded. Refer to https://docs.psychic.dev/ for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44112ead",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-readers-psychic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995afc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1f66d-10ed-4417-bdcb-f8a894836ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.readers.psychic import PsychicReader\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90589a-fb44-4ec6-9706-753dba4fa968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Psychic API key from https://dashboard.psychic.dev/api-keys\n",
    "psychic_key = \"PSYCHIC_API_KEY\"\n",
    "# Connector ID and Account ID are typically set programmatically based on the application state.\n",
    "account_id = \"ACCOUNT_ID\"\n",
    "connector_id = \"notion\"\n",
    "documents = PsychicReader(psychic_key=psychic_key).load_data(\n",
    "    connector_id=connector_id, account_id=account_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464025d-0c5a-4e2d-8a90-91c29ece9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 2383 tokens\n",
      "> [get_response] Total LLM token usage: 2383 tokens\n",
      "> [get_response] Total LLM token usage: 2383 tokens\n",
      "> [get_response] Total LLM token usage: 2383 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Psychic's privacy policy explains how we access, use, store, and share Google user data when you connect your Google Drive or other Google services to our application. By using Psychic, you agree to this Privacy Policy and our Terms of Service. We use the information we collect for the following purposes: to provide you with the Psychic services, including allowing you to access, view, and query files and folders stored in your connected Google Drive; to improve our services, including analyzing usage patterns and troubleshooting issues; and to communicate with you about important updates, promotions, or news related to Psychic. We take the security of your information seriously and implement appropriate security measures to protect it. We may share your information in certain cases, such as with service providers who assist us in providing and maintaining Psychic services, as required by law, or to protect the rights, property, or safety of Psychic, our users, or the public. Psychic provides in-product privacy notifications to inform you about the ways we access, use, store, and share your Google user data. We may update this Privacy Policy from time to time, and your continued use of Psychic after any changes to this Privacy Policy constitutes your acceptance of the updated policy.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set Logging to DEBUG for more detailed outputs\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "index = SummaryIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is Psychic's privacy policy?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c32397a35d2e76e766f80c3872b208f0c0029e8a6a9b8e2a8fe7b1641cfa009b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
