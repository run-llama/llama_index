{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4de6af5c",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/vector_stores/elasticsearch_auto_retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
   "metadata": {},
   "source": [
    "# Auto-Retrieval from a Vector Database\n",
    "\n",
    "This guide shows how to perform **auto-retrieval** in LlamaIndex. \n",
    "\n",
    "Many popular vector dbs support a set of metadata filters in addition to a query string for semantic search. Given a natural language query, we first use the LLM to infer a set of metadata filters as well as the right query string to pass to the vector db (either can also be blank). This overall query bundle is then executed against the vector db.\n",
    "\n",
    "This allows for more dynamic, expressive forms of retrieval beyond top-k semantic search. The relevant context for a given query may only require filtering on a metadata tag, or require a joint combination of filtering + semantic search within the filtered set, or just raw semantic search.\n",
    "\n",
    "We demonstrate an example with Elasticsearch, but auto-retrieval is also implemented with many other vector dbs (e.g. Pinecone, Weaviate, and more)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "We first define imports."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23e46f34",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2397cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fc317",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48af8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf49ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up OpenAI\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa106b-8261-4a01-97c6-1b037dffa1b4",
   "metadata": {},
   "source": [
    "## Defining Some Sample Data\n",
    "\n",
    "We insert some sample nodes containing text chunks into the vector database. Note that each `TextNode` not only contains the text, but also metadata e.g. `category` and `country`. These metadata fields will get converted/stored as such in the underlying vector db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bcc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.elasticsearch import ElasticsearchStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A bunch of scientists bring back dinosaurs and mayhem breaks\"\n",
    "            \" loose\"\n",
    "        ),\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"Leo DiCaprio gets lost in a dream within a dream within a dream\"\n",
    "            \" within a ...\"\n",
    "        ),\n",
    "        metadata={\n",
    "            \"year\": 2010,\n",
    "            \"director\": \"Christopher Nolan\",\n",
    "            \"rating\": 8.2,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A psychologist / detective gets lost in a series of dreams within\"\n",
    "            \" dreams within dreams and Inception reused the idea\"\n",
    "        ),\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=(\n",
    "            \"A bunch of normal-sized women are supremely wholesome and some\"\n",
    "            \" men pine after them\"\n",
    "        ),\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd70be-57c7-49e2-990b-ad9a876710fb",
   "metadata": {},
   "source": [
    "## Build Vector Index with Elasticsearch Vector Store\n",
    "\n",
    "Here we load the data into the vector store. As mentioned above, both the text and metadata for each node will get converted into corresponding representation in Elasticsearch. We can now run semantic queries and also metadata filtering on this data from Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1558b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ElasticsearchStore(\n",
    "    index_name=\"auto_retriever_movies\", es_url=\"http://localhost:9200\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35369eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c793dc45-5087-4dcb-b0d3-85b8e718539f",
   "metadata": {},
   "source": [
    "## Define `VectorIndexAutoRetriever`\n",
    "\n",
    "We define our core `VectorIndexAutoRetriever` module. The module takes in `VectorStoreInfo`,\n",
    "which contains a structured description of the vector store collection and the metadata filters it supports.\n",
    "This information will then be used in the auto-retrieval prompt where the LLM infers metadata filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedbb693-725f-478f-be26-fa7180ea38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexAutoRetriever\n",
    "from llama_index.core.vector_stores import MetadataInfo, VectorStoreInfo\n",
    "\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"Brief summary of a movie\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"genre\",\n",
    "            description=\"The genre of the movie\",\n",
    "            type=\"string or list[string]\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"year\",\n",
    "            description=\"The year the movie was released\",\n",
    "            type=\"integer\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"director\",\n",
    "            description=\"The name of the movie director\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"rating\",\n",
    "            description=\"A 1-10 rating for the movie\",\n",
    "            type=\"float\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "retriever = VectorIndexAutoRetriever(\n",
    "    index, vector_store_info=vector_store_info\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32808a60-7bab-4e9e-944c-cfe2ed0b0e2e",
   "metadata": {},
   "source": [
    "## Running over some sample data\n",
    "\n",
    "We try running over some sample data. Note how metadata filters are inferred - this helps with more precise retrieval! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb18e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.retrieve(\n",
    "    \"What are 2 movies by Christopher Nolan were made before 2020?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f00cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using query str: science fiction\n",
      "Using query str: science fiction\n",
      "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using filters: {'director': 'Andrei Tarkovsky'}\n",
      "Using filters: {'director': 'Andrei Tarkovsky'}\n",
      "INFO:llama_index.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using top_k: 2\n",
      "Using top_k: 2\n",
      "INFO:elastic_transport.transport:POST http://localhost:9200/auto_retriever_movies/_search [status:200 duration:0.042s]\n",
      "POST http://localhost:9200/auto_retriever_movies/_search [status:200 duration:0.042s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.retrieve(\"Has Andrei Tarkovsky directed any science fiction movies\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
