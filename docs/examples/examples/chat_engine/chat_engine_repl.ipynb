{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb508b5",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/chat_engine/chat_engine_repl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80deb2f-f910-4eb4-827a-ebe3cf853fda",
   "metadata": {},
   "source": [
    "# Chat Engine - Simple Mode REPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab32bf",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0019c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f67d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa7de6-9b7c-488d-8390-83501cd49701",
   "metadata": {},
   "source": [
    "### Get started in 3 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd00469-3e73-41f3-ade1-8d9cf3cea8c1",
   "metadata": {},
   "source": [
    "Using GPT3 (\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766a981-abb8-4321-aa88-056ebd35eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hi there! How can I help you?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  Tell me a joke\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Why did the chicken cross the playground?\n",
      "To get to the other slide!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  That's not funny\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I'm sorry you didn't find it funny. Is there something else I can help you with?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  Tell me another one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Why did the scarecrow win the Nobel Prize?\n",
      "Because he was outstanding in his field!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  Still not funny, sing me a song\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Oh, I'm a lumberjack and I'm okay\n",
      "I sleep all night and I work all day\n",
      "I cut down trees, I eat my lunch\n",
      "I go to the lavatory on Wednesday and Saturday\n",
      "Everybody knows my song!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "\n",
    "chat_engine = SimpleChatEngine.from_defaults()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc951f-b8f2-4dbc-b3e0-e56b8044d3a6",
   "metadata": {},
   "source": [
    "### Customize LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2313325-ff21-4fb6-b37f-9210d0d56b8c",
   "metadata": {},
   "source": [
    "Use ChatGPT (\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746ab6f-3157-476b-aec5-3ef9cc76977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537552c-9ef2-4e98-a7cb-e13971ffedfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='gpt-3.5-turbo' temperature=0.0 max_tokens=None additional_kwargs={} max_retries=10\n",
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  Tell me a joke\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Sure, here's a joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  That's not funny\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I apologize if the joke didn't meet your expectations. Humor can be subjective, and what one person finds funny, another may not. Is there anything else I can assist you with?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  Tell me another one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Of course! Here's another joke for you:\n",
      "\n",
      "Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  Still not funny, sing me a song\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Certainly! Here's a little song for you:\n",
      "\n",
      "(Verse 1)\n",
      "In a world of endless possibilities,\n",
      "I'll sing a song to bring you some ease.\n",
      "With melodies that dance upon the air,\n",
      "I hope this tune will show you I care.\n",
      "\n",
      "(Chorus)\n",
      "La la la, a melody so sweet,\n",
      "La la la, let the music take the lead.\n",
      "Close your eyes and let your worries fade,\n",
      "As I sing this song, a serenade.\n",
      "\n",
      "(Verse 2)\n",
      "Through the highs and lows, the ups and downs,\n",
      "I'll sing a song to turn your frown around.\n",
      "With harmonies that lift your spirits high,\n",
      "I hope this melody will make you sigh.\n",
      "\n",
      "(Chorus)\n",
      "La la la, a melody so sweet,\n",
      "La la la, let the music take the lead.\n",
      "Close your eyes and let your worries fade,\n",
      "As I sing this song, a serenade.\n",
      "\n",
      "(Outro)\n",
      "So let the music fill your heart and soul,\n",
      "As I sing this song, let your worries go.\n",
      "May this melody bring you joy and cheer,\n",
      "And remind you that I'm always here.\n",
      "\n",
      "I hope you enjoyed the song! Let me know if there's anything else I can do for you.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "\n",
    "chat_engine = SimpleChatEngine.from_defaults(llm=llm)\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accae591",
   "metadata": {},
   "source": [
    "## Streaming Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62a9f1-ed27-4730-82de-9a89750c08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.0, model=\"gpt-3.5-turbo-0613\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef942f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "\n",
    "chat_engine = SimpleChatEngine.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c69d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world where whimsy takes its flight,\n",
      "Where dreams and reality intertwine,\n",
      "A tale unfolds, both strange and bright,\n",
      "Of raining cats and dogs, so divine.\n",
      "\n",
      "From the heavens, a tempest brews,\n",
      "Clouds gather, dark and thick,\n",
      "And as the wind begins to choose,\n",
      "The sky releases a whimsical trick.\n",
      "\n",
      "Down they fall, with paws and tails,\n",
      "Cats and dogs, in a watery dance,\n",
      "Tiny meows and barks prevail,\n",
      "As they descend in a wild romance.\n",
      "\n",
      "The felines, graceful, land with poise,\n",
      "Their fur glistening, sleek and fine,\n",
      "With eyes that gleam like emerald joys,\n",
      "They prance and purr, in a feline line.\n",
      "\n",
      "The canines, playful, splash and bound,\n",
      "Their wagging tails a joyful sight,\n",
      "With tongues that pant and ears that sound,\n",
      "They frolic and bark, with all their might.\n",
      "\n",
      "Together they create a symphony,\n",
      "A chorus of meows and barks,\n",
      "A spectacle for all to see,\n",
      "As they dance upon the parks.\n",
      "\n",
      "Children giggle, adults stare,\n",
      "Amazed by this peculiar sight,\n",
      "For in this moment, they're all aware,\n",
      "Of the magic raining from the height.\n",
      "\n",
      "And as the storm begins to wane,\n",
      "The cats and dogs return above,\n",
      "Leaving behind a world untamed,\n",
      "A memory of a rain so rare and of love.\n",
      "\n",
      "So, let us cherish this whimsical tale,\n",
      "Of raining cats and dogs, so grand,\n",
      "For in the extraordinary, we prevail,\n",
      "And find enchantment in the palm of our hand."
     ]
    }
   ],
   "source": [
    "response = chat_engine.stream_chat(\n",
    "    \"Write me a poem about raining cats and dogs.\"\n",
    ")\n",
    "for token in response.response_gen:\n",
    "    print(token, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
