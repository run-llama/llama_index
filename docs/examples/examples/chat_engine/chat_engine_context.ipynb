{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616a781c",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/chat_engine/chat_engine_context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18e20fbc-056b-44ac-b1fc-2d34b8e99bcc",
   "metadata": {},
   "source": [
    "\n",
    "# Chat Engine - Context Mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b99eea02-429c-40e4-99be-b82a89c8d070",
   "metadata": {},
   "source": [
    "ContextChatEngine is a simple chat mode built on top of a retriever over your data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34d34fcc-e247-4d55-ab16-c3d633e2385a",
   "metadata": {},
   "source": [
    "For each chat interaction:\n",
    "* first retrieve text from the index using the user message\n",
    "* set the retrieved text as context in the system prompt\n",
    "* return an answer to the user message"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1c3cbc6-98a8-4e0e-98eb-3c7fa09ba79f",
   "metadata": {},
   "source": [
    "This approach is simple, and works for questions directly related to the knowledge base and general interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca364545",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46eb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79db0610",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff623699",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b314f279-bf7f-4e67-9f66-ebf783f08d38",
   "metadata": {},
   "source": [
    "## Get started in 5 lines of code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40d3d9e4",
   "metadata": {},
   "source": [
    "Load data and build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3237c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"API_KEY_HERE\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac125a-79df-452d-9f58-ac4f30997acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "data = SimpleDirectoryReader(input_dir=\"./data/paul_graham/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e58d7ad9-d246-477e-acac-894ad5402f24",
   "metadata": {},
   "source": [
    "Configure chat engine\n",
    "\n",
    "Since the context retrieved can take up a large amount of the available LLM context, let's ensure we configure a smaller limit to the chat history!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ef191-f86a-4ce1-aa9d-64d61f29dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=1500)\n",
    "\n",
    "chat_engine = index.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    memory=memory,\n",
    "    system_prompt=(\n",
    "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
    "        \" about an essay discussing Paul Grahams life.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63a4259d-89b5-49f8-b158-9eba5353d6f5",
   "metadata": {},
   "source": [
    "Chat with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b5bb3-37ff-4886-be2c-264584ca9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_engine.chat(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa4310-4dc5-4787-a073-755d2e0b4887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67021e64-8665-4338-9fb4-c0f1d6361092",
   "metadata": {},
   "source": [
    "Ask a follow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6181319-5d76-48c4-a5d4-23c6e9bc5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_engine.chat(\"What did Paul Graham do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95045f5b-7964-4872-bc91-809d9debf1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Growing up, Paul Graham had a keen interest in writing and programming. He spent a lot of time writing short stories, although he admits that they weren't particularly good. In terms of programming, he started working with computers in 9th grade when he had access to an IBM 1401 computer at his school. He learned an early version of Fortran and experimented with writing programs on punch cards. However, he found it challenging to figure out what to do with the computer since he didn't have much data to work with. It wasn't until microcomputers became available that he truly delved into programming, starting with a kit-built microcomputer called the Heathkit. Eventually, he convinced his father to buy a TRS-80, which allowed him to write simple games, create a word processor, and explore programming further.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc02dd-90b7-4d63-bdb2-e4c4666f87ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_engine.chat(\"Can you tell me more?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8efbb-fcb0-4c58-b92b-d2264a7e7103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! As Paul Graham continued to explore programming, he became fascinated with the possibilities it offered. He enjoyed the process of creating something out of nothing and the logical thinking required in programming. During his high school years, he also developed an interest in painting and considered pursuing it as a career.\n",
      "\n",
      "After high school, Paul Graham attended Cornell University, where he studied philosophy. However, he found himself spending more time programming than studying philosophy. He even started a company called Viaweb with some friends, which aimed to create an online store builder. Viaweb eventually became successful and was acquired by Yahoo in 1998.\n",
      "\n",
      "After the acquisition, Paul Graham moved to California and became a millionaire. However, he soon realized that he was burnt out from the stress of running Viaweb. He decided to leave Yahoo and pursue his passion for painting. He enrolled in the Accademia di Belle Arti in Florence, Italy, to study painting.\n",
      "\n",
      "During his time in Florence, Paul Graham immersed himself in the world of art and painting. He experimented with different techniques and styles, particularly focusing on still life paintings. He found joy in closely observing everyday objects and capturing their details on canvas.\n",
      "\n",
      "After a year in Florence, Paul Graham returned to the United States and worked at a software company called Interleaf. Although he was not particularly enthusiastic about the job, it provided him with a steady income and allowed him to save money to pursue his dream of attending the Rhode Island School of Design (RISD) to further his studies in painting.\n",
      "\n",
      "Overall, Paul Graham's journey from programming to painting reflects his curiosity and willingness to explore different passions. He has found success in both fields and continues to share his insights and experiences through his writings and lectures.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2c68de8-af58-4f7e-8759-19fc072873fd",
   "metadata": {},
   "source": [
    "Reset conversation state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13cf082-1a91-43c5-8bad-76fa45be96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627de435-d195-4dad-b314-a68e731979a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_engine.chat(\"Hello! What do you know?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef9e31-3cdb-4129-92f7-e61be201ea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hi there! I know a lot about Paul Graham's life. He is an entrepreneur, programmer, and investor who is best known for co-founding the venture capital firm Y Combinator. He is also the author of several essays on technology and startups, including the influential essay \"Hackers and Painters\". He has had a long and successful career in the tech industry, and his experiences have shaped his views on entrepreneurship and technology.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a65ad1a2",
   "metadata": {},
   "source": [
    "## Streaming Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad272dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "data = SimpleDirectoryReader(input_dir=\"./data/paul_graham/\").load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22605caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(chat_mode=\"context\", llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250abd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stepping down from his role at Y Combinator (YC), Paul Graham focused on pursuing different interests. Initially, he decided to dedicate his time to painting and see how good he could become with focused practice. He spent most of 2014 painting, but eventually ran out of steam and stopped.\n",
      "\n",
      "Following his break from painting, Graham returned to writing essays and also resumed working on Lisp, a programming language. He delved into the core of Lisp, which involves writing an interpreter in the language itself. Graham continued to write essays and work on Lisp in the years following his departure from YC."
     ]
    }
   ],
   "source": [
    "response = chat_engine.stream_chat(\"What did Paul Graham do after YC?\")\n",
    "for token in response.response_gen:\n",
    "    print(token, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
