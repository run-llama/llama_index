{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b50c4af8-fec3-4396-860a-1322089d76cb",
   "metadata": {},
   "source": [
    "# OpenAI Agent + Query Engine Experimental Cookbook\n",
    "\n",
    "\n",
    "In this notebook, we try out the OpenAIAgent across a variety of query engine tools and datasets. We explore how OpenAIAgent can compare/replace existing workflows solved by our retrievers/query engines.\n",
    "\n",
    "- Auto retrieval \n",
    "- Joint SQL and vector search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db402a8b-90d6-4e1d-8df6-347c54624f26",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AutoRetrieval from a Vector Database\n",
    "\n",
    "Our existing \"auto-retrieval\" capabilities (in `VectorIndexAutoRetriever`) allow an LLM to infer the right query parameters for a vector database - including both the query string and metadata filter.\n",
    "\n",
    "Since the OpenAI Function API can infer function parameters, we explore its capabilities in performing auto-retrieval here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba05c6-a80e-4992-8a90-fd8fadd53587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "\n",
    "api_key = os.environ['PINECONE_API_KEY']\n",
    "pinecone.init(api_key=api_key, environment=\"us-west1-gcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114fd4e-eefd-48d3-b082-1d918c15dfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dimensions are for text-embedding-ada-002\n",
    "try:\n",
    "    pinecone.create_index(\"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\")\n",
    "except Exception:\n",
    "    # most likely index already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b815ed5-d770-4ec4-8e2c-57b5a4c0941c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pinecone_index = pinecone.Index(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889542b-8514-4483-97a6-ff5d032fa75f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional: delete data in your pinecone index\n",
    "pinecone_index.delete(deleteAll=True, namespace=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7764e84-8f0c-4890-9d6a-5d97be6ed1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b32f02-e09a-4cfa-b7ba-fa937bdcec9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(text=\"Michael Jordan is a retired professional basketball player, widely regarded as one of the greatest basketball players of all time.\", metadata={\n",
    "        \"category\": \"Sports\",\n",
    "        \"country\": \"United States\",\n",
    "    }),\n",
    "    TextNode(text=\"Angelina Jolie is an American actress, filmmaker, and humanitarian. She has received numerous awards for her acting and is known for her philanthropic work.\", metadata={\n",
    "        \"category\": \"Entertainment\",\n",
    "        \"country\": \"United States\",\n",
    "    }),\n",
    "    TextNode(text=\"Elon Musk is a business magnate, industrial designer, and engineer. He is the founder, CEO, and lead designer of SpaceX, Tesla, Inc., Neuralink, and The Boring Company.\", metadata={\n",
    "        \"category\": \"Business\",\n",
    "        \"country\": \"United States\",\n",
    "    }),\n",
    "    TextNode(text=\"Rihanna is a Barbadian singer, actress, and businesswoman. She has achieved significant success in the music industry and is known for her versatile musical style.\", metadata={\n",
    "        \"category\": \"Music\",\n",
    "        \"country\": \"Barbados\",\n",
    "    }),\n",
    "    TextNode(text=\"Cristiano Ronaldo is a Portuguese professional footballer who is considered one of the greatest football players of all time. He has won numerous awards and set multiple records during his career.\", metadata={\n",
    "        \"category\": \"Sports\",\n",
    "        \"country\": \"Portugal\",\n",
    "    })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7974714-552d-4297-9cc3-6497409496e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index, namespace='test')\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3fff1-974f-4a72-8f09-874e61c54230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b557703-3587-41c6-a85b-949094344ca8",
   "metadata": {},
   "source": [
    "#### Define Function Tool\n",
    "\n",
    "Here we define the function interface, which is passed to OpenAI to perform auto-retrieval.\n",
    "\n",
    "We were not able to get OpenAI to work with nested pydantic objects or tuples as arguments,\n",
    "so we converted the metadata filter keys and values into lists for the function API to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b467e-b924-4994-9011-86ab98167545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define function tool\n",
    "from llama_index.tools import FunctionTool\n",
    "from llama_index.vector_stores.types import VectorStoreInfo, MetadataInfo, ExactMatchFilter, MetadataFilters\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from typing import List, Tuple, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# hardcode top k for now\n",
    "top_k = 3\n",
    "\n",
    "# define vector store info describing schema of vector store\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info='brief biography of celebrities',\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name='category', \n",
    "            type='str', \n",
    "            description='Category of the celebrity, one of [Sports, Entertainment, Business, Music]'),\n",
    "        MetadataInfo(name='country', type='str', description='Country of the celebrity, one of [United States, Barbados, Portugal]'),\n",
    "    ]\n",
    ")\n",
    "    \n",
    "# define pydantic model for auto-retrieval function\n",
    "class AutoRetrieveModel(BaseModel):\n",
    "    query: str = Field(..., description=\"natural language query string\")\n",
    "    filter_key_list: List[str] = Field(..., description=\"List of metadata filter field names\")\n",
    "    filter_value_list: List[str] = Field(..., description=(\n",
    "        \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
    "    ))\n",
    "\n",
    "def auto_retrieve_fn(query: str, filter_key_list: List[str], filter_value_list: List[str]):\n",
    "    \"\"\"Auto retrieval function.\n",
    "    \n",
    "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
    "    \n",
    "    \"\"\"\n",
    "    query = query or \"Query\"\n",
    "    \n",
    "    exact_match_filters = [ExactMatchFilter(key=k, value=v) for k, v in zip(filter_key_list, filter_value_list)]\n",
    "    retriever = VectorIndexRetriever(\n",
    "        index,\n",
    "        filters=MetadataFilters(filters=exact_match_filters),\n",
    "        top_k=top_k\n",
    "    )\n",
    "    query_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever\n",
    "    )\n",
    "    \n",
    "    response = query_engine.query(query)\n",
    "    return str(response)\n",
    "\n",
    "\n",
    "description = f\"\"\"\\\n",
    "Use this tool to look up biographical information about celebrities.\n",
    "The vector database schema is given below:\n",
    "{vector_store_info.json()}\n",
    "\"\"\"\n",
    "    \n",
    "auto_retrieve_tool = FunctionTool.from_defaults(\n",
    "    fn=auto_retrieve_fn,\n",
    "    name=\"celebrity_bios\",\n",
    "    description=description,\n",
    "    fn_schema=AutoRetrieveModel\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61f39c99-311d-4609-b13b-ca8f4b4631e9",
   "metadata": {},
   "source": [
    "#### Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49addd6e-c325-4222-b694-c19be2583650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [auto_retrieve_tool], \n",
    "    llm=ChatOpenAI(temperature=0, model_name=\"gpt-4-0613\"),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c3fc23-3f09-492f-b1d8-2291cd091a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = agent.chat(\n",
    "    \"Tell me about two celebrities from the United States. \"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d641f03d-d0cb-4c11-a571-33a9cb7221d5",
   "metadata": {},
   "source": [
    "## Joint Text-to-SQL and Semantic Search\n",
    "\n",
    "This is currenty handled by our `SQLAutoVectorQueryEngine`.\n",
    "\n",
    "Let's try implementing this by giving our `OpenAIAgent` access to two query tools: SQL and Vector "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "550dc181-3725-4b96-8528-2669483955ba",
   "metadata": {},
   "source": [
    "#### Load and Index Structured Data\n",
    "\n",
    "We load sample structured datapoints into a SQL db and index it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef04b5c-0e7f-4c44-b71d-8cb26406d50c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, String, Integer, select, column\n",
    "from llama_index import SQLDatabase\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\", future=True)\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3739b3-d1c5-4600-985d-7b6e310eb8eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a170a-e1cd-4651-8689-a01d9c82002b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print tables\n",
    "metadata_obj.tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea511f-5a01-493e-a3f7-ceb144823996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.connect() as connection:\n",
    "        cursor = connection.execute(stmt)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dfe2b8-4831-4603-a88f-ae3e571f9436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    cursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e85e7-364b-480b-8a7b-a1db956b7011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ad520-1ceb-4191-b843-31b3c2ac3cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.struct_store.sql_query import SQLTableRetrieverQueryEngine\n",
    "from llama_index.objects import SQLTableNodeMapping, ObjectIndex, SQLTableSchema\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "table_schema_objs = [(SQLTableSchema(table_name=\"city_stats\"))]\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    table_schema_objs,\n",
    "    table_node_mapping,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "query_engine = SQLTableRetrieverQueryEngine(\n",
    "    sql_database, obj_index.as_retriever()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2f1fc66-6627-4a36-9a5b-bbbd1d89dc05",
   "metadata": {},
   "source": [
    "#### Load and Index Unstructured Data\n",
    "\n",
    "We load unstructured data into a vector index backed by Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7fdd9d-365a-4978-9352-67c2d6e84599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install wikipedia python package\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38dd18c-e4e6-402d-93b9-8bb46423e944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import WikipediaReader, SimpleDirectoryReader, VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7fc15-b699-4414-8968-5ae67d59ab7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cities = ['Toronto', 'Berlin', 'Tokyo']\n",
    "wiki_docs = WikipediaReader().load_data(pages=cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ff57b-5361-486a-aa1c-1bcae921ead5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define pinecone index \n",
    "import pinecone\n",
    "import os\n",
    "\n",
    "api_key = os.environ['PINECONE_API_KEY']\n",
    "pinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\n",
    "\n",
    "# dimensions are for text-embedding-ada-002\n",
    "# pinecone.create_index(\"quickstart\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\")\n",
    "pinecone_index = pinecone.Index(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869a028-12b2-476e-b2d3-be9d90555fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: delete all\n",
    "pinecone_index.delete(deleteAll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f97c34-0f9d-4030-a6e5-5526a4f015c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index import ServiceContext, LLMPredictor\n",
    "from llama_index.storage import StorageContext\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# define node parser and LLM\n",
    "chunk_size = 1024\n",
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\", streaming=True))\n",
    "service_context = ServiceContext.from_defaults(chunk_size=chunk_size, llm_predictor=llm_predictor)\n",
    "text_splitter = TokenTextSplitter(chunk_size=chunk_size)\n",
    "node_parser = SimpleNodeParser(text_splitter=text_splitter)\n",
    "\n",
    "# define pinecone vector index\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index, namespace='wiki_cities')\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "vector_index = VectorStoreIndex([], storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc76bc8-6265-4a0e-957c-1f3d6ac0b802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert documents into vector index\n",
    "# Each document has metadata of the city attached\n",
    "for city, wiki_doc in zip(cities, wiki_docs):\n",
    "    nodes = node_parser.get_nodes_from_documents([wiki_doc])\n",
    "    # add metadata to each node\n",
    "    for node in nodes:\n",
    "        node.metadata = {\"title\": city}\n",
    "    vector_index.insert_nodes(nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6e73f5a-5c75-4963-8642-dc5060c0a735",
   "metadata": {},
   "source": [
    "#### Define Query Engines / Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21086866-120d-45fe-9233-20b070643e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.query_engine import SQLAutoVectorQueryEngine, RetrieverQueryEngine\n",
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "from llama_index.indices.vector_store import VectorIndexAutoRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0821ba8-d9ac-465f-89a6-430c2d8ca2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_query_engine = query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3522932-e9b1-4e09-b5fd-f0f827ebc8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.vector_store.retrievers import VectorIndexAutoRetriever\n",
    "from llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
    "from llama_index.query_engine.retriever_query_engine import RetrieverQueryEngine\n",
    "\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info='articles about different cities',\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name='title', \n",
    "            type='str', \n",
    "            description='The name of the city'),\n",
    "    ]\n",
    ")\n",
    "vector_auto_retriever = VectorIndexAutoRetriever(vector_index, vector_store_info=vector_store_info)\n",
    "\n",
    "retriever_query_engine = RetrieverQueryEngine.from_args(\n",
    "    vector_auto_retriever, service_context=service_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a86ca7-1240-4ea2-9f5f-6d93cca00978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    name=\"sql_tool\",\n",
    "    description=(\n",
    "        'Useful for translating a natural language query into a SQL query over a table containing: '\n",
    "        'city_stats, containing the population/country of each city'\n",
    "    )\n",
    ")\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=retriever_query_engine,\n",
    "    name=\"vector_tool\",\n",
    "    description=f'Useful for answering semantic questions about different cities',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73780d81-150a-46a7-a935-ab5af22d52ce",
   "metadata": {},
   "source": [
    "#### Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651570b6-e2d8-45f6-9c0c-bf5871af49eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [sql_tool, vector_tool], \n",
    "    # llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0613\"),\n",
    "    llm=ChatOpenAI(temperature=0, model_name=\"gpt-4-0613\"),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f467f7d3-1cb1-47e9-8b67-a356f8be55f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: gpt-3.5 gives the wrong answer, but gpt-4 is able to reason over both loops\n",
    "response = agent.chat(\"Tell me about the arts and culture of the city with the highest population\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc35ba-3162-4fa9-81a9-174aa0f1dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat('Tell me about the history of Berlin')\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873463d-4790-4c17-bfe9-2ece610fe4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"Can you give me the country corresponding to each city?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e669e27-84c1-4762-a0d1-25b84ba90def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
