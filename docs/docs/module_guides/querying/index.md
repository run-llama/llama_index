# Querying

Querying is the most important part of your LLM application. To learn more about getting a final product that you can deploy, check out the [query engine](/python/framework/module_guides/deploying/query_engine), [chat engine](/python/framework/module_guides/deploying/chat_engines).

If you wish to combine advanced reasoning with tool use, check out our [agents](/python/framework/module_guides/deploying/agents) guide.

## Query Workflows

You can create workflows for querying with ease, using our event-driven `Workflow` interface. Check out our [workflow guide](/python/framework/module_guides/workflow) for more details.

Otherwise check out how to use our query modules as standalone components ðŸ‘‡.

## Query Modules

- [Query Engines](/python/framework/module_guides/deploying/query_engine)
- [Chat Engines](/python/framework/module_guides/deploying/chat_engines)
- [Agents](/python/framework/module_guides/deploying/agents)
- [Retrievers](/python/framework/module_guides/querying/retriever)
- [Response Synthesizers](/python/framework/module_guides/querying/response_synthesizers)
- [Routers](/python/framework/module_guides/querying/router)
- [Node Postprocessors](/python/framework/module_guides/querying/node_postprocessors)
- [Structured Outputs](/python/framework/module_guides/querying/structured_outputs)
