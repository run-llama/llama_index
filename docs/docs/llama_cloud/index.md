# LlamaCloud

LlamaCloud is a managed platform for data parsing and ingestion, allowing you to get production-quality data for your production LLM application.

LlamaCloud integrates seamlessly with the open-source library, providing parsing, indexes, and retrievers to build advanced RAG, agents, and more.

LlamaCloud consists of the following main components:

- **LlamaParse**: our self-serve document parsing API
- **Ingestion and Retrieval API**: Connect to 10+ data sources and sinks. Easily setup a data pipeline that can handle large volumes of data and incremental updates. Get back an endpoint with state-of-the-art indexing/retrieval to solve your complex document needs.
- **Evaluations and Observability**: Run and track evaluations on your data and model, both in the cloud and locally.

## Why LlamaCloud?

Building production LLM applications (e.g. advanced RAG) over your data is hard, and one of the biggest issues is data quality.

As an enterprise developer, you want LLM applications with 1) high response quality and low hallucinations, 2) an easy way to improve and tune your applications, and 3) an easy way to scale to more data.

LlamaCloud allows you to spend less time wrangling with your data and more time building the business logic of your LLM application.

## Resources

- [LlamaCloud documentation](https://docs.cloud.llamaindex.ai/)
- If you're interested in LlamaCloud, [come talk to us](https://www.llamaindex.ai/contact).
- [LlamaParse](./llama_parse.md) is available to everyone: [sign up](cloud.llamaindex.ai) by signing up for LlamaCloud.
- [LlamaCloud launch blog post](https://www.llamaindex.ai/blog/introducing-llamacloud-and-llamaparse-af8cedf9006b)
