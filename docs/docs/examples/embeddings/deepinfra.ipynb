{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/embeddings/deepinfra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepInfra\n",
    "\n",
    "With this integration, you can use the DeepInfra embeddings model to get embeddings for your text data. Here is the link to the [embeddings models](https://deepinfra.com/models/embeddings).\n",
    "\n",
    "First, you need to sign up on the [DeepInfra website](https://deepinfra.com/) and get the API token. You can copy `model_ids` from the model cards and start using them in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-embeddings-deepinfra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from llama_index.embeddings.deepinfra import DeepInfraEmbeddingModel\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "model = DeepInfraEmbeddingModel(\n",
    "    model_id=\"BAAI/bge-large-en-v1.5\",  # Use custom model ID\n",
    "    api_token=\"YOUR_API_TOKEN\",  # Optionally provide token here\n",
    "    normalize=True,  # Optional normalization\n",
    "    text_prefix=\"text: \",  # Optional text prefix\n",
    "    query_prefix=\"query: \",  # Optional query prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.get_text_embedding(\"hello world\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"hello world\", \"goodbye world\"]\n",
    "response_batch = model.get_text_embedding_batch(texts)\n",
    "print(response_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = model.get_query_embedding(\"hello world\")\n",
    "print(query_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    text = \"hello world\"\n",
    "    async_response = await model.aget_text_embedding(text)\n",
    "    print(async_response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For any questions or feedback, please contact us at feedback@deepinfra.com."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
