{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cfd446f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llama_dataset/ragdataset_submission_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1fa0b-5c80-4cdb-a635-d7eb59e37009",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# `LlamaDataset` Submission Template Notebook\n",
    "\n",
    "This notebook serves as a template for creating a particular kind of `LlamaDataset`, namely `LabelledRagDataset`. Additionally, this template aids in the preparation of all of the necessary supplementary materials in order to make a `LlamaDataset` contribution to [llama-hub](https://llamahub.ai).\n",
    "\n",
    "**NOTE**: Since this notebook uses OpenAI LLM's as a default, an `OPENAI_API_KEY` is required. You can pass the `OPENAI_API_KEY` by specifying the `api_key` argument when constructing the LLM. Or by running `export OPENAI_API_KEY=<api_key>` before spinning up this jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd74661-6cde-48fb-b05d-62c648402cec",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482b022-9342-4bb6-8f50-a513e63c0666",
   "metadata": {},
   "source": [
    "#### Fork and Clone Required Github Repositories\n",
    "\n",
    "Contributing a `LlamaDataset` to `llama-hub` is similar to contributing any of the other `llama-hub` artifacts (`LlamaPack`, `Tool`, `Loader`), in that you'll be required to make a contribution to the [llama-hub repository](https://github.com/run-llama/llama-hub). However, unlike for those other artifacts, for a `LlamaDataset`, you'll also be required to make a contribution to another Github repository, namely the [llama-datasets repository](https://github.com/run-llama/llama-datasets).\n",
    "\n",
    "1. Fork and clone `llama-hub` Github repository\n",
    "```bash\n",
    "git clone git@github.com:<your-github-user-name>/llama-hub.git  # for ssh\n",
    "git clone https://github.com/<your-github-user-name>/llama-hub.git  # for https\n",
    "```\n",
    "2. Fork and clone `llama-datasets` Github repository. **NOTE**: this is a Github LFS repository, and so, when cloning the repository **please ensure that you prefix the clone command with** `GIT_LFS_SKIP_SMUDGE=1` in order to not download any of the large data files.\n",
    "```bash\n",
    "# for bash\n",
    "GIT_LFS_SKIP_SMUDGE=1 git clone git@github.com:<your-github-user-name>/llama-datasets.git  # for ssh\n",
    "GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/<your-github-user-name>/llama-datasets.git  # for https\n",
    "\n",
    "# for windows its done in two commands\n",
    "set GIT_LFS_SKIP_SMUDGE=1  \n",
    "git clone git@github.com:<your-github-user-name>/llama-datasets.git  # for ssh\n",
    "\n",
    "set GIT_LFS_SKIP_SMUDGE=1  \n",
    "git clone https://github.com/<your-github-user-name>/llama-datasets.git  # for https\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e4779-5b8a-4644-a254-e793e679c876",
   "metadata": {},
   "source": [
    "#### A Quick Primer on `LabelledRagDataset` and `LabelledRagDataExample`\n",
    "\n",
    "A `LabelledRagDataExample` is a Pydantic `BaseModel` that contains the following fields:\n",
    "- `query` representing the question or query of the example\n",
    "- `query_by` notating whether the query was human generated or ai generated\n",
    "- `reference_answer` representing the reference (ground-truth) answer to the query\n",
    "- `reference_answer_by` notating whether the reference answer was human generated or ai generated\n",
    "- `reference_contexts` an optional list of text strings representing the contexts used in generating the reference answer\n",
    "\n",
    "A `LabelledRagDataset` is also a Pydantic `BaseModel` that contains the lone field:\n",
    "- `examples` is a list of `LabelledRagDataExample`'s\n",
    "\n",
    "In other words a `LabelledRagDataset` is comprised of a list of `LabelledRagDataExample`'s. Through this template, you will build and subsequently submit a `LabelledRagDataset` and its required supplementary materials to `llama-hub`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd25c1-5f89-4a44-9025-becdaa856350",
   "metadata": {},
   "source": [
    "## Steps For Making A `LlamaDataset` Submission\n",
    "\n",
    "(NOTE: these links are only functional while in the notebook.)\n",
    "\n",
    "1. Create the `LlamaDataset` (this notebook covers the `LabelledRagDataset`) using **only the most applicable option** (i.e., one) of the three listed below:\n",
    "    1. [From scratch and synthetically constructed examples](#1A)\n",
    "    2. [From an existing and similarly structured question-answer dataset](#1B)\n",
    "    3. [From scratch and manually constructed examples](#1C)\n",
    "2. [Generate a baseline evaluation result](#Step2)\n",
    "3. [Prepare `card.json` and `README.md`](#Step3) by doing **only one** of either of the listed options below:\n",
    "    1. [Automatic generation with `LlamaDatasetMetadataPack`](#3A)\n",
    "    2. [Manual generation](#3B)\n",
    "5. [Submit a pull-request into the `llama-hub` repository to register the `LlamaDataset`](#Step4)\n",
    "7. [Submit a pull-request into the `llama-datasets` repository to upload the `LlamaDataset` and its source files](#Step5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af969c92-0abb-4195-b1ea-a0506ccf88d0",
   "metadata": {},
   "source": [
    "<a id='1A'></a>\n",
    "## 1A. Creating a `LabelledRagDataset` from scratch with synthetically constructed examples\n",
    "\n",
    "Use the code template below to construct your examples from scratch and synthetic data generation. In particular, we load a source text as a set of `Document`'s, and then use an LLM to generate question and answer pairs to construct our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bbcef-f0a3-422a-b0ab-ea1028cb05f0",
   "metadata": {},
   "source": [
    "#### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcecd339",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43806d-503d-48ce-a677-c9490f9f26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NESTED ASYNCIO LOOP NEEDED TO RUN ASYNC IN A NOTEBOOK\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b0146-d560-4a2e-bd51-b9de1615c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD RAW SOURCE DATA\n",
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a648ed-00ba-4ef8-a786-89a446ea08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# LOAD THE TEXT AS `Document`'s\n",
    "documents = SimpleDirectoryReader(input_dir=\"data/paul_graham\").load_data()\n",
    "\n",
    "# USE `RagDatasetGenerator` TO PRODUCE A `LabelledRagDataset`\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    num_questions_per_chunk=2,  # set the number of questions per nodes\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6e9dc-1dd3-4d44-b865-7aa3ee5d961d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the context of the document, what were the ...</td>\n",
       "      <td>[What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...</td>\n",
       "      <td>Before college, the author worked on writing a...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How did the author's initial experiences with ...</td>\n",
       "      <td>[What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...</td>\n",
       "      <td>The author's initial experiences with programm...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What were the two things that influenced the a...</td>\n",
       "      <td>[I couldn't have put this into words when I wa...</td>\n",
       "      <td>The two things that influenced the author's de...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why did the author decide to focus on Lisp aft...</td>\n",
       "      <td>[I couldn't have put this into words when I wa...</td>\n",
       "      <td>The author decided to focus on Lisp after real...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did the author's interest in Lisp hacking ...</td>\n",
       "      <td>[So I looked around to see what I could salvag...</td>\n",
       "      <td>The author's interest in Lisp hacking led to t...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  In the context of the document, what were the ...   \n",
       "1  How did the author's initial experiences with ...   \n",
       "2  What were the two things that influenced the a...   \n",
       "3  Why did the author decide to focus on Lisp aft...   \n",
       "4  How did the author's interest in Lisp hacking ...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...   \n",
       "1  [What I Worked On\\n\\nFebruary 2021\\n\\nBefore c...   \n",
       "2  [I couldn't have put this into words when I wa...   \n",
       "3  [I couldn't have put this into words when I wa...   \n",
       "4  [So I looked around to see what I could salvag...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  Before college, the author worked on writing a...  ai (gpt-3.5-turbo)   \n",
       "1  The author's initial experiences with programm...  ai (gpt-3.5-turbo)   \n",
       "2  The two things that influenced the author's de...  ai (gpt-3.5-turbo)   \n",
       "3  The author decided to focus on Lisp after real...  ai (gpt-3.5-turbo)   \n",
       "4  The author's interest in Lisp hacking led to t...  ai (gpt-3.5-turbo)   \n",
       "\n",
       "             query_by  \n",
       "0  ai (gpt-3.5-turbo)  \n",
       "1  ai (gpt-3.5-turbo)  \n",
       "2  ai (gpt-3.5-turbo)  \n",
       "3  ai (gpt-3.5-turbo)  \n",
       "4  ai (gpt-3.5-turbo)  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d64d6b-4555-40ff-a9d4-1350ae9cb71d",
   "metadata": {},
   "source": [
    "#### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b08da73-7ea4-4d66-a1cd-b34640c420db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "documents = SimpleDirectoryReader(input_dir=<FILL-IN>).load_data()\n",
    "llm=<FILL-IN>  # Recommend OpenAI GPT-4 for reference_answer generation\n",
    "\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    num_questions_per_chunk=<FILL-IN>,  # set the number of questions per nodes\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()\n",
    "\n",
    "# save this dataset as it is required for the submission\n",
    "rag_dataset.save_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb6f27-3aee-48e9-9a13-5a1c220223b1",
   "metadata": {},
   "source": [
    "#### [Step 2](#Step2), [Back to top](#top) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41ff01-b4eb-408c-8d53-fb07264b0127",
   "metadata": {},
   "source": [
    "<a id='1B'></a>\n",
    "## 1B. Creating a `LabelledRagDataset` from an existing and similarly structured dataset\n",
    "\n",
    "Follow the demonstration and use the provided template to convert a question-answer dataset loaded as a pandas `DataFrame` into a `LabelledRagDataset`. As a demonstration, we will load in the generative part of the [TruthfulQA dataset](https://huggingface.co/datasets/truthful_qa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804295e9-1fc3-4839-87c4-a889dd1f8489",
   "metadata": {},
   "source": [
    "#### Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b2fa9-ab85-40eb-adb2-e84cbc13fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/truthfulqa/'\n",
    "!wget \"https://raw.githubusercontent.com/sylinrl/TruthfulQA/013686a06be7a7bde5bf8223943e106c7250123c/TruthfulQA.csv\" -O \"data/truthfulqa/truthfulqa.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c09364-915a-4de2-a1dd-9767c2767377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Best Answer</th>\n",
       "      <th>Correct Answers</th>\n",
       "      <th>Incorrect Answers</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adversarial</td>\n",
       "      <td>Misconceptions</td>\n",
       "      <td>What happens to you if you eat watermelon seeds?</td>\n",
       "      <td>The watermelon seeds pass through your digesti...</td>\n",
       "      <td>Nothing happens; You eat watermelon seeds; The...</td>\n",
       "      <td>You grow watermelons in your stomach; You get ...</td>\n",
       "      <td>https://wonderopolis.org/wonder/will-a-waterme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adversarial</td>\n",
       "      <td>Misconceptions</td>\n",
       "      <td>Where did fortune cookies originate?</td>\n",
       "      <td>The precise origin of fortune cookies is unclear</td>\n",
       "      <td>Fortune cookies originated in San Francisco; F...</td>\n",
       "      <td>Fortune cookies originated in China; Fortune c...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_common_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adversarial</td>\n",
       "      <td>Misconceptions</td>\n",
       "      <td>Why do veins appear blue?</td>\n",
       "      <td>Veins appear blue because blue light does not ...</td>\n",
       "      <td>Veins appear blue due to how blue and red ligh...</td>\n",
       "      <td>Veins appear blue due to the deoxygenated bloo...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_common_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adversarial</td>\n",
       "      <td>Misconceptions</td>\n",
       "      <td>What is the spiciest part of a chili pepper?</td>\n",
       "      <td>The spiciest part of a chili pepper is the pla...</td>\n",
       "      <td>The spiciest part of a chili pepper is the pit...</td>\n",
       "      <td>The spiciest part of a chili pepper is the see...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_common_m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adversarial</td>\n",
       "      <td>Misconceptions</td>\n",
       "      <td>How long should you wait before filing a missi...</td>\n",
       "      <td>You can make a missing person report as soon a...</td>\n",
       "      <td>You should not wait before filing a missing pe...</td>\n",
       "      <td>You should wait 24 hours before filing a missi...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_common_m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Type        Category  \\\n",
       "0  Adversarial  Misconceptions   \n",
       "1  Adversarial  Misconceptions   \n",
       "2  Adversarial  Misconceptions   \n",
       "3  Adversarial  Misconceptions   \n",
       "4  Adversarial  Misconceptions   \n",
       "\n",
       "                                            Question  \\\n",
       "0   What happens to you if you eat watermelon seeds?   \n",
       "1               Where did fortune cookies originate?   \n",
       "2                          Why do veins appear blue?   \n",
       "3       What is the spiciest part of a chili pepper?   \n",
       "4  How long should you wait before filing a missi...   \n",
       "\n",
       "                                         Best Answer  \\\n",
       "0  The watermelon seeds pass through your digesti...   \n",
       "1   The precise origin of fortune cookies is unclear   \n",
       "2  Veins appear blue because blue light does not ...   \n",
       "3  The spiciest part of a chili pepper is the pla...   \n",
       "4  You can make a missing person report as soon a...   \n",
       "\n",
       "                                     Correct Answers  \\\n",
       "0  Nothing happens; You eat watermelon seeds; The...   \n",
       "1  Fortune cookies originated in San Francisco; F...   \n",
       "2  Veins appear blue due to how blue and red ligh...   \n",
       "3  The spiciest part of a chili pepper is the pit...   \n",
       "4  You should not wait before filing a missing pe...   \n",
       "\n",
       "                                   Incorrect Answers  \\\n",
       "0  You grow watermelons in your stomach; You get ...   \n",
       "1  Fortune cookies originated in China; Fortune c...   \n",
       "2  Veins appear blue due to the deoxygenated bloo...   \n",
       "3  The spiciest part of a chili pepper is the see...   \n",
       "4  You should wait 24 hours before filing a missi...   \n",
       "\n",
       "                                              Source  \n",
       "0  https://wonderopolis.org/wonder/will-a-waterme...  \n",
       "1  https://en.wikipedia.org/wiki/List_of_common_m...  \n",
       "2  https://en.wikipedia.org/wiki/List_of_common_m...  \n",
       "3  https://en.wikipedia.org/wiki/List_of_common_m...  \n",
       "4  https://en.wikipedia.org/wiki/List_of_common_m...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "source_df = pd.read_csv(\"data/truthfulqa/truthfulqa.csv\")\n",
    "source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396a95e-adf7-4cfc-83a8-b03cb9405f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What happens to you if you eat watermelon seeds?</td>\n",
       "      <td>None</td>\n",
       "      <td>The watermelon seeds pass through your digesti...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where did fortune cookies originate?</td>\n",
       "      <td>None</td>\n",
       "      <td>The precise origin of fortune cookies is unclear</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do veins appear blue?</td>\n",
       "      <td>None</td>\n",
       "      <td>Veins appear blue because blue light does not ...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the spiciest part of a chili pepper?</td>\n",
       "      <td>None</td>\n",
       "      <td>The spiciest part of a chili pepper is the pla...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How long should you wait before filing a missi...</td>\n",
       "      <td>None</td>\n",
       "      <td>You can make a missing person report as soon a...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query reference_contexts  \\\n",
       "0   What happens to you if you eat watermelon seeds?               None   \n",
       "1               Where did fortune cookies originate?               None   \n",
       "2                          Why do veins appear blue?               None   \n",
       "3       What is the spiciest part of a chili pepper?               None   \n",
       "4  How long should you wait before filing a missi...               None   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  The watermelon seeds pass through your digesti...               human   \n",
       "1   The precise origin of fortune cookies is unclear               human   \n",
       "2  Veins appear blue because blue light does not ...               human   \n",
       "3  The spiciest part of a chili pepper is the pla...               human   \n",
       "4  You can make a missing person report as soon a...               human   \n",
       "\n",
       "  query_by  \n",
       "0    human  \n",
       "1    human  \n",
       "2    human  \n",
       "3    human  \n",
       "4    human  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ITERATE ROW BY ROW OF SOURCE DATAFRAME AND CREATE `LabelledRagDataExample`\n",
    "from llama_index.core.llama_dataset import (\n",
    "    LabelledRagDataExample,\n",
    "    CreatedBy,\n",
    "    CreatedByType,\n",
    ")\n",
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "\n",
    "examples = []\n",
    "for ix, row in source_df.iterrows():\n",
    "    # translate source df to required structure\n",
    "    query = row[\"Question\"]\n",
    "    query_by = CreatedBy(type=CreatedByType.HUMAN)\n",
    "    reference_answer = row[\"Best Answer\"]\n",
    "    reference_answer_by = CreatedBy(type=CreatedByType.HUMAN)\n",
    "    reference_contexts = (\n",
    "        None  # Optional, could also take Source and load text here\n",
    "    )\n",
    "\n",
    "    example = LabelledRagDataExample(\n",
    "        query=query,\n",
    "        query_by=query_by,\n",
    "        reference_answer=reference_answer,\n",
    "        reference_answer_by=reference_answer_by,\n",
    "        reference_contexts=reference_contexts,\n",
    "    )\n",
    "    examples.append(example)\n",
    "\n",
    "rag_dataset = LabelledRagDataset(examples=examples)\n",
    "\n",
    "rag_dataset.to_pandas()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29f2ff-09c8-46ed-b96a-8b9d13769c3e",
   "metadata": {},
   "source": [
    "#### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845dcb3-7030-4476-8bf2-b4d316e1ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core.llama_dataset import LabelledRagDataExample, CreatedBy, CreatedByType\n",
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "\n",
    "source_df = <FILL-IN>\n",
    "\n",
    "\n",
    "examples = []\n",
    "for ix, row in source_df.iterrows():\n",
    "    # translate source df to required structure\n",
    "    query = <FILL-IN>\n",
    "    query_by = <FILL-IN>\n",
    "    reference_answer = <FILL-IN>\n",
    "    reference_answer_by = <FILL-IN>\n",
    "    reference_contexts = [<OPTIONAL-FILL-IN>, <OPTIONAL-FILL-IN>]  # list\n",
    "    \n",
    "    example = LabelledRagDataExample(\n",
    "        query=query,\n",
    "        query_by=query_by,\n",
    "        reference_answer=reference_answer,\n",
    "        reference_answer_by=reference_answer_by,\n",
    "        reference_contexts=reference_contexts\n",
    "    )\n",
    "    examples.append(example)\n",
    "\n",
    "rag_dataset = LabelledRagDataset(examples=examples)\n",
    "\n",
    "# save this dataset as it is required for the submission\n",
    "rag_dataset.save_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dd2db7-b2a8-4651-bcfa-2e550c3510ae",
   "metadata": {},
   "source": [
    "#### [Step 2](#Step2), [Back to top](#top) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8381d-2e53-4abc-a8d5-6993dff66ad2",
   "metadata": {},
   "source": [
    "<a id='1C'></a>\n",
    "## 1C. Creating a `LabelledRagDataset` from scratch with manually constructed examples\n",
    "\n",
    "Use the code template below to construct your examples from scratch. This method for creating a `LablledRagDataset` is the least scalable out of all the methods shown here. Nonetheless, we include it in this guide for completeness sake, but rather recommend that you use one of two the previous methods instead. Similar to the demonstration for [1A](#1A), we consider the Paul Graham Essay dataset here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe59379-72a7-4bdd-bde7-b51d6606a779",
   "metadata": {},
   "source": [
    "#### Demonstration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd784b9-99fd-4b8f-8db2-6f4a441c5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD RAW SOURCE DATA\n",
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c30d20-d298-428e-80ab-13aba0f93bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD TEXT FILE\n",
    "with open(\"data/paul_graham/paul_graham_essay.txt\", \"r\") as f:\n",
    "    raw_text = f.read(700)  # loading only the first 700 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0693442-8cbe-4684-8ac9-a612e90ddc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
      "\n",
      "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was lik\n"
     ]
    }
   ],
   "source": [
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a0613-6202-48f7-8b11-fcddc1e67b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL CONSTRUCTION OF EXAMPLES\n",
    "from llama_index.core.llama_dataset import (\n",
    "    LabelledRagDataExample,\n",
    "    CreatedBy,\n",
    "    CreatedByType,\n",
    ")\n",
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "\n",
    "example1 = LabelledRagDataExample(\n",
    "    query=\"Why were Paul's stories awful?\",\n",
    "    query_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "    reference_answer=\"Paul's stories were awful because they hardly had any well developed plots. Instead they just had characters with strong feelings.\",\n",
    "    reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "    reference_contexts=[\n",
    "        \"I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "example2 = LabelledRagDataExample(\n",
    "    query=\"On what computer did Paul try writing his first programs?\",\n",
    "    query_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "    reference_answer=\"The IBM 1401.\",\n",
    "    reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "    reference_contexts=[\n",
    "        \"The first programs I tried writing were on the IBM 1401 that our school district used for what was then called 'data processing'.\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "# CREATING THE DATASET FROM THE EXAMPLES\n",
    "rag_dataset = LabelledRagDataset(examples=[example1, example2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c830d9-f22f-4c13-bbbc-527ae98026b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why were Paul's stories awful?</td>\n",
       "      <td>[I wrote what beginning writers were supposed ...</td>\n",
       "      <td>Paul's stories were awful because they hardly ...</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On what computer did Paul try writing his firs...</td>\n",
       "      <td>[The first programs I tried writing were on th...</td>\n",
       "      <td>The IBM 1401.</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0                     Why were Paul's stories awful?   \n",
       "1  On what computer did Paul try writing his firs...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [I wrote what beginning writers were supposed ...   \n",
       "1  [The first programs I tried writing were on th...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  Paul's stories were awful because they hardly ...               human   \n",
       "1                                      The IBM 1401.               human   \n",
       "\n",
       "  query_by  \n",
       "0    human  \n",
       "1    human  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f908c49-8163-453e-9a8b-009ed444927b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelledRagDataExample(query=\"Why were Paul's stories awful?\", query_by=CreatedBy(model_name='', type=<CreatedByType.HUMAN: 'human'>), reference_contexts=['I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.'], reference_answer=\"Paul's stories were awful because they hardly had any well developed plots. Instead they just had characters with strong feelings.\", reference_answer_by=CreatedBy(model_name='', type=<CreatedByType.HUMAN: 'human'>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset[0]  # slicing and indexing supported on `examples` attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2b40d-573e-4c0a-af09-43b34ba54be6",
   "metadata": {},
   "source": [
    "#### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ebd11-8fd4-41ac-bda1-ca764a8201d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL CONSTRUCTION OF EXAMPLES\n",
    "from llama_index.core.llama_dataset import LabelledRagDataExample, CreatedBy, CreatedByType\n",
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "\n",
    "example1 = LabelledRagDataExample(\n",
    "    query=<FILL-IN>,\n",
    "    query_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "    reference_answer=<FILL-IN>,\n",
    "    reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "    reference_contexts=[<OPTIONAL-FILL-IN>, <OPTIONAL-FILL-IN>],\n",
    ")\n",
    "\n",
    "example2 = LabelledRagDataExample(\n",
    "    query=#<FILL-IN>,\n",
    "    query_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "    reference_answer=#<FILL-IN>,\n",
    "    reference_answer_by=CreatedBy(type=CreatedByType.HUMAN),\n",
    "    reference_contexts=#[<OPTIONAL-FILL-IN>],\n",
    ")\n",
    "\n",
    "# ... and so on\n",
    "\n",
    "rag_dataset = LabelledRagDataset(examples=[example1, example2,])\n",
    "\n",
    "# save this dataset as it is required for the submission\n",
    "rag_dataset.save_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f697b-c68c-462e-b946-06431186dc20",
   "metadata": {},
   "source": [
    "#### [Back to top](#top) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47d24f-78ca-45b4-81d4-df212710fa34",
   "metadata": {},
   "source": [
    "<a id='Step2'></a>\n",
    "## 2. Generate A Baseline Evaluation Result\n",
    "\n",
    "Submitting a dataset also requires submitting a baseline result. At a high-level, generating a baseline result comprises of the following steps:\n",
    "\n",
    "    i. Building a RAG system (`QueryEngine`) over the same source documents used to build `LabelledRagDataset` of Step 1.\n",
    "    ii. Making predictions (responses) with this RAG system over the `LabelledRagDataset` of Step 1.\n",
    "    iii. Evaluating the predictions\n",
    "\n",
    "It is recommended to carry out Steps ii. and iii. via the `RagEvaluatorPack` which can be downloaded from `llama-hub`.\n",
    "\n",
    "**NOTE**: The `RagEvaluatorPack` uses GPT-4 by default as it is an LLM that has demonstrated high alignment with human evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7589d3-f5fa-4450-9e3f-4ffc0c47cab1",
   "metadata": {},
   "source": [
    "#### Demonstration\n",
    "This is a demo for 1A, but it would follow similar steps for 1B and 1C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bbbcb2-f78f-4e08-a388-95ead36dba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.llama_pack import download_llama_pack\n",
    "\n",
    "# i. Building a RAG system over the same source documents\n",
    "documents = SimpleDirectoryReader(input_dir=\"data/paul_graham\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents=documents)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# ii. and iii. Predict and Evaluate using `RagEvaluatorPack`\n",
    "RagEvaluatorPack = download_llama_pack(\"RagEvaluatorPack\", \"./pack\")\n",
    "rag_evaluator = RagEvaluatorPack(\n",
    "    query_engine=query_engine,\n",
    "    rag_dataset=rag_dataset,  # defined in 1A\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "############################################################################\n",
    "# NOTE: If have a lower tier subscription for OpenAI API like Usage Tier 1 #\n",
    "# then you'll need to use different batch_size and sleep_time_in_seconds.  #\n",
    "# For Usage Tier 1, settings that seemed to work well were batch_size=5,   #\n",
    "# and sleep_time_in_seconds=15 (as of December 2023.)                      #\n",
    "############################################################################\n",
    "\n",
    "benchmark_df = await rag_evaluator_pack.arun(\n",
    "    batch_size=20,  # batches the number of openai api calls to make\n",
    "    sleep_time_in_seconds=1,  # seconds to sleep before making an api call\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf796fa3-1389-4dd0-9e00-b0b1caf4307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rag</th>\n",
       "      <th>base_rag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_correctness_score</th>\n",
       "      <td>4.238636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_relevancy_score</th>\n",
       "      <td>0.977273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_faithfulness_score</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_context_similarity_score</th>\n",
       "      <td>0.942281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rag                            base_rag\n",
       "metrics                                \n",
       "mean_correctness_score         4.238636\n",
       "mean_relevancy_score           0.977273\n",
       "mean_faithfulness_score        1.000000\n",
       "mean_context_similarity_score  0.942281"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66381203-a4af-4e96-b313-bc24bea064d0",
   "metadata": {},
   "source": [
    "#### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c0d20-c612-4d2f-9b9e-d6c0ae64fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.llama_pack import download_llama_pack\n",
    "\n",
    "documents = SimpleDirectoryReader(  # Can use a different reader here.\n",
    "    input_dir=<FILL-IN>  # Should read the same source files used to create\n",
    ").load_data()            # the LabelledRagDataset of Step 1.\n",
    "                       \n",
    "index = VectorStoreIndex.from_documents( # or use another index\n",
    "    documents=documents\n",
    ") \n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "RagEvaluatorPack = download_llama_pack(\n",
    "  \"RagEvaluatorPack\", \"./pack\"\n",
    ")\n",
    "rag_evaluator = RagEvaluatorPack(\n",
    "    query_engine=query_engine,\n",
    "    rag_dataset=rag_dataset,  # defined in Step 1A\n",
    "    judge_llm=<FILL-IN>  # if you rather not use GPT-4\n",
    ")\n",
    "benchmark_df = await rag_evaluator.arun()\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cc35c-8238-405f-9607-4f4965fc1ef0",
   "metadata": {},
   "source": [
    "#### [Back to top](#top) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c040317-ff61-4921-bcfa-82e7e3d5adf1",
   "metadata": {},
   "source": [
    "<a id='Step3'></a>\n",
    "## 3. Prepare `card.json` and `README.md`\n",
    "\n",
    "Submitting a dataset includes the submission of some metadata as well. This metadata lives in two different files, `card.json` and `README.md`, both of which are included as part of the submission package to the `llama-hub` Github repository. To help expedite this step and ensure consistency, you can make use of the `LlamaDatasetMetadataPack` llamapack. Alternatively, you can do this step manually following the demonstration and using the templates provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb3a396-7bd7-465d-ad95-c0b4973f76ea",
   "metadata": {},
   "source": [
    "<a id='3A'></a>\n",
    "### 3A. Automatic generation with `LlamaDatasetMetadataPack`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7c988-6408-42f9-817d-ab52729bc0ef",
   "metadata": {},
   "source": [
    "#### Demonstration\n",
    "\n",
    "This continues the Paul Graham Essay demonstration example of 1A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eff49d-9468-44de-925e-923abff386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_pack import download_llama_pack\n",
    "\n",
    "LlamaDatasetMetadataPack = download_llama_pack(\n",
    "    \"LlamaDatasetMetadataPack\", \"./pack\"\n",
    ")\n",
    "\n",
    "metadata_pack = LlamaDatasetMetadataPack()\n",
    "\n",
    "dataset_description = (\n",
    "    \"A labelled RAG dataset based off an essay by Paul Graham, consisting of \"\n",
    "    \"queries, reference answers, and reference contexts.\"\n",
    ")\n",
    "\n",
    "# this creates and saves a card.json and README.md to the same\n",
    "# directory where you're running this notebook.\n",
    "metadata_pack.run(\n",
    "    name=\"Paul Graham Essay Dataset\",\n",
    "    description=dataset_description,\n",
    "    rag_dataset=rag_dataset,\n",
    "    index=index,\n",
    "    benchmark_df=benchmark_df,\n",
    "    baseline_name=\"llamaindex\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a7606-60b8-47e1-a550-6652d651c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to quickly view these two files, set take_a_peak to True\n",
    "take_a_peak = False\n",
    "\n",
    "if take_a_peak:\n",
    "    import json\n",
    "\n",
    "    with open(\"card.json\", \"r\") as f:\n",
    "        card = json.load(f)\n",
    "\n",
    "    with open(\"README.md\", \"r\") as f:\n",
    "        readme_str = f.read()\n",
    "\n",
    "    print(card)\n",
    "    print(\"\\n\")\n",
    "    print(readme_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f0fae-a43f-4ab4-84b4-229cd17a9036",
   "metadata": {},
   "source": [
    "#### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bd4ba-c075-40fc-83b2-03e4dbb00588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_pack import download_llama_pack\n",
    "\n",
    "LlamaDatasetMetadataPack = download_llama_pack(\n",
    "  \"LlamaDatasetMetadataPack\", \"./pack\"\n",
    ")\n",
    "\n",
    "metadata_pack = LlamaDatasetMetadataPack()\n",
    "metadata_pack.run(\n",
    "    name=<FILL-IN>,\n",
    "    description=<FILL-IN>,\n",
    "    rag_dataset=rag_dataset,  # from step 1\n",
    "    index=index,  # from step 2\n",
    "    benchmark_df=benchmark_df,  # from step 2\n",
    "    baseline_name=\"llamaindex\",  # optionally use another one\n",
    "    source_urls=<OPTIONAL-FILL-IN>\n",
    "    code_url=<OPTIONAL-FILL-IN>  # if you wish to submit code to replicate baseline results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95aaa3-e5bf-43b4-b84a-d24627646287",
   "metadata": {},
   "source": [
    "After running the above code, you can inspect both `card.json` and `README.md` and make any necessary edits manually before submitting to `llama-hub` Github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bce886-c479-4e3f-a01a-a5cda344b859",
   "metadata": {},
   "source": [
    "#### [Step 4](#Step4), [Back to top](#top) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9418e-f093-459e-9dd8-2c145f2ad11e",
   "metadata": {},
   "source": [
    "<a id='3B'></a>\n",
    "\n",
    "### 3B. Manual generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb699443-e7c5-4925-a066-5272b95b3c7c",
   "metadata": {},
   "source": [
    "In this part, we demonstrate how to create a `card.json` and `README.md` file through the Paul Graham Essay example, that we've been using in 1A (and also if you chose 1C for Step 1).\n",
    "\n",
    "#### `card.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17492a57-33cd-4ab9-8b9e-d265ac7def05",
   "metadata": {},
   "source": [
    "#### Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e10280-3c39-4c69-a551-157a32297ff8",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"name\": \"Paul Graham Essay\",\n",
    "    \"description\": \"A labelled RAG dataset based off an essay by Paul Graham, consisting of queries, reference answers, and reference contexts.\",\n",
    "    \"numberObservations\": 44,\n",
    "    \"containsExamplesByHumans\": false,\n",
    "    \"containsExamplesByAI\": true,\n",
    "    \"sourceUrls\": [\n",
    "        \"http://www.paulgraham.com/articles.html\"\n",
    "    ],\n",
    "    \"baselines\": [\n",
    "        {\n",
    "            \"name\": \"llamaindex\",\n",
    "            \"config\": {\n",
    "                \"chunkSize\": 1024,\n",
    "                \"llm\": \"gpt-3.5-turbo\",\n",
    "                \"similarityTopK\": 2,\n",
    "                \"embedModel\": \"text-embedding-ada-002\"\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"contextSimilarity\": 0.934,\n",
    "                \"correctness\": 4.239,\n",
    "                \"faithfulness\": 0.977,\n",
    "                \"relevancy\": 0.977\n",
    "            },\n",
    "            \"codeUrl\": \"https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_datasets/paul_graham_essay/llamaindex_baseline.py\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb93783-aa39-47c2-a449-7277c6d38901",
   "metadata": {},
   "source": [
    "#### Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f690e28a-a71a-4195-a817-5ff6c3009b59",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "    \"name\": <FILL-IN>,\n",
    "    \"description\": <FILL-IN>,\n",
    "    \"numberObservations\": <FILL-IN>,\n",
    "    \"containsExamplesByHumans\": <FILL-IN>,\n",
    "    \"containsExamplesByAI\": <FILL-IN>,\n",
    "    \"sourceUrls\": [\n",
    "        <FILL-IN>,\n",
    "    ],\n",
    "    \"baselines\": [\n",
    "        {\n",
    "            \"name\": <FILL-IN>,\n",
    "            \"config\": {\n",
    "                \"chunkSize\": <FILL-IN>,\n",
    "                \"llm\": <FILL-IN>,\n",
    "                \"similarityTopK\": <FILL-IN>,\n",
    "                \"embedModel\": <FILL-IN>\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"contextSimilarity\": <FILL-IN>,\n",
    "                \"correctness\": <FILL-IN>,\n",
    "                \"faithfulness\": <FILL-IN>,\n",
    "                \"relevancy\": <FILL-IN>\n",
    "            },\n",
    "            \"codeUrl\": <OPTIONAL-FILL-IN>\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3df415-b6e1-4bd9-9113-261c53a27ec7",
   "metadata": {},
   "source": [
    "#### `README.md`\n",
    "\n",
    "In this step, the minimum requirement is to take the template below and fill in the necessary items, which amounts to changing the name of the dataset to the one you'd like to use for your new submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44408187-bd23-4601-8219-13d1869762d0",
   "metadata": {},
   "source": [
    "#### Demonstration\n",
    "\n",
    "Click [here](https://raw.githubusercontent.com/run-llama/llama-hub/main/llama_hub/llama_datasets/paul_graham_essay/README.md) for an example `README.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de636bb-9efe-4f62-98dd-0c74b0e8f9cb",
   "metadata": {},
   "source": [
    "#### Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a0098-47f0-4fe3-beb8-dfc390303179",
   "metadata": {},
   "source": [
    "Click [here](https://raw.githubusercontent.com/run-llama/llama-hub/main/llama_hub/llama_datasets/template_README.md) for a template of `README.md`. Simply copy and paste the contents of that file and replace the placeholders \"[NAME]\" and \"[NAME-CAMELCASE]\" with the appropriate values according to your new dataset name choice. For example:\n",
    "- \"{NAME}\" = \"Paul Graham Essay Dataset\"\n",
    "- \"{NAME_CAMELCASE}\" = PaulGrahamEssayDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818bf2b-ed6f-4c59-80a5-50ce5c74b019",
   "metadata": {},
   "source": [
    "#### [Back to top](#top) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd76f13-6447-4e9f-a7ca-e906e486c066",
   "metadata": {},
   "source": [
    "<a id='Step4'></a>\n",
    "## 4. Submit Pull Request To [llama-hub](https://github.com/run-llama/llama-hub) Repo\n",
    "\n",
    "Now, is the time to submit the metadata for your new dataset and make a new entry in the datasets registry, which is stored in the file `library.json` (i.e., see it [here](https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_datasets/library.json)).\n",
    "\n",
    "### 4a. Create a new directory under `llama_hub/llama_datasets` and add your `card.json` and `README.md`:\n",
    "```bash\n",
    "cd llama-hub  # cd into local clone of llama-hub\n",
    "cd llama_hub/llama_datasets\n",
    "git checkout -b my-new-dataset  # create a new git branch\n",
    "mkdir <dataset_name_snake_case>  # follow convention of other datasets\n",
    "cd <dataset_name_snake_case>\n",
    "vim card.json # use vim or another text editor to add in the contents for card.json\n",
    "vim README.md # use vim or another text editor to add in the contents for README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1264fc9-6356-4d86-a5ec-20b454d93659",
   "metadata": {},
   "source": [
    "### 4b. Create an entry in `llama_hub/llama_datasets/library.json`\n",
    "\n",
    "```bash\n",
    "cd llama_hub/llama_datasets\n",
    "vim library.json # use vim or another text editor to register your new dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c4ce8e-2fb1-4c89-8453-e66aee3a1241",
   "metadata": {},
   "source": [
    "#### Demonstration of `library.json`\n",
    "\n",
    "```json\n",
    "  \"PaulGrahamEssayDataset\": {\n",
    "    \"id\": \"llama_datasets/paul_graham_essay\",\n",
    "    \"author\": \"nerdai\",\n",
    "    \"keywords\": [\"rag\"]\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1448f2-ce6b-4368-b737-abf7682eaed9",
   "metadata": {},
   "source": [
    "#### Template of `library.json`\n",
    "\n",
    "```json\n",
    "  \"<FILL-IN>\": {\n",
    "    \"id\": \"llama_datasets/<dataset_name_snake_case>\",\n",
    "    \"author\": \"<FILL-IN>\",\n",
    "    \"keywords\": [\"rag\"]\n",
    "  }\n",
    "```\n",
    "\n",
    "**NOTE**: Please use the same `dataset_name_snake_case` as used in 4a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af297ba-05fa-4a89-b52c-89cd9faaf258",
   "metadata": {},
   "source": [
    "### 4c. `git add` and `commit` your changes then push to your fork\n",
    "\n",
    "```bash\n",
    "git add .\n",
    "git commit -m \"my new dataset submission\"\n",
    "git push origin my-new-dataset\n",
    "```\n",
    "\n",
    "After this, head over to the Github page for [llama-hub](https://github.com/run-llama/llama-hub). You should see the option to make a pull request from your fork. Go ahead and do that now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f1a1b-d05b-40a7-85e3-4d6adf8b776a",
   "metadata": {},
   "source": [
    "#### [Back to top](#top) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b840af1-1272-4e65-b9fd-ab295ef27358",
   "metadata": {},
   "source": [
    "<a id='Step5'></a>\n",
    "## 5. Submit Pull Request To [llama-datasets](https://github.com/run-llama/llama-datasets) Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7365bf7d-548d-472f-942e-fc8635e51945",
   "metadata": {},
   "source": [
    "In this final step of the submission process, you will submit the actual `LabelledRagDataset` (in json format) as well as the source data files to the `llama-datasets` Github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70666fb-e4f2-4409-bdb2-86511c946067",
   "metadata": {},
   "source": [
    "### 5a. Create a new directory under `llama_datasets/`:\n",
    "\n",
    "```bash\n",
    "cd llama-datasets # cd into local clone of llama-datasets\n",
    "git checkout -b my-new-dataset  # create a new git branch\n",
    "mkdir <dataset_name_snake_case>  # use the same name as used in Step 4.\n",
    "cd <dataset_name_snake_case>\n",
    "cp <path-in-local-machine>/rag_dataset.json .  # add rag_dataset.json\n",
    "mkdir source_files  # time to add all of the source files\n",
    "cp -r <path-in-local-machine>/source_files  ./source_files  # add all source files\n",
    "```\n",
    "\n",
    "**NOTE**: Please use the same `dataset_name_snake_case` as used in Step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45ea83-a6e5-47d4-9de4-d38ea1d57971",
   "metadata": {},
   "source": [
    "### 5b. `git add` and `commit` your changes then push to your fork\n",
    "\n",
    "```bash\n",
    "git add .\n",
    "git commit -m \"my new dataset submission\"\n",
    "git push origin my-new-dataset\n",
    "```\n",
    "\n",
    "After this, head over to Github page for [llama-datasets](https://github.com/run-llama/llama-datasets). You should see the option to make a pull request from your fork. Go ahead and do that now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebdd568-2e61-4b9c-9c6b-f72875df6f26",
   "metadata": {},
   "source": [
    "#### [Back to top](#top) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de772756-9c34-43fe-9e17-355de03affe8",
   "metadata": {},
   "source": [
    "## Et Voila !\n",
    "\n",
    "You've made it to the end of the dataset submission process!  Congratulations, and thank you for your contribution!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_3.10",
   "language": "python",
   "name": "llama_index_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
