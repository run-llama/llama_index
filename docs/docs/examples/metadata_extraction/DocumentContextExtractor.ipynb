{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTEXTUAL RETRIEVAL WITH LLAMA_INDEX\n",
    "\n",
    "This notebook covers contextual retrieval with llama_index DocumentContextExtractor\n",
    "\n",
    "Based on an Anthropic [blost post](https://www.anthropic.com/news/contextual-retrieval), the concept is to:\n",
    "1. Use an LLM to generate a 'context' for each chunk based on the entire document\n",
    "2. embed the chunk + context together\n",
    "3. reap the benefits of higher RAG accuracy\n",
    "\n",
    "While you can also do this manually, the DocumentContextExtractor offers a lot of convenience and error handling, plus you can integrate it into your llama_index pipelines! Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTALL PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-file in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (0.4.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-readers-file) (0.12.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-readers-file) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-readers-file) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-readers-file) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.2.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2024.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.10.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pandas->llama-index-readers-file) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-embeddings-huggingface) (0.12.5)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-embeddings-huggingface) (3.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.11.10)\n",
      "Requirement already satisfied: minijinja>=1.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.5.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.2.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.10.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.17.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-llms-huggingface-api in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-llms-huggingface-api) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-llms-huggingface-api) (0.12.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.2.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.2.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.10.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-huggingface-api) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-llms-openai\n",
      "  Using cached llama_index_llms_openai-0.3.12-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.4 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-llms-openai) (0.12.5)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from llama-index-llms-openai)\n",
      "  Using cached openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.2.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.10.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.17.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.18.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->llama-index-llms-openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->llama-index-llms-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (3.23.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.4->llama-index-llms-openai) (24.2)\n",
      "Using cached llama_index_llms_openai-0.3.12-py3-none-any.whl (14 kB)\n",
      "Using cached openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "Installing collected packages: openai, llama-index-llms-openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.57.2\n",
      "    Uninstalling openai-1.57.2:\n",
      "      Successfully uninstalled openai-1.57.2\n",
      "Successfully installed llama-index-llms-openai-0.3.12 openai-1.58.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Obtaining file:///C:/Users/cklap/llama_index/llama-index-core\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.12.5) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (1.0.8)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (0.2.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (2024.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (2.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (2.10.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from llama-index-core==0.12.5) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.12.5) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.12.5) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.12.5) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.12.5) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.12.5) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.12.5) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.12.5) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.12.5) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core==0.12.5) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core==0.12.5) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core==0.12.5) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core==0.12.5) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core==0.12.5) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.12.5) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.12.5) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.12.5) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core==0.12.5) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.12.5) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core==0.12.5) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core==0.12.5) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core==0.12.5) (3.23.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core==0.12.5) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpx->llama-index-core==0.12.5) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core==0.12.5) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.12.5) (24.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core==0.12.5) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cklap\\llama_index\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core==0.12.5) (1.3.1)\n",
      "Building wheels for collected packages: llama-index-core\n",
      "  Building editable for llama-index-core (pyproject.toml): started\n",
      "  Building editable for llama-index-core (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-index-core: filename=llama_index_core-0.12.5-py3-none-any.whl size=2860 sha256=d1a6b7410feea6a2dc56898ab46804c6788ae0d047b0bb407d7e649dcf10e988\n",
      "  Stored in directory: C:\\Users\\cklap\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-5toukz54\\wheels\\2d\\25\\68\\7ab0dd2755e5dc74690e7d6b9cb1c2241bfa8c9efd536d2973\n",
      "Successfully built llama-index-core\n",
      "Installing collected packages: llama-index-core\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.12.5\n",
      "    Uninstalling llama-index-core-0.12.5:\n",
      "      Successfully uninstalled llama-index-core-0.12.5\n",
      "Successfully installed llama-index-core-0.12.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-readers-file\n",
    "%pip install llama-index-embeddings-huggingface\n",
    "%pip install llama-index-llms-openai\n",
    "%pip install -e \"C:\\\\Users\\\\cklap\\\\llama_index\\\\llama-index-core\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP AN LLM\n",
    "You can use the MockLLM or you can use a real LLM of your choice here. flash 2 and gpt-4o-mini work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "OPENAI_API_KEY = \"\"\n",
    "llm = OpenAI(model=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #Setup a data pipeline\n",
    "\n",
    " we'll need an embedding model, an index store, a vectore store, and a way to split tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline & Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.storage.index_store.simple_index_store import (\n",
    "    SimpleIndexStore,\n",
    ")\n",
    "from llama_index.core.vector_stores.simple import SimpleVectorStore\n",
    "from llama_index.core.storage.docstore.simple_docstore import (\n",
    "    SimpleDocumentStore,\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Initialize document store and embedding model\n",
    "docstore = SimpleDocumentStore()\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create storage context\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    separator=\" \", chunk_size=512, chunk_overlap=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DocumentContextExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the new part!\n",
    "\n",
    "from llama_index.core.extractors import DocumentContextExtractor\n",
    "\n",
    "context_extractor = DocumentContextExtractor(\n",
    "    # mandatory\n",
    "    docstore=docstore,\n",
    "    max_context_length=128000,\n",
    "    # optional\n",
    "    llm=llm,  # default to Settings.llm\n",
    "    oversized_document_strategy=\"warn\",\n",
    "    max_output_tokens=100,\n",
    "    key=\"context\",\n",
    "    prompt=DocumentContextExtractor.ORIGINAL_CONTEXT_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=[],\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    transformations=[text_splitter, context_extractor],\n",
    ")\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "index_nocontext = VectorStoreIndex.from_documents(\n",
    "    documents=[],\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    transformations=[text_splitter],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\" \"paul_graham_essay.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=[\"paul_graham_essay.txt\"])\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the pipeline, then search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:01<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# have to keep this updated for the DocumentContextExtractor to function.\n",
    "# everytime we insert a doc the entire pipeline will run and context will be generated\n",
    "storage_context.docstore.add_documents(documents)\n",
    "for doc in documents:\n",
    "    index.insert(doc)\n",
    "    index_nocontext.insert(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all nodes have context\n",
    "assert context_extractor.is_job_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "NO CONTEXT\n",
      "\n",
      "Chunk 1:\n",
      "Score: 0.1881885285336999\n",
      "Content: I met the Reddits before we even started Y Combinator. In fact they were one of the reasons we started it.\n",
      "\n",
      "YC grew out of a talk I gave to the Harvard Computer Society (the undergrad computer club) about how to start a startup. Everyone else in the audience was probably local, but Steve and Alexis came up on the train from the University of Virginia, where they were seniors. Since they'd come so far I agreed to meet them for coffee. They told me about the startup idea we'd later fund them to drop: a way to order fast food on your cellphone.\n",
      "\n",
      "This was before smartphones. They'd have had to make deals with cell carriers and fast food chains just to get it launched. So it was not going to happen. It still doesn't exist, 19 years later. But I was impressed with their brains and their energy. In fact I was so impressed with them and some of the other people I met at that talk that I decided to start something to fund them. A few days later I told Steve and Alexis that we were starting Y Combinator, and encouraged them to apply.\n",
      "\n",
      "That first batch we didn't have any way to identify applicants, so we made up nicknames for them. The Reddits were the \"Cell food muffins.\" \"Muffin\" is a term of endearment Jessica uses for things like small dogs and two year olds. So that gives you some idea what kind of impression Steve and Alexis made in those days. They had the look of slightly ruffled surprise that baby birds have.\n",
      "\n",
      "Their idea was bad though. And since we thought then that we were funding ideas rather than founders, we rejected them. But we felt bad about it. Jessica was sad that we'd rejected the muffins. And it seemed wrong to me to turn down the people we'd been inspired to start YC to fund.\n",
      "\n",
      "I don't think the startup sense of the word \"pivot\" had been invented yet, but we wanted to fund Steve and Alexis, so if their idea was bad, they'd have to work on something else. And I knew what else. In those days there was a site called Delicious where you could save links. It had a page called del.icio.us/popular that listed the most-saved links, and people were using this page as a de facto Reddit. I knew because a lot of the traffic to my site was coming from it. There needed to be something like\n",
      "\n",
      "Chunk 2:\n",
      "Score: 0.16611732451563457\n",
      "Content: coming from it. There needed to be something like del.icio.us/popular, but designed for sharing links instead of being a byproduct of saving them.\n",
      "\n",
      "So I called Steve and Alexis and said that we liked them, just not their idea, so we'd fund them if they'd work on something else. They were on the train home to Virginia at that point. They got off at the next station and got on the next train north, and by the end of the day were committed to working on what's now called Reddit.\n",
      "\n",
      "They would have liked to call it Snoo, as in \"What snoo?\" But snoo.com was too expensive, so they settled for calling the mascot Snoo and picked a name for the site that wasn't registered. Early on Reddit was just a provisional name, or so they told me at least, but it's probably too late to change it now.\n",
      "\n",
      "As with all the really great startups, there's an uncannily close match between the company and the founders. Steve in particular. Reddit has a certain personality  curious, skeptical, ready to be amused  and that personality is Steve's.\n",
      "\n",
      "Steve will roll his eyes at this, but he's an intellectual; he's interested in ideas for their own sake. That was how he came to be in that audience in Cambridge in the first place. He knew me because he was interested in a programming language I've written about called Lisp, and Lisp is one of those languages few people learn except out of intellectual curiosity. Steve's kind of vacuum-cleaner curiosity is exactly what you want when you're starting a site that's a list of links to literally anything interesting.\n",
      "\n",
      "Steve was not a big fan of authority, so he also liked the idea of a site without editors. In those days the top forum for programmers was a site called Slashdot. It was a lot like Reddit, except the stories on the frontpage were chosen by human moderators. And though they did a good job, that one small difference turned out to be a big difference. Being driven by user submissions meant Reddit was fresher than Slashdot. News there was newer, and users will always go where the newest news is.\n",
      "\n",
      "I pushed the Reddits to launch fast. A version one didn't need to be more than a couple hundred lines of code. How could that take more than a week or two to build? And they did launch comparatively fast, about three weeks into the first YC batch. The\n",
      "\n",
      "Chunk 3:\n",
      "Score: 0.15013441897881055\n",
      "Content: three weeks into the first YC batch. The first users were Steve, Alexis, me, and some of their YC batchmates and college friends. It turns out you don't need that many users to collect a decent list of interesting links, especially if you have multiple accounts per user.\n",
      "\n",
      "Reddit got two more people from their YC batch: Chris Slowe and Aaron Swartz, and they too were unusually smart. Chris was just finishing his PhD in physics at Harvard. Aaron was younger, a college freshman, and even more anti-authority than Steve. It's not exaggerating to describe him as a martyr for what authority later did to him.\n",
      "\n",
      "Slowly but inexorably Reddit's traffic grew. At first the numbers were so small they were hard to distinguish from background noise. But within a few weeks it was clear that there was a core of real users returning regularly to the site. And although all kinds of things have happened to Reddit the company in the years since, Reddit the site never looked back.\n",
      "\n",
      "Reddit the site (and now app) is such a fundamentally useful thing that it's almost unkillable. Which is why, despite a long stretch after Steve left when the management strategy ranged from benign neglect to spectacular blunders, traffic just kept growing. You can't do that with most companies. Most companies you take your eye off the ball for six months and you're in deep trouble. But Reddit was special, and when Steve came back in 2015, I knew the world was in for a surprise.\n",
      "\n",
      "People thought they had Reddit's number: one of the players in Silicon Valley, but not one of the big ones. But those who knew what had been going on behind the scenes knew there was more to the story than this. If Reddit could grow to the size it had with management that was harmless at best, what could it do if Steve came back? We now know the answer to that question. Or at least a lower bound on the answer. Steve is not out of ideas yet.\n",
      "==========\n",
      "WITH CONTEXT\n",
      "\n",
      "Chunk 1:\n",
      "Score: 0.1881885285336999\n",
      "Content: I met the Reddits before we even started Y Combinator. In fact they were one of the reasons we started it.\n",
      "\n",
      "YC grew out of a talk I gave to the Harvard Computer Society (the undergrad computer club) about how to start a startup. Everyone else in the audience was probably local, but Steve and Alexis came up on the train from the University of Virginia, where they were seniors. Since they'd come so far I agreed to meet them for coffee. They told me about the startup idea we'd later fund them to drop: a way to order fast food on your cellphone.\n",
      "\n",
      "This was before smartphones. They'd have had to make deals with cell carriers and fast food chains just to get it launched. So it was not going to happen. It still doesn't exist, 19 years later. But I was impressed with their brains and their energy. In fact I was so impressed with them and some of the other people I met at that talk that I decided to start something to fund them. A few days later I told Steve and Alexis that we were starting Y Combinator, and encouraged them to apply.\n",
      "\n",
      "That first batch we didn't have any way to identify applicants, so we made up nicknames for them. The Reddits were the \"Cell food muffins.\" \"Muffin\" is a term of endearment Jessica uses for things like small dogs and two year olds. So that gives you some idea what kind of impression Steve and Alexis made in those days. They had the look of slightly ruffled surprise that baby birds have.\n",
      "\n",
      "Their idea was bad though. And since we thought then that we were funding ideas rather than founders, we rejected them. But we felt bad about it. Jessica was sad that we'd rejected the muffins. And it seemed wrong to me to turn down the people we'd been inspired to start YC to fund.\n",
      "\n",
      "I don't think the startup sense of the word \"pivot\" had been invented yet, but we wanted to fund Steve and Alexis, so if their idea was bad, they'd have to work on something else. And I knew what else. In those days there was a site called Delicious where you could save links. It had a page called del.icio.us/popular that listed the most-saved links, and people were using this page as a de facto Reddit. I knew because a lot of the traffic to my site was coming from it. There needed to be something like\n",
      "\n",
      "Chunk 2:\n",
      "Score: 0.16611732451563457\n",
      "Content: coming from it. There needed to be something like del.icio.us/popular, but designed for sharing links instead of being a byproduct of saving them.\n",
      "\n",
      "So I called Steve and Alexis and said that we liked them, just not their idea, so we'd fund them if they'd work on something else. They were on the train home to Virginia at that point. They got off at the next station and got on the next train north, and by the end of the day were committed to working on what's now called Reddit.\n",
      "\n",
      "They would have liked to call it Snoo, as in \"What snoo?\" But snoo.com was too expensive, so they settled for calling the mascot Snoo and picked a name for the site that wasn't registered. Early on Reddit was just a provisional name, or so they told me at least, but it's probably too late to change it now.\n",
      "\n",
      "As with all the really great startups, there's an uncannily close match between the company and the founders. Steve in particular. Reddit has a certain personality  curious, skeptical, ready to be amused  and that personality is Steve's.\n",
      "\n",
      "Steve will roll his eyes at this, but he's an intellectual; he's interested in ideas for their own sake. That was how he came to be in that audience in Cambridge in the first place. He knew me because he was interested in a programming language I've written about called Lisp, and Lisp is one of those languages few people learn except out of intellectual curiosity. Steve's kind of vacuum-cleaner curiosity is exactly what you want when you're starting a site that's a list of links to literally anything interesting.\n",
      "\n",
      "Steve was not a big fan of authority, so he also liked the idea of a site without editors. In those days the top forum for programmers was a site called Slashdot. It was a lot like Reddit, except the stories on the frontpage were chosen by human moderators. And though they did a good job, that one small difference turned out to be a big difference. Being driven by user submissions meant Reddit was fresher than Slashdot. News there was newer, and users will always go where the newest news is.\n",
      "\n",
      "I pushed the Reddits to launch fast. A version one didn't need to be more than a couple hundred lines of code. How could that take more than a week or two to build? And they did launch comparatively fast, about three weeks into the first YC batch. The\n",
      "\n",
      "Chunk 3:\n",
      "Score: 0.15013441897881055\n",
      "Content: three weeks into the first YC batch. The first users were Steve, Alexis, me, and some of their YC batchmates and college friends. It turns out you don't need that many users to collect a decent list of interesting links, especially if you have multiple accounts per user.\n",
      "\n",
      "Reddit got two more people from their YC batch: Chris Slowe and Aaron Swartz, and they too were unusually smart. Chris was just finishing his PhD in physics at Harvard. Aaron was younger, a college freshman, and even more anti-authority than Steve. It's not exaggerating to describe him as a martyr for what authority later did to him.\n",
      "\n",
      "Slowly but inexorably Reddit's traffic grew. At first the numbers were so small they were hard to distinguish from background noise. But within a few weeks it was clear that there was a core of real users returning regularly to the site. And although all kinds of things have happened to Reddit the company in the years since, Reddit the site never looked back.\n",
      "\n",
      "Reddit the site (and now app) is such a fundamentally useful thing that it's almost unkillable. Which is why, despite a long stretch after Steve left when the management strategy ranged from benign neglect to spectacular blunders, traffic just kept growing. You can't do that with most companies. Most companies you take your eye off the ball for six months and you're in deep trouble. But Reddit was special, and when Steve came back in 2015, I knew the world was in for a surprise.\n",
      "\n",
      "People thought they had Reddit's number: one of the players in Silicon Valley, but not one of the big ones. But those who knew what had been going on behind the scenes knew there was more to the story than this. If Reddit could grow to the size it had with management that was harmless at best, what could it do if Steve came back? We now know the answer to that question. Or at least a lower bound on the answer. Steve is not out of ideas yet.\n"
     ]
    }
   ],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "nodes_fromcontext = retriever.retrieve(\"Who is Paul Graham.\")\n",
    "\n",
    "retriever_nocontext = index_nocontext.as_retriever(similarity_top_k=5)\n",
    "nodes_nocontext = retriever.retrieve(\"Who is Paul Graham.\")\n",
    "# Print each node's content\n",
    "print(\"==========\")\n",
    "print(\"NO CONTEXT\")\n",
    "for i, node in enumerate(nodes_nocontext, 1):\n",
    "    print(f\"\\nChunk {i}:\")\n",
    "    print(f\"Score: {node.score}\")  # Similarity score\n",
    "    print(f\"Content: {node.node.text}\")  # The actual text content\n",
    "\n",
    "# Print each node's content\n",
    "print(\"==========\")\n",
    "print(\"WITH CONTEXT\")\n",
    "for i, node in enumerate(nodes_fromcontext, 1):\n",
    "    print(f\"\\nChunk {i}:\")\n",
    "    print(f\"Score: {node.score}\")  # Similarity score\n",
    "    print(f\"Content: {node.node.text}\")  # The actual text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index and vectorstore, cause it can take time and money to generate context!\n",
    "\n",
    "# for google drive support\n",
    "# persist_dir = '/content/drive/MyDrive/your_project_folder'\n",
    "persist_dir = \"./\"\n",
    "storage_context.persist(persist_dir=persist_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
