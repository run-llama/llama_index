{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index llama-index-embeddings-openai llama-index-graph-stores-kuzu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kùzu](https://kuzudb.com/) is an open source, embedded graph database that's designed for query speed and scalability. It implements the Cypher query language, and utilizes a structured property graph model (a variant of the labelled property graph model) with support for ACID transactions. Because Kùzu is embedded, there's no requirement for a server to set up and use the database.\n",
    "\n",
    "If you already have an existing graph, please skip to the end of this notebook. Otherwise, let's begin by creating a graph from unstructured text to demonstrate how to use Kùzu as a graph store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"enter your key here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using OpenAI models for this example, so we'll specify the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-27 16:12:46--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8002::154, 2606:50c0:8000::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
      "\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-08-27 16:12:47 (1.61 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "We first need to create an empty Kùzu database directory by calling the `kuzu.Database` constructor. This step instantiates the database and creates the necessary directories and files within a local directory that stores the graph. This `Database` object is then passed to the `KuzuPropertyGraph` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import kuzu\n",
    "\n",
    "shutil.rmtree(\"test_db\", ignore_errors=True)\n",
    "db = kuzu.Database(\"test_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.kuzu import KuzuPropertyGraphStore\n",
    "\n",
    "graph_store = KuzuPropertyGraphStore(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Kùzu implements the structured graph property model, it imposes some level of structure on the schema of the graph. In the above case, because we did not specify a relationship schema that we want in our graph, it uses a generic schema, where the relationship types are not constrained, allowing the extracted triples from the LLM to be stored as relationships in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models\n",
    "\n",
    "Below, we'll define the models used for embedding the text and the LLMs that are used to extract triples from the text and generate the response.\n",
    "In this case, we specify different temperature settings for the same model - the extraction model has a temperature of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "extract_llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "generate_llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create property graph index without imposing structure\n",
    "\n",
    "Because we didn't specify the relationship schema above, we can simply invoke the `SchemaLLMPathExtractor` to extract the triples from the text and store them in the graph. We can define the property graph index using Kùzu as the graph store, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 17.81it/s]\n",
      "Extracting paths from text with schema: 100%|██████████| 22/22 [00:31<00:00,  1.43s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:00<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=embed_model,\n",
    "    kg_extractors=[SchemaLLMPathExtractor(extract_llm)],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the graph is created, we can explore it in [Kùzu Explorer](https://docs.kuzudb.com/visualization/), a web-base UI, by running a Docker container that pulls the latest image of Kùzu Explorer as follows:\n",
    "```bash\n",
    "docker run -p 8000:8000 \\\n",
    "           -v ./test_db:/database \\\n",
    "           --rm kuzudb/explorer:latest\n",
    "```\n",
    "\n",
    "Then, launch the UI and then visting [http://localhost:8000/](http://localhost:8000/). \n",
    "\n",
    "The easiest way to see the entire graph is to use a Cypher query like `\"match (a)-[b]->(c) return * limit 200\"`.\n",
    "\n",
    "To delete the entire graph, you can either delete the `./test_db` directory that contains the database files, or run the Cypher query `\"match (n) detach delete n\"` in the Kùzu Explorer shell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaf and Viaweb are both products associated with the development of software solutions. Interleaf is linked to Lisp, indicating a relationship where Interleaf may utilize or be built upon Lisp programming language capabilities. Viaweb, on the other hand, is identified as an ecommerce software product and also has a connection to Lisp, suggesting that it may incorporate Lisp in its architecture or functionality. Both products are documented in a text file, which includes details about their creation and modification dates, file size, and type.\n"
     ]
    }
   ],
   "source": [
    "# Switch to the generate LLM during retrieval\n",
    "Settings.llm = generate_llm\n",
    "\n",
    "query_engine = index.as_query_engine(include_text=False)\n",
    "\n",
    "response = query_engine.query(\"Tell me more about Interleaf and Viaweb\")\n",
    "\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create property graph index with structure\n",
    "\n",
    "The recommended way to use Kùzu is to apply a structured schema to the graph. The schema is defined by specifying the relationship types (including direction) that we want in the graph. The imposition of structure helps with generating triples that are more meaningful for the types of questions we may want to answer from the graph.\n",
    "\n",
    "By specifying the below validation schema, we can enforce that the graph only contains relationships of the specified types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "entities = Literal[\"PERSON\", \"PLACE\", \"ORGANIZATION\"]\n",
    "relations = Literal[\"HAS\", \"PART_OF\", \"WORKED_ON\", \"WORKED_WITH\", \"WORKED_AT\"]\n",
    "# Define the relationship schema that we will pass to our graph store\n",
    "# This must be a list of valid triples in the form (head_entity, relation, tail_entity)\n",
    "validation_schema = [\n",
    "    (\"ORGANIZATION\", \"HAS\", \"PERSON\"),\n",
    "    (\"PERSON\", \"WORKED_AT\", \"ORGANIZATION\"),\n",
    "    (\"PERSON\", \"WORKED_WITH\", \"PERSON\"),\n",
    "    (\"PERSON\", \"WORKED_ON\", \"ORGANIZATION\"),\n",
    "    (\"PERSON\", \"PART_OF\", \"ORGANIZATION\"),\n",
    "    (\"ORGANIZATION\", \"PART_OF\", \"ORGANIZATION\"),\n",
    "    (\"PERSON\", \"WORKED_AT\", \"PLACE\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new empty database\n",
    "shutil.rmtree(\"test_db\", ignore_errors=True)\n",
    "db = kuzu.Database(\"test_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with the `Database` constructor, we also specify two additional arguments to the property graph store: `has_structured_schema=True` and `relationship_schema=validation_schema`, which provides Kùzu additional information as it instantiates a new graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = KuzuPropertyGraphStore(\n",
    "    db,\n",
    "    has_structured_schema=True,\n",
    "    relationship_schema=validation_schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a property graph with the desired schema, observe that we specify a few additional arguments to the `SchemaLLMPathExtractor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s]\n",
      "Extracting paths from text with schema: 100%|██████████| 22/22 [00:29<00:00,  1.34s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Generating embeddings: 100%|██████████| 4/4 [00:01<00:00,  3.69it/s]\n"
     ]
    }
   ],
   "source": [
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    "    kg_extractors=[\n",
    "        SchemaLLMPathExtractor(\n",
    "            llm=OpenAI(model=\"gpt-4o-mini\", temperature=0.0),\n",
    "            possible_entities=entities,\n",
    "            possible_relations=relations,\n",
    "            kg_validation_schema=validation_schema,\n",
    "            strict=True,  # if false, will allow triples outside of the schema\n",
    "        )\n",
    "    ],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the query engine on the index as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interleaf and Viaweb are both organizations mentioned in the provided information. Interleaf is associated with Emacs, indicating a connection to text editing or software development environments. Viaweb, on the other hand, has several associations, including individuals like Julian and Idelle, as well as the programming language Lisp. This suggests that Viaweb may have a broader scope, potentially involving web development or e-commerce, given its historical context as an early web application platform. Both organizations appear to have been referenced in a document related to Paul Graham, indicating their relevance in discussions around technology or entrepreneurship.\n"
     ]
    }
   ],
   "source": [
    "# Switch to the generate LLM during retrieval\n",
    "Settings.llm = generate_llm\n",
    "\n",
    "query_engine = index.as_query_engine(include_text=False)\n",
    "\n",
    "response2 = query_engine.query(\"Tell me more about Interleaf and Viaweb\")\n",
    "print(str(response2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use existing graph\n",
    "\n",
    "You can reuse an existing `Database` object to connect to its underlying `PropertyGraphIndex`. This is useful when you want to query the graph without having to re-extract the triples from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viaweb was founded by Paul Graham. The specific founding date is not provided in the information available.\n"
     ]
    }
   ],
   "source": [
    "graph_store = KuzuPropertyGraphStore(db)\n",
    "\n",
    "# Set up the property graph index\n",
    "index = PropertyGraphIndex.from_existing(\n",
    "    embed_model=embed_model,\n",
    "    llm=generate_llm,\n",
    "    property_graph_store=graph_store,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine(include_text=False)\n",
    "\n",
    "response3 = query_engine.query(\"When was Viaweb founded, and by whom?\")\n",
    "print(str(response3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full details on construction, retrieval, querying of a property graph, see the [full docs page](/../../module_guides/indexing/lpg_index_guide)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
