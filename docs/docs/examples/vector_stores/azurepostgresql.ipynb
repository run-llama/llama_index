{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd8cd46",
   "metadata": {},
   "source": [
    "# Azure Postgres Vector Store\n",
    "In this notebook we are going to show how to use [Azure Postgresql](https://azure.microsoft.com/en-au/products/postgresql) and  [pg_diskann](https://github.com/microsoft/DiskANN) to perform vector searches in LlamaIndex. \n",
    "Please note that this document is mostly based on the document for [PostgreSQL integration](https://docs.llamaindex.ai/en/stable/examples/vector_stores/postgres/) to simplify the transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece76c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# TODO: This is necessary for now to use the package without building it. Once the PR is merged: remove this step.\n",
    "# Add the azurepostgresql integration path to Python path\n",
    "azurepostgresql_path = os.path.join('../../../../', \"llama-index-integrations/vector_stores/llama-index-vector-stores-azurepostgresql/src/\")\n",
    "if azurepostgresql_path not in sys.path:\n",
    "    sys.path.insert(0, azurepostgresql_path)\n",
    "\n",
    "# Uncomment to see debug logs\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "import textwrap\n",
    "\n",
    "# Import from the local file\n",
    "from llama_index.vector_stores.azure_postgres import AzurePGVectorStore\n",
    "from llama_index.vector_stores.azure_postgres.common import (\n",
    "    AzurePGConnectionPool,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc750f",
   "metadata": {},
   "source": [
    "### Setup OpenAI\n",
    "The first step is to configure the Azure openai key. It will be used to created embeddings for the documents loaded into the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Method 1: Using os.environ.get() with fallback values\n",
    "aoai_api_key = os.environ.get(\"AOAI_API_KEY\", \"key\")\n",
    "aoai_endpoint = os.environ.get(\"AOAI_ENDPOINT\", \"endpoint\")\n",
    "aoai_api_version = os.environ.get(\"AOAI_API_VERSION\", \"2024-12-01-preview\")\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"o4-mini\",\n",
    "    deployment_name=\"o4-mini\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    deployment_name=\"text-embedding-3-small\",\n",
    "    api_key=aoai_api_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_version=aoai_api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef64e3f",
   "metadata": {},
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9644d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1056a",
   "metadata": {},
   "source": [
    "### Loading documents\n",
    "Load the documents stored in the `data/paul_graham/` using the SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e41e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./data/paul_graham\").load_data()\n",
    "print(\"Document ID:\", documents[0].doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa5bc3",
   "metadata": {},
   "source": [
    "### Create the Database\n",
    "Using an existing postgres instance running on Azure, we will use Microsoft Entra authentication to connect to the database. Please make sure you are logged in to your Azure account.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = os.environ.get(\"PGHOST\", \"<your_host>\")\n",
    "port = os.environ.get(\"PGPORT\", 5432)\n",
    "database = os.environ.get(\"PGDATABASE\", \"postgres\")\n",
    "\n",
    "from psycopg import Connection\n",
    "from psycopg.rows import dict_row\n",
    "from llama_index.vector_stores.azure_postgres.common import ConnectionInfo, create_extensions, Extension\n",
    "\n",
    "def configure_connection(conn: Connection) -> None:\n",
    "    conn.autocommit = True\n",
    "    create_extensions(conn, [Extension(ext_name=\"vector\")])\n",
    "    create_extensions(conn, [Extension(ext_name=\"pg_diskann\")])\n",
    "    conn.row_factory = dict_row\n",
    "\n",
    "\n",
    "azure_conn_info: ConnectionInfo = ConnectionInfo(host=host, port=port, dbname=database, configure=configure_connection)\n",
    "conn = AzurePGConnectionPool(\n",
    "    azure_conn_info=azure_conn_info,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d3e11",
   "metadata": {},
   "source": [
    "### Create the index\n",
    "Here we create an index backed by Postgres using the documents loaded previously. AzurePGVectorStore takes a few arguments. The example below constructs a PGVectorStore with a pg_diskann index with max_neighbors = 32, l_value_ib = 100, and l_value_is = 100, with the `vector_cosine_ops` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c8526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_store = AzurePGVectorStore.from_params(\n",
    "    connection_pool=conn,\n",
    "    table_name=\"llamaindex_vectors\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    "    pg_diskann_kwargs={\n",
    "        \"pg_diskann_operator_class\": \"vector_cosine_ops\",\n",
    "        \"pg_diskann_max_neighbors\": 32,\n",
    "        \"pg_diskann_l_value_ib\" : 100,\n",
    "        \"pg_diskann_l_value_is\" : 100,\n",
    "    }\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, show_progress=True\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8cb8e",
   "metadata": {},
   "source": [
    "### Query the index\n",
    "We can now ask questions using our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What did the author do?\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2211642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What happened in the mid 1980s?\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0d3af",
   "metadata": {},
   "source": [
    "### Querying existing index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = AzurePGVectorStore.from_params(\n",
    "    connection_pool=conn,\n",
    "    schema_name=\"public\",\n",
    "    table_name=\"llamaindex_vectors\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    "    pg_diskann_kwargs={\n",
    "        \"pg_diskann_operator_class\": \"vector_cosine_ops\",\n",
    "        \"pg_diskann_max_neighbors\": 32,\n",
    "        \"pg_diskann_l_value_ib\" : 100,\n",
    "        \"pg_diskann_l_value_is\" : 100,\n",
    "        \"pg_diskann_iterative_search\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60569a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What did the author do?\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966d7bb",
   "metadata": {},
   "source": [
    "### Access individual nodes\n",
    "Read and delete a specific node by its id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3dedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = vector_store.get_nodes()\n",
    "print(len(nodes))\n",
    "node_id = nodes[0].node_id\n",
    "print(node_id)\n",
    "nodes = vector_store.get_nodes([node_id])\n",
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete_nodes(node_ids=[node_id])\n",
    "nodes = vector_store.get_nodes()\n",
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c68a15",
   "metadata": {},
   "source": [
    "### Metadata filters\n",
    "\n",
    "AzurePGVectorStore supports storing metadata in nodes, and filtering based on that metadata during the retrieval step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4acf74",
   "metadata": {},
   "source": [
    "#### Download git commits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6368602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p 'data/csv/'\n",
    "# !wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/csv/commit_history_2.csv' -O 'data/csv/commit_history_2.csv'\n",
    "import builtins\n",
    "import csv\n",
    "\n",
    "# TODO: Once the PR is merged: Change this to with open(\"data/csv/commit_history_2.csv\", \"r\") as f:\n",
    "with builtins.open(\"../data/csv/commit_history_2.csv\", \"r\") as f:\n",
    "    commits = list(csv.DictReader(f))\n",
    "\n",
    "print(commits[0])\n",
    "print(len(commits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1f6fd",
   "metadata": {},
   "source": [
    "#### Add nodes with custom metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TextNode for each of the first 100 commits\n",
    "from llama_index.core.schema import TextNode\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "nodes = []\n",
    "dates = set()\n",
    "authors = set()\n",
    "for commit in commits[:100]:\n",
    "    author_email = commit[\"author\"].split(\"<\")[1][:-1]\n",
    "    commit_date = datetime.strptime(\n",
    "        commit[\"date\"], \"%a %b %d %H:%M:%S %Y %z\"\n",
    "    ).strftime(\"%Y-%m-%d\")\n",
    "    commit_text = commit[\"change summary\"]\n",
    "    if commit[\"change details\"]:\n",
    "        commit_text += \"\\n\\n\" + commit[\"change details\"]\n",
    "    fixes = re.findall(r\"#(\\d+)\", commit_text, re.IGNORECASE)\n",
    "    nodes.append(\n",
    "        TextNode(\n",
    "            text=commit_text,\n",
    "            metadata={\n",
    "                \"commit_date\": commit_date,\n",
    "                \"author\": author_email,\n",
    "                \"fixes\": fixes,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    dates.add(commit_date)\n",
    "    authors.add(author_email)\n",
    "\n",
    "print(nodes[0])\n",
    "print(min(dates), \"to\", max(dates))\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = AzurePGVectorStore.from_params(\n",
    "    connection_pool=conn,\n",
    "    schema_name=\"public\",\n",
    "    table_name=\"metadata_filter_demo3\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    "    pg_diskann_kwargs={\n",
    "        \"pg_diskann_operator_class\": \"vector_cosine_ops\",\n",
    "        \"pg_diskann_max_neighbors\": 32,\n",
    "        \"pg_diskann_l_value_ib\" : 100,\n",
    "        \"pg_diskann_l_value_is\" : 100,\n",
    "    },\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83297f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index.as_query_engine().query(\"How did Leonhardt allow modal?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32eeb2d",
   "metadata": {},
   "source": [
    "#### Apply metadata filters\n",
    "\n",
    "Now we can filter by commit author or by date when retrieving nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.types import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"author\", value=\"matb@microsoft.com\"),\n",
    "        MetadataFilter(key=\"author\", value=\"benjamin.pasero@microsoft.com\"),\n",
    "    ],\n",
    "    condition=\"or\",\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=10,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "retrieved_nodes = retriever.retrieve(\"What is this software project about?\")\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    print(node.node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9ca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"commit_date\", value=\"2025-08-20\", operator=\">=\"),\n",
    "        MetadataFilter(key=\"commit_date\", value=\"2025-08-25\", operator=\"<=\"),\n",
    "    ],\n",
    "    condition=\"and\",\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=10,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "retrieved_nodes = retriever.retrieve(\"What is this software project about?\")\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    print(node.node.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abff37",
   "metadata": {},
   "source": [
    "#### Apply nested filters\n",
    "\n",
    "In the above examples, we combined multiple filters using AND or OR. We can also combine multiple sets of filters.\n",
    "\n",
    "e.g. in SQL:\n",
    "```sql\n",
    "WHERE (commit_date >= '2025-08-20' AND commit_date <= '2023-08-25') AND (author = 'matb@microsoft.com' OR author = 'benjamin.pasero@microsoft.com')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilters(\n",
    "            filters=[\n",
    "                MetadataFilter(\n",
    "                    key=\"commit_date\", value=\"2025-08-20\", operator=\">=\"\n",
    "                ),\n",
    "                MetadataFilter(\n",
    "                    key=\"commit_date\", value=\"2025-08-25\", operator=\"<=\"\n",
    "                ),\n",
    "            ],\n",
    "            condition=\"and\",\n",
    "        ),\n",
    "        MetadataFilters(\n",
    "            filters=[\n",
    "                MetadataFilter(key=\"author\", value=\"matb@microsoft.com\"),\n",
    "                MetadataFilter(key=\"author\", value=\"benjamin.pasero@microsoft.com\"),\n",
    "            ],\n",
    "            condition=\"or\",\n",
    "        ),\n",
    "    ],\n",
    "    condition=\"and\",\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=10,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "retrieved_nodes = retriever.retrieve(\"What is this software project about?\")\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    print(node.node.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce4d6f",
   "metadata": {},
   "source": [
    "The above can be simplified by using the IN operator. `AzurePGVectorStore` supports `in`, `nin`, and `contains` for comparing an element with a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cdc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"commit_date\", value=\"2025-08-15\", operator=\">=\"),\n",
    "        MetadataFilter(key=\"commit_date\", value=\"2025-08-20\", operator=\"<=\"),\n",
    "        MetadataFilter(\n",
    "            key=\"author\",\n",
    "            value=[\"matb@microsoft.com\", \"benjamin.pasero@microsoft.com\"],\n",
    "            operator=\"in\",\n",
    "        ),\n",
    "    ],\n",
    "    condition=\"and\",\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=10,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "retrieved_nodes = retriever.retrieve(\"What is this software project about?\")\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    print(node.node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing, with NOT IN\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"commit_date\", value=\"2025-08-15\", operator=\">=\"),\n",
    "        MetadataFilter(key=\"commit_date\", value=\"2025-08-20\", operator=\"<=\"),\n",
    "        MetadataFilter(\n",
    "            key=\"author\",\n",
    "            value=[\"matb@microsoft.com\", \"benjamin.pasero@microsoft.com\"],\n",
    "            operator=\"nin\",\n",
    "        ),\n",
    "    ],\n",
    "    condition=\"and\",\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=10,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "retrieved_nodes = retriever.retrieve(\"What is this software project about?\")\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    print(node.node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTAINS\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"fixes\", value=\"5680\", operator=\"contains\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(\n",
    "    similarity_top_k=10,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "retrieved_nodes = retriever.retrieve(\"How did these commits fix the issue?\")\n",
    "for node in retrieved_nodes:\n",
    "    print(node.node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21182ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
