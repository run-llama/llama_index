{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5860e4e-3775-41b9-8329-46a6d9568056",
   "metadata": {},
   "source": [
    "## Couchbase Vector Store\n",
    "[Couchbase](https://couchbase.com/) is an award-winning distributed NoSQL cloud database that delivers unmatched versatility, performance, scalability, and financial value for all of your cloud, mobile, AI, and edge computing applications. Couchbase embraces AI with coding assistance for developers and vector search for their applications.\n",
    "\n",
    "Vector Search is a part of the [Full Text Search Service](https://docs.couchbase.com/server/current/learn/services-and-indexes/services/search-service.html) (Search Service) in Couchbase.\n",
    "\n",
    "This tutorial explains how to use Vector Search in Couchbase. You can work with both [Couchbase Capella](https://www.couchbase.com/products/capella/) and your self-managed Couchbase Server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb82a99-965c-4a04-80d0-2baa91f5dcf0",
   "metadata": {},
   "source": [
    "### Installation\n",
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e1c57-f30c-4dd2-b1c0-91f80df7012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-couchbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d75ac-c7c2-444f-9a3d-adbdc6533160",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321020f-849a-4848-9747-b154ecd0a15e",
   "metadata": {},
   "source": [
    "### Creating Couchbase Connection\n",
    "We create a connection to the Couchbase cluster initially and then pass the cluster object to the Vector Store.\n",
    "\n",
    "Here, we are connecting using the username and password. You can also connect using any other supported way to your cluster.\n",
    "\n",
    "For more information on connecting to the Couchbase cluster, please check the [Python SDK documentation](https://docs.couchbase.com/python-sdk/current/hello-world/start-using-sdk.html#connect).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97805d01-3bd5-4933-82e1-6876c5101e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUCHBASE_CONNECTION_STRING = (\n",
    "    \"couchbase://localhost\"  # or \"couchbases://localhost\" if using TLS\n",
    ")\n",
    "DB_USERNAME = \"Administrator\"\n",
    "DB_PASSWORD = \"P@ssword1!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22874017-6010-4a2f-899e-08904a3108ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "from couchbase.auth import PasswordAuthenticator\n",
    "from couchbase.cluster import Cluster\n",
    "from couchbase.options import ClusterOptions\n",
    "\n",
    "auth = PasswordAuthenticator(DB_USERNAME, DB_PASSWORD)\n",
    "options = ClusterOptions(auth)\n",
    "cluster = Cluster(COUCHBASE_CONNECTION_STRING, options)\n",
    "\n",
    "# Wait until the cluster is ready for use.\n",
    "cluster.wait_until_ready(timedelta(seconds=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368c1c4-3f31-40e2-afee-5b6567445ff0",
   "metadata": {},
   "source": [
    "### Creating the Search Index\n",
    "Currently, the Search index needs to be created from the Couchbase Capella or Server UI or using the REST interface.\n",
    "\n",
    "Let us define a Search index with the name `vector-index` on the `testing` bucket\n",
    "\n",
    "For this example, let us use the Import Index feature on the Search Service on the UI.\n",
    "\n",
    "We are defining an index on the testing bucketâ€™s `_default` scope on the `_default` collection with the vector field set to `embedding` with 1536 dimensions and the text field set to text. We are also indexing and storing all the fields under metadata in the document as a dynamic mapping to account for varying document structures. The similarity metric is set to `dot_product`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b944c44-a891-455a-b6d9-9c5c44fdd397",
   "metadata": {},
   "source": [
    "#### How to Import an Index to the Full Text Search service?\n",
    "\n",
    "- [Couchbase Server](https://docs.couchbase.com/server/current/search/import-search-index.html)\n",
    "    - Click on Search -> Add Index -> Import\n",
    "    - Copy the following Index definition in the Import screen\n",
    "    - Click on Create Index to create the index.\n",
    "\n",
    "\n",
    "- [Couchbase Capella](https://docs.couchbase.com/cloud/search/import-search-index.html)\n",
    "    - Copy the index definition to a new file `index.json`\n",
    "    - Import the file in Capella using the instructions in the documentation.\n",
    "    - Click on Create Index to create the index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984c13c-149e-461d-9859-be50bce17bab",
   "metadata": {},
   "source": [
    "#### Index Definition\n",
    "```\n",
    "{\n",
    " \"name\": \"vector-index\",\n",
    " \"type\": \"fulltext-index\",\n",
    " \"params\": {\n",
    "  \"doc_config\": {\n",
    "   \"docid_prefix_delim\": \"\",\n",
    "   \"docid_regexp\": \"\",\n",
    "   \"mode\": \"type_field\",\n",
    "   \"type_field\": \"type\"\n",
    "  },\n",
    "  \"mapping\": {\n",
    "   \"default_analyzer\": \"standard\",\n",
    "   \"default_datetime_parser\": \"dateTimeOptional\",\n",
    "   \"default_field\": \"_all\",\n",
    "   \"default_mapping\": {\n",
    "    \"dynamic\": true,\n",
    "    \"enabled\": true,\n",
    "    \"properties\": {\n",
    "     \"metadata\": {\n",
    "      \"dynamic\": true,\n",
    "      \"enabled\": true\n",
    "     },\n",
    "     \"embedding\": {\n",
    "      \"enabled\": true,\n",
    "      \"dynamic\": false,\n",
    "      \"fields\": [\n",
    "       {\n",
    "        \"dims\": 1536,\n",
    "        \"index\": true,\n",
    "        \"name\": \"embedding\",\n",
    "        \"similarity\": \"dot_product\",\n",
    "        \"type\": \"vector\",\n",
    "        \"vector_index_optimized_for\": \"recall\"\n",
    "       }\n",
    "      ]\n",
    "     },\n",
    "     \"text\": {\n",
    "      \"enabled\": true,\n",
    "      \"dynamic\": false,\n",
    "      \"fields\": [\n",
    "       {\n",
    "        \"index\": true,\n",
    "        \"name\": \"text\",\n",
    "        \"store\": true,\n",
    "        \"type\": \"text\"\n",
    "       }\n",
    "      ]\n",
    "     }\n",
    "    }\n",
    "   },\n",
    "   \"default_type\": \"_default\",\n",
    "   \"docvalues_dynamic\": false,\n",
    "   \"index_dynamic\": true,\n",
    "   \"store_dynamic\": true,\n",
    "   \"type_field\": \"_type\"\n",
    "  },\n",
    "  \"store\": {\n",
    "   \"indexType\": \"scorch\",\n",
    "   \"segmentVersion\": 16\n",
    "  }\n",
    " },\n",
    " \"sourceType\": \"gocbcore\",\n",
    " \"sourceName\": \"testing\",\n",
    " \"sourceParams\": {},\n",
    " \"planParams\": {\n",
    "  \"maxPartitionsPerPIndex\": 103,\n",
    "  \"indexPartitions\": 10,\n",
    "  \"numReplicas\": 0\n",
    " }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99315a8-9274-4df7-89c8-5d45f2cda82d",
   "metadata": {},
   "source": [
    "We will now set the bucket, scope, and collection names in the Couchbase cluster that we want to use for Vector Search.\n",
    "\n",
    "For this example, we are using the default scope & collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096cd6f-61b5-4d33-8d78-6d81fd5d8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"testing\"\n",
    "SCOPE_NAME = \"_default\"\n",
    "COLLECTION_NAME = \"_default\"\n",
    "SEARCH_INDEX_NAME = \"vector-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad4f59-05fd-4700-8a7b-c9df44c4a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import Settings\n",
    "from llama_index.vector_stores.couchbase import CouchbaseSearchVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b979489-7139-498a-a4b9-b7045756fda0",
   "metadata": {},
   "source": [
    "For this tutorial, we will use OpenAI embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df1e42-bc0a-47c5-b682-da2608ffa5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73e27a-460f-49b3-9311-6f6f18325de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcb0a8-d93e-4914-a41a-bf4c9a6c0e66",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd02c6c-c8d1-4f48-931e-459483056d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-09 23:31:46--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: â€˜data/paul_graham/paul_graham_essay.txtâ€™\n",
      "\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2024-04-09 23:31:46 (8.97 MB/s) - â€˜data/paul_graham/paul_graham_essay.txtâ€™ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638c82b-cee6-4472-87ca-ea5093a9f9df",
   "metadata": {},
   "source": [
    "#### Load the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a3c07-1155-4b91-9303-09f64f0e6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcb0dc-fec4-4e13-b783-37b462744d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = CouchbaseSearchVectorStore(\n",
    "    cluster=cluster,\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    scope_name=SCOPE_NAME,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_name=SEARCH_INDEX_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f39bc1-ec01-4709-90bd-55cb6161f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05c1f5-caea-41c0-afc9-594c6ba27d1c",
   "metadata": {},
   "source": [
    "### Basic Example\n",
    "We will ask the query engine a question about the essay we just indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a589d0-390f-4895-8d58-769014a3ca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "His investments in Y Combinator were $6k per founder, totaling $12k in the typical two-founder case, in return for 6% equity.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What were his investments in Y Combinator?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc945757-a212-4e73-8e9a-fecb27dc1472",
   "metadata": {},
   "source": [
    "### Metadata Filters\n",
    "We will create some example documents with metadata so that we can see how to filter documents based on metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9d195-8265-48fe-baa3-5f7b835bcf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5abb42cf-7312-46eb-859e-60df4f92842a',\n",
       " 'b90525f4-38bf-453c-a51a-5f0718bccc98',\n",
       " '22f732d0-da17-4bad-b3cd-b54e2102367a']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"The Shawshank Redemption\",\n",
    "        metadata={\n",
    "            \"author\": \"Stephen King\",\n",
    "            \"theme\": \"Friendship\",\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Godfather\",\n",
    "        metadata={\n",
    "            \"director\": \"Francis Ford Coppola\",\n",
    "            \"theme\": \"Mafia\",\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"Inception\",\n",
    "        metadata={\n",
    "            \"director\": \"Christopher Nolan\",\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a14fde-1ef3-4df1-96c5-21b3eac99c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='b90525f4-38bf-453c-a51a-5f0718bccc98', embedding=None, metadata={'director': 'Francis Ford Coppola', 'theme': 'Mafia'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The Godfather', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.3068528194400547)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata filter\n",
    "from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[ExactMatchFilter(key=\"theme\", value=\"Mafia\")]\n",
    ")\n",
    "\n",
    "retriever = index.as_retriever(filters=filters)\n",
    "\n",
    "retriever.retrieve(\"What is inception about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1879cba-8ead-4d73-9225-e42027fd52b5",
   "metadata": {},
   "source": [
    "### Custom Filters and overriding Query\n",
    "Couchbase supports `ExactMatchFilters` only at the moment via LlamaIndex. Couchbase supports a wide range of filters, including range filters, geospatial filters, and more. To use these filters, you can pass them in as a list of dictionaries to the `cb_search_options` parameter. \n",
    "The different search/query possibilities for the search_options can be found [here](https://docs.couchbase.com/server/current/search/search-request-params.html#query-object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7762c7a0-2a08-4a1a-a9e7-90f28bd66377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "His investments in Y Combinator were based on a combination of the deal he did with Julian ($10k for 10%) and what Robert said MIT grad students got for the summer ($6k). He invested $6k per founder, which in the typical two-founder case was $12k, in return for 6%.\n"
     ]
    }
   ],
   "source": [
    "def custom_query(query, query_str):\n",
    "    print(\"custom query\", query)\n",
    "    return query\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    vector_store_kwargs={\n",
    "        \"cb_search_options\": {\n",
    "            \"query\": {\"match\": \"growing up\", \"field\": \"text\"}\n",
    "        },\n",
    "        \"custom_query\": custom_query,\n",
    "    }\n",
    ")\n",
    "response = query_engine.query(\"what were his investments in Y Combinator?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
