{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e33dced-e587-4397-81b3-d6606aa1738a",
   "metadata": {},
   "source": [
    "# DataBricks\n",
    "\n",
    "Integrate with DataBricks LLMs APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4105d3",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "- [Databricks personal access token](https://docs.databricks.com/en/dev-tools/auth/pat.html) to query and access Databricks model serving endpoints.\n",
    "\n",
    "- [Databricks workspace](https://docs.databricks.com/en/workspace/index.html) in a [supported region](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-limits.html#regions) for Foundation Model APIs pay-per-token."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5863dde9-84a0-4c33-ad52-cc767442f63f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833bdb2b",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install llama-index-llms-databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbc106",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad297f19-998f-4485-aa2f-d67020058b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.databricks import Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eefec25",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "export DATABRICKS_API_KEY=<your api key>\n",
    "export DATABRICKS_API_BASE=<your api serving endpoint>\n",
    "```\n",
    "\n",
    "Alternatively, you can pass your API key and serving endpoint to the LLM when you init it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ced37-9a42-47be-9a39-4218521f5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Databricks(\n",
    "    model=\"databricks-dbrx-instruct\",\n",
    "    api_key=\"your_api_key\",\n",
    "    api_base=\"https://[your-work-space].cloud.databricks.com/serving-endpoints/[your-serving-endpoint]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562455fe",
   "metadata": {},
   "source": [
    "A list of available LLM models can be found [here](https://console.groq.com/docs/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b10bb-e911-47fb-8e84-19828cf224be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(\"Explain the importance of open source LLMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd14f4e-c245-4384-a471-97e4ddfcb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ba9503c-b440-43c6-a50c-676c79993813",
   "metadata": {},
   "source": [
    "#### Call `chat` with a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a4a55-5680-4dc6-a44c-fc8ad7892f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9bfe53-d15b-4e75-9d91-8c5d024f4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ad1b00-28fc-4bcd-96c4-d5b35605721a",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13c641fa-345a-4dce-87c5-ab1f6dcf4757",
   "metadata": {},
   "source": [
    "Using `stream_complete` endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da1ef1-2f6b-497c-847b-62dd2df11491",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.stream_complete(\"Explain the importance of open source LLMs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b851def-5160-46e5-a30c-5a3ef2356b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca52051d-6b28-49d7-98f5-82e266a1c7a6",
   "metadata": {},
   "source": [
    "Using `stream_chat` endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe553190-52a9-436d-84ae-4dd99a1808f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
    "]\n",
    "resp = llm.stream_chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c503c-f893-4b6b-8a65-a9a27b636046",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
