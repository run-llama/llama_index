{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/friendli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friendli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-friendli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FRIENDLI_TOKEN=...\n"
     ]
    }
   ],
   "source": [
    "%env FRIENDLI_TOKEN=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.friendli import Friendli\n",
    "\n",
    "# To customize your friendli token, do this\n",
    "# otherwise it will lookup FRIENDLI_TOKEN from your env variable\n",
    "# llm = Friendli(friendli_token=\"Your personal access token\")\n",
    "\n",
    "llm = Friendli()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call `chat` with a list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Of course, I'd be happy to share a joke with you! Here it is:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "I hope that brought a smile to your face. Would you like to hear another joke, or is there something else you'd like to talk about?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "message = ChatMessage(role=MessageRole.USER, content=\"Tell me a joke.\")\n",
    "resp = llm.chat([message])\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course, I'd be happy to share a joke with you! Here it is:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "I hope that brought a smile to your face. Would you like to hear another joke, or is there something else you'd like to talk about?"
     ]
    }
   ],
   "source": [
    "resp = llm.stream_chat([message])\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Sure, here's one:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "resp = await llm.achat([message])\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's one:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!"
     ]
    }
   ],
   "source": [
    "resp = await llm.astream_chat([message])\n",
    "async for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call `complete` with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my interest in the Software Engineer position at XYZ Company. As a highly skilled and motivated software engineer with over five years of experience in the field, I am confident that I have the skills and expertise necessary to make a valuable contribution to your team.\n",
      "\n",
      "Throughout my career, I have gained extensive experience in designing, developing, and maintaining complex software systems. I have a strong background in programming languages such as Java, Python, and C++, and I am proficient in using various software development tools and frameworks. I am also experienced in working with agile methodologies and have a proven track record of delivering high-quality software on time and within budget.\n",
      "\n",
      "In my current role at ABC Company, I have been responsible for leading a team of software engineers in the development of a mission-critical application used by over 10,000 users. I have successfully managed the entire software development lifecycle, from requirements gathering to deployment, and have implemented various performance optimization techniques to ensure the application runs smoothly even during peak usage times.\n",
      "\n",
      "I am particularly drawn to XYZ Company because of its reputation as a leader in the software engineering industry.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Draft a cover letter for a role in software engineering.\"\n",
    "resp = llm.complete(prompt)\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my interest in the Software Engineer position at XYZ Company. With a Bachelor's degree in Computer Science and over five years of experience in software development, I am confident in my ability to make a valuable contribution to your team.\n",
      "\n",
      "Throughout my career, I have gained experience in various programming languages such as Java, Python, and C++. I have also worked on full-stack development projects, where I was responsible for both front-end and back-end development. My experience includes designing and implementing software solutions, collaborating with cross-functional teams, and conducting code reviews.\n",
      "\n",
      "I am particularly interested in XYZ Company's focus on innovation and cutting-edge technology. I am excited about the opportunity to work with a team that values creativity and continuous learning. I am confident that my skills and experience make me a strong candidate for this role.\n",
      "\n",
      "Thank you for considering my application. I look forward to the opportunity to discuss my qualifications further.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your Name]"
     ]
    }
   ],
   "source": [
    "resp = llm.stream_complete(prompt)\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my interest in the Software Engineer position at XYZ Company. With a Bachelor's degree in Computer Science and over five years of experience in software development, I am confident in my ability to make a valuable contribution to your team.\n",
      "\n",
      "Throughout my career, I have gained experience in various programming languages such as Java, Python, and C++. I have also worked on full-stack development projects, where I was responsible for both front-end and back-end development. My experience includes working on cloud-based applications, developing APIs, and integrating third-party services.\n",
      "\n",
      "I am passionate about writing clean, efficient, and maintainable code. I am also a strong believer in Agile methodologies and have experience working in Agile teams. I am a team player and enjoy collaborating with others to find solutions to complex problems.\n",
      "\n",
      "In my current role at ABC Company, I have been responsible for leading a team of software engineers in the development of a cloud-based application. I have also been involved in the design and implementation of the company's DevOps practices, which has helped to improve the team's productivity and efficiency.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = await llm.acomplete(prompt)\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my interest in the Software Engineer position at XYZ Corporation. With a Bachelor's degree in Computer Science and over five years of experience in software development, I am confident in my ability to make a valuable contribution to your team.\n",
      "\n",
      "Throughout my career, I have gained extensive experience in various programming languages such as Java, Python, and C++. I have also worked on developing web applications using frameworks such as React and Angular. My experience includes working on both front-end and back-end development, as well as leading teams to deliver high-quality software products.\n",
      "\n",
      "At my current role, I have been responsible for designing and implementing software solutions for clients in various industries. I have worked closely with cross-functional teams, including product managers, designers, and quality assurance engineers, to ensure that the final product meets the client's requirements. I have also been involved in the entire software development lifecycle, from requirements gathering to deployment.\n",
      "\n",
      "I am particularly interested in the Software Engineer role at XYZ Corporation because of the company's reputation for innovation and excellence. I am excited about the opportunity to work with a talented team"
     ]
    }
   ],
   "source": [
    "resp = await llm.astream_complete(prompt)\n",
    "async for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.friendli import Friendli\n",
    "\n",
    "llm = Friendli(model=\"llama-2-70b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant:  Sure, here's a joke for you:\n",
      "\n",
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two-tired!\n",
      "\n",
      "I hope that brought a smile to your face! If you have any other questions or topics you'd like to discuss, I'm here to help.\n"
     ]
    }
   ],
   "source": [
    "resp = llm.chat([message])\n",
    "\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
