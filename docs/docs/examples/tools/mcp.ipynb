{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex + MCP Usage\n",
    "\n",
    "The `llama-index-tools-mcp` package provides several tools for using MCP with LlamaIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-tools-mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tools from an MCP Server\n",
    "\n",
    "Using the `get_tools_from_mcp_url` or `aget_tools_from_mcp_url` function, you can get a list of `FunctionTool`s from an MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import (\n",
    "    get_tools_from_mcp_url,\n",
    "    aget_tools_from_mcp_url,\n",
    ")\n",
    "\n",
    "# async\n",
    "tools = await aget_tools_from_mcp_url(\"http://127.0.0.1:8000/sse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, this will use our `BasicMCPClient`, which will run a command or connect to the URL and return the tools.\n",
    "\n",
    "You can also pass in a custom `ClientSession` to use a different client.\n",
    "\n",
    "You can also specify a list of allowed tools to filter the tools that are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient\n",
    "\n",
    "client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "\n",
    "tools = await aget_tools_from_mcp_url(\n",
    "    \"http://127.0.0.1:8000/sse\",\n",
    "    client=client,\n",
    "    allowed_tools=[\"tool1\", \"tool2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a Workflow to an MCP App\n",
    "\n",
    "If you have a custom `Workflow`, you can convert it to an MCP app using the `workflow_as_mcp` function.\n",
    "\n",
    "For example, let's use the following workflow that will make a string loud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Context,\n",
    "    Workflow,\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    ")\n",
    "from llama_index.tools.mcp.utils import workflow_as_mcp\n",
    "\n",
    "\n",
    "class RunEvent(StartEvent):\n",
    "    msg: str\n",
    "\n",
    "\n",
    "class InfoEvent(Event):\n",
    "    msg: str\n",
    "\n",
    "\n",
    "class LoudWorkflow(Workflow):\n",
    "    \"\"\"Useful for converting strings to uppercase and making them louder.\"\"\"\n",
    "\n",
    "    @step\n",
    "    def step_one(self, ctx: Context, ev: RunEvent) -> StopEvent:\n",
    "        ctx.write_event_to_stream(InfoEvent(msg=\"Hello, world!\"))\n",
    "\n",
    "        return StopEvent(result=ev.msg.upper() + \"!\")\n",
    "\n",
    "\n",
    "workflow = LoudWorkflow()\n",
    "\n",
    "mcp = workflow_as_mcp(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will automatically generate a `FastMCP` server that will\n",
    "- Use the workflow class name as the tool name\n",
    "- Use our custom `RunEvent` as the typed inputs to the tool\n",
    "- Automatically use the SSE stream for streaming json dumps of the workflow event stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this code was in a script called `script.py`, you could launch the MCP server with:\n",
    "\n",
    "```bash\n",
    "mcp dev script.py\n",
    "```\n",
    "\n",
    "Or the other commands documented in the [MCP CLI README](https://github.com/modelcontextprotocol/python-sdk?tab=readme-ov-file#quickstart).\n",
    "\n",
    "Note that to launch from the CLI, you may need to install the MCP CLI:\n",
    "\n",
    "```bash\n",
    "pip install \"mcp[cli]\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can further customize the `FastMCP` server by passing in additional arguments to the `workflow_as_mcp` function:\n",
    "- `workflow_name`: The name of the workflow. Defaults to the class name.\n",
    "- `workflow_description`: The description of the workflow. Defaults to the class docstring.\n",
    "- `start_event_model`: The event model to use for the start event. You can either use a custom `StartEvent` class in your workflow or pass in your own pydantic model here to define the inputs to the workflow.\n",
    "- `**fastmcp_init_kwargs`: Any extra arguments to pass to the `FastMCP()` server constructor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
