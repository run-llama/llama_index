# ğŸ”¬ Evaluation

LlamaIndexæä¾›äº†å‡ ä¸ªå…³é”®æ¨¡å—æ¥è¯„ä¼°æ–‡æ¡£æ£€ç´¢å’Œå“åº”åˆæˆçš„è´¨é‡ã€‚ä»¥ä¸‹æ˜¯æ¯ä¸ªç»„ä»¶çš„ä¸€äº›å…³é”®é—®é¢˜ï¼š
- **æ–‡æ¡£æ£€ç´¢**ï¼šæºä¸æŸ¥è¯¢ç›¸å…³å—ï¼Ÿ
- **å“åº”åˆæˆ**ï¼šå“åº”æ˜¯å¦ä¸æ£€ç´¢çš„ä¸Šä¸‹æ–‡åŒ¹é…ï¼Ÿå®ƒä¹Ÿä¸æŸ¥è¯¢åŒ¹é…å—ï¼Ÿ

æœ¬æŒ‡å—ä»‹ç»äº†LlamaIndexä¸­çš„è¯„ä¼°ç»„ä»¶å¦‚ä½•å·¥ä½œã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ç›®å‰çš„è¯„ä¼°æ¨¡å—*ä¸*éœ€è¦åŸºç¡€çœŸå®æ ‡ç­¾ã€‚è¯„ä¼°å¯ä»¥é€šè¿‡æŸ¥è¯¢ã€ä¸Šä¸‹æ–‡ã€å“åº”å’ŒLLMè°ƒç”¨çš„æŸç§ç»„åˆæ¥å®Œæˆã€‚

## å“åº”+ä¸Šä¸‹æ–‡çš„è¯„ä¼°

æ¯ä¸ª`query_engine.query`è°ƒç”¨è¿”å›çš„å“åº”éƒ½åŒ…æ‹¬åˆæˆçš„å“åº”å’Œæºæ–‡æ¡£ã€‚

æˆ‘ä»¬å¯ä»¥è¯„ä¼°å“åº”ä¸æ£€ç´¢æºçš„å“åº”ï¼Œè€Œä¸è€ƒè™‘æŸ¥è¯¢ï¼

è¿™æ ·å¯ä»¥æµ‹é‡å¹»è§‰ - å¦‚æœå“åº”ä¸æ£€ç´¢çš„æºä¸åŒ¹é…ï¼Œè¿™æ„å‘³ç€æ¨¡å‹å¯èƒ½ä¼šâ€œå¹»æƒ³â€ä¸€ä¸ªç­”æ¡ˆï¼Œå› ä¸ºå®ƒæ²¡æœ‰æ ¹æ®æç¤ºä¸­æä¾›çš„ä¸Šä¸‹æ–‡æ¥å›ç­”ã€‚

è¿™é‡Œæœ‰ä¸¤ç§å­æ¨¡å¼çš„è¯„ä¼°ã€‚æˆ‘ä»¬å¯ä»¥è·å¾—ä¸€ä¸ªäºŒè¿›åˆ¶å“åº”â€œYESâ€/â€œNOâ€ï¼Œè¡¨ç¤ºå“åº”æ˜¯å¦ä¸*ä»»ä½•*æºä¸Šä¸‹æ–‡åŒ¹é…ï¼Œä¹Ÿå¯ä»¥è·å¾—è·¨æºçš„å“åº”åˆ—è¡¨ï¼Œä»¥æŸ¥çœ‹å“ªäº›æºåŒ¹é…ã€‚

### äºŒè¿›åˆ¶è¯„ä¼°

æ­¤æ¨¡å¼çš„è¯„ä¼°å°†è¿”å›â€œYESâ€/â€œNOâ€ï¼Œå¦‚æœåˆæˆçš„å“åº”ä¸ä»»ä½•æºä¸Šä¸‹æ–‡åŒ¹é…ã€‚

```python
from llama_index import GPTVectorStoreIndex
from llama_index.evaluation import ResponseEvaluator

# build service context
llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name="gpt-4"))
service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)

# build index
...

# define evaluator
evaluator = ResponseEvaluator(service_context=service_context)

# query index
query_engine = vector_index.as_query_engine()
response = query_engine.query("What battles took place in New York City in the American Revolution?")
eval_result = evaluator.evaluate(response)
print(str(eval_result))

```

æ‚¨å°†è·å¾—â€œYESâ€æˆ–â€œNOâ€çš„å“åº”ã€‚

#### å›¾è¡¨

ï¼[](/_static/evaluation/eval_response_context.png)


### æ¥æºè¯„ä¼°

æ­¤æ¨¡å¼çš„è¯„ä¼°å°†ä¸ºæ¯ä¸ªæºèŠ‚ç‚¹è¿”å›â€œYESâ€/â€œNOâ€ã€‚å®šä¹‰è¯„ä¼°å™¨
evaluator = ResponseEvaluatorï¼ˆservice_context = service_contextï¼‰

#æŸ¥è¯¢ç´¢å¼•
query_engine = vector_index.as_query_engineï¼ˆï¼‰
response = query_engine.queryï¼ˆâ€œç¾å›½é©å‘½æ—¶æœŸçº½çº¦å¸‚å‘ç”Ÿäº†å“ªäº›æˆ˜æ–—ï¼Ÿâ€ï¼‰
eval_result = evaluator.evaluate_source_nodesï¼ˆresponseï¼‰
æ‰“å°ï¼ˆstrï¼ˆeval_resultï¼‰ï¼‰

æ‚¨å°†è·å¾—ä¸€ä¸ªâ€œæ˜¯â€/â€œå¦â€çš„åˆ—è¡¨ï¼Œå¯¹åº”äºresponse.source_nodesä¸­çš„æ¯ä¸ªæºèŠ‚ç‚¹ã€‚

### Notebook

è¯·å‚é˜…æ­¤[ç¬”è®°æœ¬](https://github.com/jerryjliu/llama_index/blob/main/examples/evaluation/TestNYC-Evaluation.ipynb)ã€‚


```{toctree}
---
caption: Examples
maxdepth: 1
---

../../examples/evaluation/TestNYC-Evaluation.ipynb
../../examples/evaluation/TestNYC-Evaluation-Query.ipynb
../../examples/evaluation/QuestionGeneration.ipynb
```