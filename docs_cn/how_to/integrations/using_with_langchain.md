ä½¿ç”¨Langchain ğŸ¦œğŸ”—

LlamaIndexæä¾›äº†ç”¨äºLangchainä»£ç†çš„å·¥å…·æŠ½è±¡ä»¥åŠå†…å­˜æ¨¡å—ã€‚

å·¥å…·æŠ½è±¡+å†…å­˜æ¨¡å—çš„APIå‚è€ƒ[åœ¨è¿™é‡Œ](/reference/langchain_integrations/base.rst)ã€‚

### Llama Tool abstractions
LlamaIndexæä¾›äº†å·¥å…·æŠ½è±¡ï¼Œå› æ­¤æ‚¨å¯ä»¥ä½¿ç”¨LlamaIndexä¸Langchainä»£ç†ä¸€èµ·ä½¿ç”¨ã€‚

ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ç›´æ¥ä»`QueryEngine`åˆ›å»ºâ€œToolâ€ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```python
from llama_index.langchain_helpers.agents import IndexToolConfig, LlamaIndexTool

tool_config = IndexToolConfig(
    query_engine=query_engine, 
    name=f"Vector Index",
    description=f"useful for when you want to answer queries about X",
    tool_kwargs={"return_direct": True}
)

tool = LlamaIndexTool.from_tool_config(tool_config)

```

æ‚¨è¿˜å¯ä»¥é€‰æ‹©æä¾›ä¸€ä¸ª`LlamaToolkit`ï¼š

```python
toolkit = LlamaToolkit(
    index_configs=index_configs,
)
```

è¿™æ ·çš„å·¥å…·åŒ…å¯ä»¥ç”¨äºé€šè¿‡æˆ‘ä»¬çš„`create_llama_agent`å’Œ`create_llama_chat_agent`å‘½ä»¤åˆ›å»ºä¸‹æ¸¸åŸºäºLangchainçš„èŠå¤©ä»£ç†ï¼š

```python
from llama_index.langchain_helpers.agents import create_llama_chat_agent

agent_chain = create_llama_chat_agent(
    toolkit,
    llm,
    memory=memory,
    verbose=True
)

agent_chain.run(input="Query about X")
```

æ‚¨å¯ä»¥åœ¨[è¿™é‡ŒæŸ¥çœ‹å®Œæ•´çš„æ•™ç¨‹ç¬”è®°æœ¬](https://github.com/jerryjliu/llama_index/blob/main/examples/chatbot/Chatbot_SEC.ipynb)ã€‚

### Llama Demo Notebookï¼šTool + Memory module

æˆ‘ä»¬è¿˜æä¾›äº†å¦ä¸€ä¸ªæ¼”ç¤ºç¬”è®°æœ¬ï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä»¥ä¸‹ç»„ä»¶æ„å»ºèŠå¤©ä»£ç†ã€‚
- ä½¿ç”¨LlamaIndexä½œä¸ºå…·æœ‰Langchainä»£ç†çš„é€šç”¨å¯è°ƒç”¨å·¥å…·
- ä½¿ç”¨LlamaIndexä½œä¸ºå†…å­˜æ¨¡å—ï¼›è¿™å…è®¸æ‚¨ä½¿ç”¨LangchainèŠå¤©æœºå™¨äººæ’å…¥ä»»æ„æ•°é‡çš„å¯¹è¯å†å²ï¼

è¯·å‚é˜…[æ­¤å¤„çš„ç¬”è®°æœ¬](https://github.com/jerryjliu/llama_index/blob/main/examples/langchain_demo/LangchainDemo.ipynb)ã€‚