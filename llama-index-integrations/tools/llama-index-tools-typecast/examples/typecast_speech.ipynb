{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b6b613",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Make sure you have installed the following two packages\n",
    "```\n",
    "llama-index-agent-openai\n",
    "llama-index-tools-typecast\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI Agent\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\"\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97355b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.typecast import TypecastToolSpec\n",
    "\n",
    "speech_tool = TypecastToolSpec(api_key=\"your-typecast-key\")\n",
    "\n",
    "agent = FunctionAgent(\n",
    "    tools=[*speech_tool.to_tool_list()],\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    ")\n",
    "print(\n",
    "    await agent.run(\n",
    "        'Get the list of available voices, select the first voice, and use it to create speech from the text \"Hello world! How are you today?\" with a happy emotion, saving to \"speech.wav\"'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kira5q4803",
   "metadata": {},
   "source": [
    "### Direct Tool Usage (without Agent)\n",
    "You can also use the tool directly without an agent for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evidyh3snds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct usage example (V2 API)\n",
    "from llama_index.tools.typecast import TypecastToolSpec\n",
    "\n",
    "speech_tool = TypecastToolSpec(api_key=\"your-typecast-key\")\n",
    "\n",
    "# Get all available voices with optional filters\n",
    "voices = speech_tool.get_voices(model=\"ssfm-v30\", gender=\"female\")\n",
    "print(f\"Found {len(voices)} voices\")\n",
    "\n",
    "# Get specific voice details (V2 response format)\n",
    "voice = speech_tool.get_voice(voices[0][\"voice_id\"])\n",
    "print(f\"Voice: {voice['voice_name']}\")\n",
    "print(f\"Gender: {voice.get('gender')}, Age: {voice.get('age')}\")\n",
    "print(f\"Use cases: {voice.get('use_cases')}\")\n",
    "\n",
    "# Models now include emotions per model version\n",
    "for model in voice['models']:\n",
    "    print(f\"Model {model['version']}: emotions = {model['emotions']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3h9ac5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-to-speech with all parameters including seed for reproducibility\n",
    "output_path = speech_tool.text_to_speech(\n",
    "    text=\"Hello world! This is a test.\",\n",
    "    voice_id=voices[0][\"voice_id\"],\n",
    "    output_path=\"output_with_seed.wav\",\n",
    "    model=\"ssfm-v21\",\n",
    "    language=\"eng\",\n",
    "    emotion_preset=\"happy\",\n",
    "    emotion_intensity=1.5,\n",
    "    volume=100,\n",
    "    audio_pitch=0,\n",
    "    audio_tempo=1.0,\n",
    "    audio_format=\"wav\",\n",
    "    seed=42,  # Use seed for reproducible results\n",
    ")\n",
    "print(f\"Audio saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
