{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b6b613",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Make sure you have installed the following two packages\n",
    "```\n",
    "llama-index-agent-openai\n",
    "llama-index-tools-typecast\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI Agent\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\"\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97355b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.typecast import TypecastToolSpec\n",
    "\n",
    "speech_tool = TypecastToolSpec(api_key=\"your-typecast-key\")\n",
    "\n",
    "agent = FunctionAgent(\n",
    "    tools=[*speech_tool.to_tool_list()],\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    ")\n",
    "print(\n",
    "    await agent.run(\n",
    "        'Get the list of available voices, select the first voice, and use it to create speech from the text \"Hello world! How are you today?\" with a happy emotion, saving to \"speech.wav\"'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kira5q4803",
   "source": "### Direct Tool Usage (without Agent)\nYou can also use the tool directly without an agent for more control.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "evidyh3snds",
   "source": "# Direct usage example (V2 API)\nfrom llama_index.tools.typecast import TypecastToolSpec\n\nspeech_tool = TypecastToolSpec(api_key=\"your-typecast-key\")\n\n# Get all available voices with optional filters\nvoices = speech_tool.get_voices(model=\"ssfm-v30\", gender=\"female\")\nprint(f\"Found {len(voices)} voices\")\n\n# Get specific voice details (V2 response format)\nvoice = speech_tool.get_voice(voices[0][\"voice_id\"])\nprint(f\"Voice: {voice['voice_name']}\")\nprint(f\"Gender: {voice.get('gender')}, Age: {voice.get('age')}\")\nprint(f\"Use cases: {voice.get('use_cases')}\")\n\n# Models now include emotions per model version\nfor model in voice['models']:\n    print(f\"Model {model['version']}: emotions = {model['emotions']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fc3h9ac5a06",
   "source": "# Text-to-speech with all parameters including seed for reproducibility\noutput_path = speech_tool.text_to_speech(\n    text=\"Hello world! This is a test.\",\n    voice_id=voices[0][\"voice_id\"],\n    output_path=\"output_with_seed.wav\",\n    model=\"ssfm-v21\",\n    language=\"eng\",\n    emotion_preset=\"happy\",\n    emotion_intensity=1.5,\n    volume=100,\n    audio_pitch=0,\n    audio_tempo=1.0,\n    audio_format=\"wav\",\n    seed=42,  # Use seed for reproducible results\n)\nprint(f\"Audio saved to: {output_path}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}