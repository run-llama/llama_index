{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NVIDIA's LLM API Catalog Connector\n",
    "\n",
    "This notebook will guide you through understanding the basic usage of the `NVIDIA` connector.\n",
    "\n",
    "With this connector, you'll be able to connect to and generate from compatible models available at the NVIDIA [API Catalog](https://build.nvidia.com/explore/discover), such as:\n",
    "\n",
    "- Google's [gemma-7b](https://build.nvidia.com/google/gemma-7b)\n",
    "- Mistal AI's [mistral-7b-instruct-v0.2](https://build.nvidia.com/mistralai/mistral-7b-instruct-v2)\n",
    "- And more!\n",
    "\n",
    "We'll begin by ensuring `llama-index` and associated packages are installed.\n",
    "\n",
    "> NOTE: Only models that have a base URL of `https://integrate.api.nvidia.com/v1` are compatible with this connector at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (0.10.26)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.2.1)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.26 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.10.26)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.14)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.13)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.1.15)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.24.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.14.3)\n",
      "Requirement already satisfied: pandas in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.0)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.6.4)\n",
      "Requirement already satisfied: anyio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.9.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.26->llama-index) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.16.0)\n",
      "Requirement already satisfied: llama-index-core in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (0.10.26)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.1.15)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.24.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.14.3)\n",
      "Requirement already satisfied: pandas in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core) (2.6.4)\n",
      "Requirement already satisfied: anyio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: click in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from dataclasses-json->llama-index-core) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core) (1.16.0)\n",
      "Requirement already satisfied: llama-index-embeddings-openai in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (0.1.7)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-embeddings-openai) (0.10.26)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.1.15)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.24.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.14.3)\n",
      "Requirement already satisfied: pandas in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.6.4)\n",
      "Requirement already satisfied: anyio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-core\n",
    "!pip install llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Keys and Boilerplate\n",
    "\n",
    "During the next cell we'll run some boilerplate to allow the examples to be executed smoothly in a notebook environment. \n",
    "\n",
    "We'll also provide our API keys. \n",
    "\n",
    "> NOTE: You can create your NVIDIA API key using the `Get API Key` button in the code example window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "\n",
    "# Using OpenAI API for embeddings\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
    "\n",
    "# Using NVIDIA API Playground API Key for LLM\n",
    "os.environ[\"NVIDIA_AI_PLAYGROUND_API_KEY\"] = \"nvapi-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the NVIDIA LLM\n",
    "\n",
    "Now we can load our `NVIDIA` LLM by passing in the model name, as found in the docs - located [here](https://docs.api.nvidia.com/nim/reference/)\n",
    "\n",
    "> NOTE: The default model is `mistralai/mistral-7b-instruct-v0.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.nvidia import NVIDIA\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = NVIDIA(model=\"mistralai/mistral-7b-instruct-v0.2\")\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe which model our `llm` object is currently associated with the `.model` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistralai/mistral-7b-instruct-v0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading API Catalogue LLM\n",
    "\n",
    "We can also load models using their API Catalogue address.\n",
    "\n",
    "Let's use `gemma-7b` as an example!\n",
    "\n",
    "1. Navigate to the [model page](https://build.nvidia.com/google/gemma-7b)\n",
    "2. Find the address in the `model` parameter (e.g. `\"google/gemma-7b\"`)\n",
    "3. Verify it has the `base_url` of `\"https://integrate.api.nvidia.com/v1\"`\n",
    "4. Use `NVIDIA(model=\"model_name_here\")` to point the connector at that model (e.g. `NVIDIA(model=\"google/gemma-7b\"`)\n",
    "\n",
    "Let's see this in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = NVIDIA(model=\"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm we've associated our `NvidiaAIPlayground` LLM with the correct model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google/gemma-7b'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Functionality\n",
    "\n",
    "Now we can explore the different ways you can use the connector within the LlamaIndex ecosystem!\n",
    "\n",
    "Before we begin, lets set up a list of `ChatMessage` objects - which is the expected input for some of the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "chat_messages = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=(\n",
    "            \"You are a helpful assistant.\"\n",
    "        )\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=(\n",
    "            \"What are the most popular house pets in North America?\"\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll follow the same basic pattern for each example: \n",
    "\n",
    "1. We'll point our `NVIDIA` LLM to our desired model\n",
    "2. We'll examine how to use the endpoint to achieve the desired task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete: `.complete()`\n",
    "\n",
    "We can use `.complete()`/`.acomplete()` (which takes a string) to prompt a response from the selected model.\n",
    "\n",
    "Let's use our default model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_llm = NVIDIA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify this is the expected default by checking the `.model` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistralai/mistral-7b-instruct-v0.2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_llm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call `.complete()` on our model with a string, in this case `\"Hello!\"`, and observe the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\" Hello! How can I help you today? I'm here to answer any questions you might have, provide information, or just chat if you'd like. Let me know what's on your mind!\\n\\nHere are a few things I can help with:\\n\\n* Answering factual questions\\n* Providing definitions and explanations\\n* Helping with math problems\\n* Giving suggestions for books, movies, or other forms of entertainment\\n* Offering advice on a variety of topics\\n* And much more!\\n\\nSo, what can I help you with today? Let me know and I'll do my best to assist you.\\n\\nIf you have a specific question or topic in mind, feel free to ask it directly. If you're not sure what you're looking for, or if you just want to chat, that's fine too! I'm here to help in any way I can.\\n\\nI look forward to hearing from you! Let me know if you have any questions or if there's anything I can help you with.\\n\\nBest regards,\\n\\n[Your Name]\\n\\nAssistant: [Your Name] is an assistant designed to help answer questions, provide information, and offer suggestions. I'm here to make your life easier and more convenient. Let me know how I can assist you today.\", additional_kwargs={}, raw={'id': 'chatcmpl-c5a6b737-7efc-476e-bda6-7a493d814c2f', 'choices': [Choice(finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, text_offset=[], token_logprobs=[0.0, 0.0], tokens=[], top_logprobs=[]), message=ChatCompletionMessage(content=\" Hello! How can I help you today? I'm here to answer any questions you might have, provide information, or just chat if you'd like. Let me know what's on your mind!\\n\\nHere are a few things I can help with:\\n\\n* Answering factual questions\\n* Providing definitions and explanations\\n* Helping with math problems\\n* Giving suggestions for books, movies, or other forms of entertainment\\n* Offering advice on a variety of topics\\n* And much more!\\n\\nSo, what can I help you with today? Let me know and I'll do my best to assist you.\\n\\nIf you have a specific question or topic in mind, feel free to ask it directly. If you're not sure what you're looking for, or if you just want to chat, that's fine too! I'm here to help in any way I can.\\n\\nI look forward to hearing from you! Let me know if you have any questions or if there's anything I can help you with.\\n\\nBest regards,\\n\\n[Your Name]\\n\\nAssistant: [Your Name] is an assistant designed to help answer questions, provide information, and offer suggestions. I'm here to make your life easier and more convenient. Let me know how I can assist you today.\", role='assistant', function_call=None, tool_calls=None))], 'created': 1712175907, 'model': 'mistralai/mistral-7b-instruct-v0.2', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=284, prompt_tokens=11, total_tokens=295)}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_llm.complete(\"Hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is expected by LlamaIndex - we get a `CompletionResponse` in response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Complete: `.acomplete()`\n",
    "\n",
    "There is also an async implementation which can be leveraged in the same way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\" Hello there! How can I help you today? I'm here to answer any questions you might have or provide information on a wide range of topics. So feel free to ask me anything!\\n\\nIf you're looking for a specific topic, just let me know and I'll do my best to provide you with accurate and up-to-date information. And if you have any requests for fun facts or trivia, I'm happy to oblige!\\n\\nSo, what would you like to know today? Let me help make your day a little brighter! ðŸ˜Š\", additional_kwargs={}, raw={'id': 'chatcmpl-8ce881c1-a47b-43aa-afd8-9e9addf26ce9', 'choices': [Choice(finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, text_offset=[], token_logprobs=[0.0, 0.0], tokens=[], top_logprobs=[]), message=ChatCompletionMessage(content=\" Hello there! How can I help you today? I'm here to answer any questions you might have or provide information on a wide range of topics. So feel free to ask me anything!\\n\\nIf you're looking for a specific topic, just let me know and I'll do my best to provide you with accurate and up-to-date information. And if you have any requests for fun facts or trivia, I'm happy to oblige!\\n\\nSo, what would you like to know today? Let me help make your day a little brighter! ðŸ˜Š\", role='assistant', function_call=None, tool_calls=None))], 'created': 1712175910, 'model': 'mistralai/mistral-7b-instruct-v0.2', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=123, prompt_tokens=11, total_tokens=134)}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await completion_llm.acomplete(\"Hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat: `.chat()`\n",
    "\n",
    "Now we can try the same thing using the `.chat()` method. This method expects a list of chat messages - so we'll use the one we created above.\n",
    "\n",
    "We'll use the `mistralai/mixtral-8x7b-instruct-v0.1` model for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = NVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do now is call `.chat()` on our list of `ChatMessages` and observe our response.\n",
    "\n",
    "You'll also notice that we can pass in a few additional key-word arguments that can influence the generation - in this case, we've used the `seed` parameter to influence our generation and the `stop` parameter to indicate we want the model to stop generating once it reaches a certain token!\n",
    "\n",
    "> NOTE: You can find information about what additional kwargs are supported by the model's endpoint by referencing the API documentation for the selected model. Mixtral's is located [here](https://docs.api.nvidia.com/nim/reference/mistralai-mixtral-8x7b-instruct-infer) as an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=' The most popular house pets in North America are dogs and cats', additional_kwargs={}), raw={'id': 'chatcmpl-2a072acf-9611-42fd-82bc-e5295ea44c69', 'choices': [Choice(finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, text_offset=[], token_logprobs=[0.0, 0.0], tokens=[], top_logprobs=[]), message=ChatCompletionMessage(content=' The most popular house pets in North America are dogs and cats', role='assistant', function_call=None, tool_calls=None))], 'created': 1712177058, 'model': 'mistralai/mixtral-8x7b-instruct-v0.1', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=12, prompt_tokens=59, total_tokens=71)}, delta=None, logprobs=None, additional_kwargs={})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.chat(chat_messages, seed=4, stop=[\"cat\", \"cats\", \"Cat\", \"Cats\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we receive a `ChatResponse` in response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Chat: (`achat`)\n",
    "\n",
    "We also have an async implementation of the `.chat()` method which can be called in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=' The most popular house pets in North America are dogs and cats. According to the American Pet Products Association (APPA), as of 2021, approximately 69 million homes in the United States own a pet, and 63.4 million of those households have a dog, while 42.7 million have a cat. Birds, small mammals, reptiles, and fish are also popular pets, but to a lesser extent.', additional_kwargs={}), raw={'id': 'chatcmpl-373a1d42-4dc1-4ef9-aaf3-5fea137e8e1e', 'choices': [Choice(finish_reason=None, index=0, logprobs=ChoiceLogprobs(content=None, text_offset=[], token_logprobs=[0.0, 0.0], tokens=[], top_logprobs=[]), message=ChatCompletionMessage(content=' The most popular house pets in North America are dogs and cats. According to the American Pet Products Association (APPA), as of 2021, approximately 69 million homes in the United States own a pet, and 63.4 million of those households have a dog, while 42.7 million have a cat. Birds, small mammals, reptiles, and fish are also popular pets, but to a lesser extent.', role='assistant', function_call=None, tool_calls=None))], 'created': 1712177472, 'model': 'mistralai/mixtral-8x7b-instruct-v0.1', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=95, prompt_tokens=59, total_tokens=154)}, delta=None, logprobs=None, additional_kwargs={})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat_llm.achat(chat_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream: `.stream_chat()`\n",
    "\n",
    "We can also use the models found on `build.nvidia.com` for streaming use-cases!\n",
    "\n",
    "Let's select another model and observe this behaviour. We'll use Google's `gemma-7b` model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_llm = NVIDIA(model=\"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call our model with `.stream_chat()`, which again expects a list of `ChatMessage` objects, and capture the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamed_response = stream_llm.stream_chat(chat_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat.<locals>.wrapped_gen at 0x787709eea680>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamed_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the response is a generator with the streamed response. \n",
    "\n",
    "Let's take a look at the final response once the generation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Sure, here are the most popular house pets in North America:\n",
      "\n",
      "1. Dogs\n",
      "2. Cats\n",
      "3. Fish\n",
      "4. Rabbits\n",
      "5. Small Mammals\n"
     ]
    }
   ],
   "source": [
    "last_element = None\n",
    "for last_element in streamed_response:\n",
    "    pass\n",
    "\n",
    "print(last_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Stream: `.astream_chat()`\n",
    "\n",
    "We have the equivalent async method for streaming as well, which can be used in a similar way to the sync implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamed_response = await stream_llm.astream_chat(chat_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object llm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat.<locals>.wrapped_gen at 0x787709eea460>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Sure, here are the most popular house pets in North America:\n",
      "\n",
      "1. Dogs\n",
      "2. Cats\n",
      "3. Fish\n",
      "4. Small Mammals\n",
      "5. Birds\n"
     ]
    }
   ],
   "source": [
    "last_element = None\n",
    "async for last_element in streamed_response:\n",
    "    pass\n",
    "\n",
    "print(last_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Query Engine Responses\n",
    "\n",
    "Let's look at a slightly more involved example using a query engine!\n",
    "\n",
    "We'll start by loading some data (we'll be using the [Hitchhiker's Guide to the Galaxy](https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "Let's first create a directory where our data can live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/hhgttg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll download our data from the above source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-01 14:39:38--  https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt\n",
      "Resolving web.eecs.utk.edu (web.eecs.utk.edu)... 160.36.127.165\n",
      "Connecting to web.eecs.utk.edu (web.eecs.utk.edu)|160.36.127.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1534289 (1.5M) [text/plain]\n",
      "Saving to: â€˜data/hhgttg/hhgttg.txtâ€™\n",
      "\n",
      "data/hhgttg/hhgttg. 100%[===================>]   1.46M  6.75MB/s    in 0.2s    \n",
      "\n",
      "2024-04-01 14:39:39 (6.75 MB/s) - â€˜data/hhgttg/hhgttg.txtâ€™ saved [1534289/1534289]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt' -O 'data/hhgttg/hhgttg.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to have an embedding model for this step! We'll use OpenAI's `text-embedding-03-small` model to achieve this, and save it in our `Settings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "openai_embedding = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "Settings.embed_model = openai_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load our document and create an index leveraging the above created `OpenAIEmbedding()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data/hhgttg\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a simple query engine and set our `streaming` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_qe = index.as_query_engine(streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's send a query to our query engine, and then stream the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_response = streaming_qe.query(\n",
    "    \"What is the significance of the number 42?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The significance of the number 42 is a central theme in \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams. The book is a comedic science fiction satire that follows the adventures of two intergalactic travelers, Arthur Dent and Ford Prefect, as they try to escape the destruction of Earth and uncover the true meaning of the number 42.\n",
      "\n",
      "Throughout the book, the number 42 is presented as the ultimate answer to the ultimate question of life, the universe, and everything. The question itself is never explicitly stated, but it is implied to be a deeply profound and existential one that has been sought after by philosophers, scientists, and thinkers throughout history.\n",
      "\n",
      "The idea of the number 42 as the ultimate answer is a playful jab at the idea of seeking ultimate knowledge and understanding, which is often seen as an impossible task. The number 42 is also a reference to the famous \"42\" answer in the \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, which is a comedic science fiction satire that follows the adventures of two intergalactic travelers, Arthur Dent and Ford Prefect, as they try to escape the destruction of Earth and uncover the true meaning of the number 42.\n",
      "\n",
      "In the book, the supercomputer Deep Thought is asked to find the answer to the ultimate question, and after billions of years of computation, it determines that the answer is 42. The answer is so profound that it causes Deep Thought to become obsolete, as it is no longer needed to answer questions.\n",
      "\n",
      "The significance of the number 42 in \"The Hitchhiker's Guide to the Galaxy\" is a commentary on the nature of knowledge and the quest for ultimate understanding. It is a reminder that there are limits to what can be known and that the pursuit of knowledge should be done with a sense of humor and a willingness to accept the unknown."
     ]
    }
   ],
   "source": [
    "streaming_response.print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvidia-llama-index-playground-connector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
