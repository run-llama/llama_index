{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NVIDIA's API Playground Connector\n",
    "\n",
    "This notebook will guide you through understanding the basic usage of the `NvidiaAIPlayground` connector.\n",
    "\n",
    "With this connector, you'll be able to connect to and generate from compatible models available at the NVIDIA [API Catalog](https://build.nvidia.com/explore/discover), such as:\n",
    "\n",
    "- Google's [gemma-7b](https://build.nvidia.com/google/gemma-7b)\n",
    "- Mistal AI's [mistral-7b-instruct-v0.2](https://build.nvidia.com/mistralai/mistral-7b-instruct-v2)\n",
    "- And more!\n",
    "\n",
    "We'll begin by ensuring `llama-index` and associated packages are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (0.10.26)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.2.1)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.26 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.10.26)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.14)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.13)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.1.15)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.24.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.14.3)\n",
      "Requirement already satisfied: pandas in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.0)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.6.4)\n",
      "Requirement already satisfied: anyio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.9.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.26->llama-index) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.16.0)\n",
      "Requirement already satisfied: llama-index-core in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (0.10.26)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.1.15)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.24.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.14.3)\n",
      "Requirement already satisfied: pandas in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core) (2.6.4)\n",
      "Requirement already satisfied: anyio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: click in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from dataclasses-json->llama-index-core) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core) (1.16.0)\n",
      "Requirement already satisfied: llama-index-embeddings-openai in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (0.1.7)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-embeddings-openai) (0.10.26)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.1.15)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.24.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.14.3)\n",
      "Requirement already satisfied: pandas in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.6.4)\n",
      "Requirement already satisfied: anyio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n",
      "Requirement already satisfied: click in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/chris/anaconda3/envs/llama_index_nvidia/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-core\n",
    "!pip install llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Keys and Boilerplate\n",
    "\n",
    "During the next cell we'll run some boilerplate to allow the examples to be executed smoothly in a notebook environment. \n",
    "\n",
    "We'll also provide our API keys. \n",
    "\n",
    "> NOTE: You can create your NVIDIA API key using the `Get API Key` button in the code example window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "\n",
    "# Using OpenAI API for embeddings\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
    "\n",
    "# Using NVIDIA API Playground API Key for LLM\n",
    "os.environ[\"NVIDIA_AI_PLAYGROUND_API_KEY\"] = \"nvapi-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Playground LLM\n",
    "\n",
    "Now we can load our `NvidiaAIPlayground` LLM by passing in the model name, as found in the code example on `build.nvidia.com`.\n",
    "\n",
    "> NOTE: The default model will be `playground_nemotron_steerlm_8b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.nvidia_ai_playground import NvidiaAIPlayground\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = NvidiaAIPlayground(model=\"playground_nemotron_steerlm_8b\")\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe which model our `llm` object is currently associated with the `.model` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'playground_nemotron_steerlm_8b'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading API Catalogue LLM\n",
    "\n",
    "We can also load models using their API Catalogue address.\n",
    "\n",
    "Let's use `gemma-7b` as an example!\n",
    "\n",
    "1. Navigate to the [model page](https://build.nvidia.com/google/gemma-7b)\n",
    "2. Find the address in the `model` parameter (e.g. `\"google/gemma-7b\"`)\n",
    "3. Set the `model` parameter to the same name for `NvidiaAIPlayground`\n",
    "\n",
    "Let's see this in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = NvidiaAIPlayground(model=\"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm we've associated our `NvidiaAIPlayground` LLM with the correct model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google/gemma-7b'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Functionality\n",
    "\n",
    "Now we can explore the different ways you can use the connector within the LlamaIndex ecosystem!\n",
    "\n",
    "Before we begin, lets set up a list of `ChatMessage` objects - which is the expected input for some of the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "\n",
    "chat_messages = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=(\n",
    "            \"You are a helpful assistant.\"\n",
    "        )\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=(\n",
    "            \"How do I get to Paris from London?\"\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll follow the same basic pattern for each example: \n",
    "\n",
    "1. We'll point our endpoint to a model hosted on `build.nvidia.com`.\n",
    "2. We'll examine how to use the endpoint to achieve the desired task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete: `.complete()`\n",
    "\n",
    "We can use `.complete()`/`.acomplete()` (which takes a string) to prompt a response from the selected model.\n",
    "\n",
    "Let's use our default model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_llm = NvidiaAIPlayground()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify this is the expected default by checking the `.model` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'playground_nemotron_steerlm_8b'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_llm.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call `.complete()` on our model with a string, in this case `\"Hello!\"`, and observe the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='Hello! I am NV Assistant, a language model developed by NVIDIA, designed to answer any questions or help with a variety of tasks. I am continually learning from interactions with users, so I would be happy to assist you with whatever you need.\\n\\nHere are a few examples of the types of tasks and questions I can help with:\\n\\n    Personal assistance:\\n        - What is the weather like today?\\n        - What is the current time in my city?\\n        - What is the best way to cook a chicken breast?\\n\\n    Information retrieval:\\n        - What is the capital of France?\\n        - How many countries are in the European Union?\\n        - Who was the president of the United States in 2009?\\n\\n    Helpful tools and tips:\\n        - How do I create a Google account?\\n        - How do I install software on my computer?\\n        - How do I troubleshoot a Wi-Fi connection?\\n\\n    General conversation:\\n        - Tell me a joke.\\n        - What is your favorite book or movie?\\n        - What is the meaning of life?\\n\\nPlease let me know how I can assist you today!', additional_kwargs={}, raw={'id': '97bda373-0673-468a-ae37-735b2ac4a912', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! I am NV Assistant, a language model developed by NVIDIA, designed to answer any questions or help with a variety of tasks. I am continually learning from interactions with users, so I would be happy to assist you with whatever you need.\\n\\nHere are a few examples of the types of tasks and questions I can help with:\\n\\n    Personal assistance:\\n        - What is the weather like today?\\n        - What is the current time in my city?\\n        - What is the best way to cook a chicken breast?\\n\\n    Information retrieval:\\n        - What is the capital of France?\\n        - How many countries are in the European Union?\\n        - Who was the president of the United States in 2009?\\n\\n    Helpful tools and tips:\\n        - How do I create a Google account?\\n        - How do I install software on my computer?\\n        - How do I troubleshoot a Wi-Fi connection?\\n\\n    General conversation:\\n        - Tell me a joke.\\n        - What is your favorite book or movie?\\n        - What is the meaning of life?\\n\\nPlease let me know how I can assist you today!', role='assistant', function_call=None, tool_calls=None, name=None, labels={'creativity': 0, 'verbosity': 9, 'complexity': 9}))], 'created': None, 'model': None, 'object': None, 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=250, prompt_tokens=138, total_tokens=388)}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_llm.complete(\"Hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is expected by LlamaIndex - we get a `CompletionResponse` in response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Complete: `.acomplete()`\n",
    "\n",
    "There is also an async implementation which can be leveraged in the same way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='Hello! I am NV Assistant, a language model developed by NVIDIA, designed to answer any questions or help with a variety of tasks. I am continually learning from interactions with users, so I would be happy to assist you with whatever you need.\\n\\nHere are a few examples of the types of tasks and questions I can help with:\\n\\n    Personal assistance: I can answer questions, provide information, and perform tasks to help you with daily activities, such as scheduling appointments, making travel arrangements, or providing weather forecasts.\\n\\n    Technical support: I can provide information and troubleshooting tips for a variety of technical issues, such as computer or software problems, internet connectivity issues, or hardware problems.\\n\\n    Customer service: I can assist with customer service inquiries, such as placing orders, tracking shipments, or resolving billing issues.\\n\\n    Writing assistance: I can provide suggestions for improving the clarity and effectiveness of your writing, such as offering grammar and spelling suggestions, or providing tips for creating effective titles and headings.\\n\\n    General knowledge: I can provide information and answers on a wide range of topics, including history, science, literature, and many others.\\n\\nPlease feel free to ask me a question or describe the task you need help with, and I will do my best to assist you.', additional_kwargs={}, raw={'id': 'cd262092-814d-4dec-a504-bf7a55a7edef', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! I am NV Assistant, a language model developed by NVIDIA, designed to answer any questions or help with a variety of tasks. I am continually learning from interactions with users, so I would be happy to assist you with whatever you need.\\n\\nHere are a few examples of the types of tasks and questions I can help with:\\n\\n    Personal assistance: I can answer questions, provide information, and perform tasks to help you with daily activities, such as scheduling appointments, making travel arrangements, or providing weather forecasts.\\n\\n    Technical support: I can provide information and troubleshooting tips for a variety of technical issues, such as computer or software problems, internet connectivity issues, or hardware problems.\\n\\n    Customer service: I can assist with customer service inquiries, such as placing orders, tracking shipments, or resolving billing issues.\\n\\n    Writing assistance: I can provide suggestions for improving the clarity and effectiveness of your writing, such as offering grammar and spelling suggestions, or providing tips for creating effective titles and headings.\\n\\n    General knowledge: I can provide information and answers on a wide range of topics, including history, science, literature, and many others.\\n\\nPlease feel free to ask me a question or describe the task you need help with, and I will do my best to assist you.', role='assistant', function_call=None, tool_calls=None, name=None, labels={'creativity': 0, 'verbosity': 9, 'complexity': 9}))], 'created': None, 'model': None, 'object': None, 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=266, prompt_tokens=138, total_tokens=404)}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await completion_llm.acomplete(\"Hello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat: `.chat()`\n",
    "\n",
    "Now we can try the same thing using the `.chat()` method. This method expects a list of chat messages - so we'll use the one we created above.\n",
    "\n",
    "We'll use the `playground_mixtral_8x7b` model for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = NvidiaAIPlayground(model=\"playground_mixtral_8x7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do now is call `.chat()` on our list of `ChatMessages` and observe our response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='There are several ways to get from London to Paris:\\n\\n1. **By Eurostar Train**: This is the fastest and most convenient way to travel between the two cities. The Eurostar train departs from St Pancras International Station in London and arrives at Gare du Nord in Paris. The journey takes approximately 2 hours and 15 minutes.\\n\\n2. **By Plane**: There are numerous flights between London and Paris every day. The flight duration is about 1 hour, but you need to add time for getting to and from the airports, security checks, and baggage claim. The major airports in London are Heathrow, Gatwick, Stansted, and Luton, and in Paris, they are Charles de Gaulle and Orly.\\n\\n3. **By Bus**: This is the cheapest but slowest option. Buses depart from Victoria Coach Station in London and arrive at Gallieni Porte de Bagnolet in Paris. The journey can take up to 8 hours, depending on traffic.\\n\\n4. **By Car**: If you prefer to drive, you can take a ferry or the Channel Tunnel (also known as the Chunnel) to cross the English Channel. The total journey time, including the ferry or Chunnel ride, is approximately 6-7 hours, depending on traffic and the exact locations of departure and arrival.\\n\\nRemember to check the travel restrictions and requirements due to COVID-19 before planning your trip.', additional_kwargs={}), raw={'id': '7e0eb350-573c-4a44-8d42-dfded6da9393', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='There are several ways to get from London to Paris:\\n\\n1. **By Eurostar Train**: This is the fastest and most convenient way to travel between the two cities. The Eurostar train departs from St Pancras International Station in London and arrives at Gare du Nord in Paris. The journey takes approximately 2 hours and 15 minutes.\\n\\n2. **By Plane**: There are numerous flights between London and Paris every day. The flight duration is about 1 hour, but you need to add time for getting to and from the airports, security checks, and baggage claim. The major airports in London are Heathrow, Gatwick, Stansted, and Luton, and in Paris, they are Charles de Gaulle and Orly.\\n\\n3. **By Bus**: This is the cheapest but slowest option. Buses depart from Victoria Coach Station in London and arrive at Gallieni Porte de Bagnolet in Paris. The journey can take up to 8 hours, depending on traffic.\\n\\n4. **By Car**: If you prefer to drive, you can take a ferry or the Channel Tunnel (also known as the Chunnel) to cross the English Channel. The total journey time, including the ferry or Chunnel ride, is approximately 6-7 hours, depending on traffic and the exact locations of departure and arrival.\\n\\nRemember to check the travel restrictions and requirements due to COVID-19 before planning your trip.', role='assistant', function_call=None, tool_calls=None))], 'created': None, 'model': None, 'object': None, 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=315, prompt_tokens=24, total_tokens=339)}, delta=None, logprobs=None, additional_kwargs={})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.chat(chat_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we receive a `ChatResponse` in response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Chat: (`achat`)\n",
    "\n",
    "We also have an async implementation of the `.chat()` method which can be called in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='There are several ways to get from London to Paris:\\n\\n1. **By Eurostar Train**: This is the fastest and most convenient way to travel between the two cities. The Eurostar train departs from St Pancras International Station in London and arrives at Gare du Nord in Paris. The journey takes approximately 2 hours and 15 minutes.\\n\\n2. **By Plane**: There are numerous flights between London and Paris every day. The flight duration is about 1 hour, but you need to add time for getting to and from the airports, security checks, and baggage claim. The major airports in London are Heathrow, Gatwick, Stansted, and Luton, and in Paris, they are Charles de Gaulle and Orly.\\n\\n3. **By Bus**: This is the cheapest but slowest option. Buses depart from Victoria Coach Station in London and arrive at Gallieni Porte de Bagnolet in Paris. The journey can take up to 8 hours, depending on traffic.\\n\\n4. **By Car**: If you prefer to drive, you can take a ferry or the Channel Tunnel (also known as the Chunnel) to cross the English Channel. The total journey time, including the ferry or Chunnel ride, is approximately 6-7 hours, depending on traffic and the exact locations of departure and arrival.\\n\\nRemember to check the travel restrictions and requirements due to COVID-19 before planning your trip.', additional_kwargs={}), raw={'id': '893d0ef6-4eae-410b-a417-2adca2a88e3a', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='There are several ways to get from London to Paris:\\n\\n1. **By Eurostar Train**: This is the fastest and most convenient way to travel between the two cities. The Eurostar train departs from St Pancras International Station in London and arrives at Gare du Nord in Paris. The journey takes approximately 2 hours and 15 minutes.\\n\\n2. **By Plane**: There are numerous flights between London and Paris every day. The flight duration is about 1 hour, but you need to add time for getting to and from the airports, security checks, and baggage claim. The major airports in London are Heathrow, Gatwick, Stansted, and Luton, and in Paris, they are Charles de Gaulle and Orly.\\n\\n3. **By Bus**: This is the cheapest but slowest option. Buses depart from Victoria Coach Station in London and arrive at Gallieni Porte de Bagnolet in Paris. The journey can take up to 8 hours, depending on traffic.\\n\\n4. **By Car**: If you prefer to drive, you can take a ferry or the Channel Tunnel (also known as the Chunnel) to cross the English Channel. The total journey time, including the ferry or Chunnel ride, is approximately 6-7 hours, depending on traffic and the exact locations of departure and arrival.\\n\\nRemember to check the travel restrictions and requirements due to COVID-19 before planning your trip.', role='assistant', function_call=None, tool_calls=None))], 'created': None, 'model': None, 'object': None, 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=315, prompt_tokens=24, total_tokens=339)}, delta=None, logprobs=None, additional_kwargs={})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat_llm.achat(chat_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream: `.stream_chat()`\n",
    "\n",
    "We can also use the models found on `build.nvidia.com` for streaming use-cases!\n",
    "\n",
    "Let's select another model and observe this behaviour. We'll use Google's `gemma-7b` model for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_llm = NvidiaAIPlayground(model=\"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call our model with `.stream_chat()`, which again expects a list of `ChatMessage` objects, and capture the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamed_response = stream_llm.stream_chat(chat_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object llm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat.<locals>.wrapped_gen at 0x7989c61a0260>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamed_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the response is a generator with the streamed response. \n",
    "\n",
    "Let's take a look at the final response once the generation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Sure, here's how you can get to Paris from London:\n",
      "\n",
      "**By Train:**\n",
      "\n",
      "* The most convenient way to travel between London and Paris is by train. There are several direct train routes available between the two cities, operated by Eurostar, National Express, and Thalys.\n",
      "* The journey takes approximately 2 hours and 15 minutes, and the cost varies depending on the time of travel and the operator you choose.\n",
      "* To book your train tickets, you can visit the official website of the train operator you choose.\n",
      "\n",
      "**By Ferry:**\n",
      "\n",
      "* You can also travel between London and Paris by ferry. There are several ferry companies that offer regular services between the two cities, including Brittany Ferries, DFDS, and Eurotunnel.\n",
      "* The journey takes approximately 2-3 hours, and the cost varies depending on the ferry company and the time of travel.\n",
      "* To book your ferry tickets, you can visit the official website of the ferry company you choose.\n",
      "\n",
      "**By Car:**\n",
      "\n",
      "* If you have your own car, you can drive from London to Paris. The journey takes approximately 2 hours and 30 minutes, and the cost of fuel and tolls will vary depending on your driving style and the route you choose.\n",
      "* To find directions, you can use a navigation app such as Google Maps or Waze.\n",
      "\n",
      "**Additional Tips:**\n",
      "\n",
      "* It is recommended to book your train or ferry tickets in advance, especially during peak travel season.\n",
      "* You can save money by purchasing a Eurail pass if you plan on traveling to multiple European cities.\n",
      "* If you are a student, you can get a student discount on train and ferry tickets.\n",
      "* To get to the city center of Paris from the train station, you can take a metro or taxi.\n",
      "\n",
      "Please let me know if you have any further questions about your trip to Paris.\n"
     ]
    }
   ],
   "source": [
    "last_element = None\n",
    "for last_element in streamed_response:\n",
    "    pass\n",
    "\n",
    "print(last_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Stream: `.astream_chat()`\n",
    "\n",
    "We have the equivalent async method for streaming as well, which can be used in a similar way to the sync implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamed_response = await stream_llm.astream_chat(chat_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<async_generator object llm_chat_callback.<locals>.wrap.<locals>.wrapped_async_llm_chat.<locals>.wrapped_gen at 0x7989c61a3cd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Sure, here's how you can get to Paris from London:\n",
      "\n",
      "**By Train:**\n",
      "\n",
      "* The most convenient way to travel between London and Paris is by train. There are several direct train routes available, operated by Eurostar, National Express, and Thalys. The journey takes around 2 hours and costs between 20-50.\n",
      "* To get to the train station, you can take a tube or taxi to London St Pancras International station.\n",
      "\n",
      "**By Ferry:**\n",
      "\n",
      "* You can also travel to Paris by ferry, which takes around 2 hours and costs between 20-40. Ferries depart from London's Tower Bridge and Canary Wharf.\n",
      "* To get to the ferry terminal, you can take a tube or taxi to the terminal.\n",
      "\n",
      "**By Car:**\n",
      "\n",
      "* If you prefer driving, you can take a road trip to Paris, which takes around 2 hours and costs between 20-40 for tolls and parking.\n",
      "* To get to Paris by car, you can take the M25 motorway.\n",
      "\n",
      "**Additional Tips:**\n",
      "\n",
      "* It is recommended to book your train tickets in advance, especially during peak season.\n",
      "* You can find the best travel options and prices on websites such as Eurostar, National Express, and Ferry.\n",
      "* To save money, consider traveling during the off-season or taking a budget airline.\n",
      "* Be sure to pack light, as you will need to navigate the city on foot.\n",
      "\n",
      "**Here are some additional resources that you may find helpful:**\n",
      "\n",
      "* [Eurostar](eurostar.com/)\n",
      "* [National Express](nationalexpress.com/)\n",
      "* [Thalys](thalys.com/)\n",
      "* [Ferries to Paris](ferrys.com/paris)\n",
      "\n",
      "I hope this information is helpful!\n"
     ]
    }
   ],
   "source": [
    "last_element = None\n",
    "async for last_element in streamed_response:\n",
    "    pass\n",
    "\n",
    "print(last_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Query Engine Responses\n",
    "\n",
    "Let's look at a slightly more involved example using a query engine!\n",
    "\n",
    "We'll start by loading some data (we'll be using the [Hitchhiker's Guide to the Galaxy](https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "Let's first create a directory where our data can live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/hhgttg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll download our data from the above source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-01 14:39:38--  https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt\n",
      "Resolving web.eecs.utk.edu (web.eecs.utk.edu)... 160.36.127.165\n",
      "Connecting to web.eecs.utk.edu (web.eecs.utk.edu)|160.36.127.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1534289 (1.5M) [text/plain]\n",
      "Saving to: data/hhgttg/hhgttg.txt\n",
      "\n",
      "data/hhgttg/hhgttg. 100%[===================>]   1.46M  6.75MB/s    in 0.2s    \n",
      "\n",
      "2024-04-01 14:39:39 (6.75 MB/s) - data/hhgttg/hhgttg.txt saved [1534289/1534289]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://web.eecs.utk.edu/~hqi/deeplearning/project/hhgttg.txt' -O 'data/hhgttg/hhgttg.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to have an embedding model for this step! We'll use OpenAI's `text-embedding-03-small` model to achieve this, and save it in our `Settings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "openai_embedding = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "Settings.embed_model = openai_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load our document and create an index leveraging the above created `OpenAIEmbedding()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data/hhgttg\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a simple query engine and set our `streaming` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_qe = index.as_query_engine(streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's send a query to our query engine, and then stream the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_response = streaming_qe.query(\n",
    "    \"What is the significance of the number 42?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The significance of the number 42 is a central theme in \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams. The book is a comedic science fiction satire that follows the adventures of two intergalactic travelers, Arthur Dent and Ford Prefect, as they try to escape the destruction of Earth and uncover the true meaning of the number 42.\n",
      "\n",
      "Throughout the book, the number 42 is presented as the ultimate answer to the ultimate question of life, the universe, and everything. The question itself is never explicitly stated, but it is implied to be a deeply profound and existential one that has been sought after by philosophers, scientists, and thinkers throughout history.\n",
      "\n",
      "The idea of the number 42 as the ultimate answer is a playful jab at the idea of seeking ultimate knowledge and understanding, which is often seen as an impossible task. The number 42 is also a reference to the famous \"42\" answer in the \"The Hitchhiker's Guide to the Galaxy\" by Douglas Adams, which is a comedic science fiction satire that follows the adventures of two intergalactic travelers, Arthur Dent and Ford Prefect, as they try to escape the destruction of Earth and uncover the true meaning of the number 42.\n",
      "\n",
      "In the book, the supercomputer Deep Thought is asked to find the answer to the ultimate question, and after billions of years of computation, it determines that the answer is 42. The answer is so profound that it causes Deep Thought to become obsolete, as it is no longer needed to answer questions.\n",
      "\n",
      "The significance of the number 42 in \"The Hitchhiker's Guide to the Galaxy\" is a commentary on the nature of knowledge and the quest for ultimate understanding. It is a reminder that there are limits to what can be known and that the pursuit of knowledge should be done with a sense of humor and a willingness to accept the unknown."
     ]
    }
   ],
   "source": [
    "streaming_response.print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvidia-llama-index-playground-connector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
