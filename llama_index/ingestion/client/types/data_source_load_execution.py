# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

import pydantic

from ..core.datetime_utils import serialize_datetime
from .data_source_load_execution_run_config_per_op_value import (
    DataSourceLoadExecutionRunConfigPerOpValue,
)
from .etl_job_names import EtlJobNames
from .status_enum import StatusEnum


class DataSourceLoadExecution(pydantic.BaseModel):
    """
    Schema for job that loads from a data source.
    """

    id: typing.Optional[str] = pydantic.Field(description="Unique identifier")
    created_at: typing.Optional[dt.datetime] = pydantic.Field(
        description="Creation datetime"
    )
    updated_at: typing.Optional[dt.datetime] = pydantic.Field(
        description="Update datetime"
    )
    job_name: EtlJobNames
    status: StatusEnum
    started_at: typing.Optional[dt.datetime]
    ended_at: typing.Optional[dt.datetime]
    run_config_per_op: typing.Dict[
        str, DataSourceLoadExecutionRunConfigPerOpValue
    ] = pydantic.Field(description="Run config that was given to the Dagster job")
    partitions: typing.Optional[typing.Dict[str, str]] = pydantic.Field(
        description="Partition information"
    )
    data_source_id: str = pydantic.Field(
        description="The ID for the DataSource this execution loaded documents from."
    )

    def json(self, **kwargs: typing.Any) -> str:
        kwargs_with_defaults: typing.Any = {
            "by_alias": True,
            "exclude_unset": True,
            **kwargs,
        }
        return super().json(**kwargs_with_defaults)

    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:
        kwargs_with_defaults: typing.Any = {
            "by_alias": True,
            "exclude_unset": True,
            **kwargs,
        }
        return super().dict(**kwargs_with_defaults)

    class Config:
        frozen = True
        smart_union = True
        json_encoders = {dt.datetime: serialize_datetime}
