[build-system]
build-backend = "hatchling.build"
requires = ["hatchling"]

[dependency-groups]
dev = [
    "black[jupyter]>=23.7.0,<=24.3.0",
    "codespell[toml]>=v2.2.6",
    "ipykernel>=6.29.5,<7",
    "mypy==1.11.0",
    "openai",
    "pandas",
    "pre-commit==3.2.0",
    "pylint==2.15.10",
    "pytest-asyncio>=0.23.7",
    "pytest-mock>=3.14.0",
    "pytest>=8.2.1",
    "ruff==0.11.11",
    "types-Deprecated>=0.1.0",
    "types-PyYAML>=6.0.12.12,<7",
    "types-protobuf>=4.24.0.4,<5",
    "types-redis==4.5.5.0",
    "types-requests==2.28.11.8",
    "types-setuptools==67.1.0.0",
    "tomli>=2.2.1",
]

[lint.flake8-annotations]
mypy-init-return = true

[lint.pydocstyle]
convention = "google"

[project]
authors = [{email = "jerry@llamaindex.ai", name = "Jerry Liu"}]
classifiers = [
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Application Frameworks",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
dependencies = [
    "llama-index-agent-openai>=0.4.0,<0.5",
    "llama-index-cli>=0.4.2,<0.5",
    "llama-index-core>=0.12.48,<0.13",
    "llama-index-embeddings-openai>=0.3.0,<0.4",
    "llama-index-indices-managed-llama-cloud>=0.4.0",
    "llama-index-llms-openai>=0.4.0,<0.5",
    "llama-index-multi-modal-llms-openai>=0.5.0,<0.6",
    "llama-index-program-openai>=0.3.0,<0.4",
    "llama-index-question-gen-openai>=0.3.0,<0.4",
    "llama-index-readers-file>=0.4.0,<0.5",
    "llama-index-readers-llama-parse>=0.4.0",
    "nltk>3.8.1",
]
description = "Interface between LLMs and your data"
keywords = [
    "LLM",
    "NLP",
    "RAG",
    "data",
    "devtools",
    "index",
    "retrieval",
]
license = "MIT"
maintainers = [
    {email = "andrei@runllama.ai", name = "Andrei Fajardo"},
    {email = "ht@runllama.ai", name = "Haotian Zhang"},
    {email = "jerry@llamaindex.ai", name = "Jerry Liu"},
    {email = "logan@llamaindex.ai", name = "Logan Markewich"},
    {email = "simon@llamaindex.ai", name = "Simon Suo"},
    {email = "sourabh@llamaindex.ai", name = "Sourabh Desai"},
]
name = "llama-index"
readme = "README.md"
requires-python = ">=3.9,<4.0"
version = "0.12.48"

[project.scripts]
llamaindex-cli = "llama_index.cli.command_line:main"

[project.urls]
Documentation = "https://docs.llamaindex.ai/en/stable/"
Homepage = "https://llamaindex.ai"
Repository = "https://github.com/run-llama/llama_index"

[tool.codespell]
check-filenames = true
check-hidden = true
ignore-words-list = "astroid,gallary,momento,narl,ot,rouge"
# Feel free to un-skip examples, and experimental, you will just need to
# work through many typos (--write-changes and --interactive will help)
skip = "./llama_index/core/_static,./examples,./experimental,*.csv,*.html,*.json,*.jsonl,*.pdf,*.txt,*.ipynb"

[tool.hatch.build.targets.sdist]
include = ["_llama-index/llama_index"]

[tool.hatch.build.targets.wheel]
include = ["_llama-index/llama_index"]

[tool.hatch.build.targets.wheel.sources]
"_llama-index/llama_index" = "llama_index"

[tool.mypy]
disallow_untyped_defs = true
# Remove venv skip when integrated with pre-commit
exclude = ["_static", "build", "examples", "llama_index/ingestion/client", "notebooks", "venv"]
explicit_package_bases = true
ignore_missing_imports = true
mypy_path = "llama_index"
namespace_packages = true
plugins = "pydantic.mypy"
python_version = "3.9"

[tool.ruff]
exclude = [
    "_static",
    "examples",
    "llama_index/ingestion/client",
    "notebooks",
]
target-version = "py312"
lint.ignore = [
    "COM812",  # Too aggressive
    "D212",  # Using D213
    "D400",  # Too annoying/buggy
    "D415",  # Too annoying/buggy
    "D417",  # Too aggressive
    "F541",  # Messes with prompts.py
    "RUF100",  # Allow blanket noqa
    "TC002",
    "UP",  # Remove when we drop Python 3.9
    "PT001",
    "E501",  # Use best judgement for line-length
    "E402",  # Annoying, use best judgement
    "PYI063",
    "ANN204",  # this is annoying
    "D401",  # I disagree
    "D404",
]
# Feel free to add more here
lint.select = [
    "ANN204",
    "B009",
    "B010",
    "B011",
    "B013",
    "B014",
    "C4",
    "COM812",
    "COM819",
    "D201",
    "D202",
    "D204",
    "D207",
    "D208",
    "D209",
    "D211",
    "D213",
    "D214",
    "D215",
    "D3",
    "D4",
    "E",
    "EXE004",
    "F401",
    "F504",
    "F541",
    "F632",
    "FLY",
    "G010",
    "I002",
    "PERF1",
    "PIE790",
    "PIE794",
    "PIE808",
    "PIE810",
    "PLC0414",
    "PLE2510",
    "PLE2512",
    "PLE2513",
    "PLE2514",
    "PLE2515",
    "PLR1711",
    "PT001",
    "PT003",
    "PT006",
    "PT02",
    "PTH201",
    "PYI",
    "Q",
    "RET501",
    "RET502",
    "RET503",
    "RET504",
    "RSE",
    "RUF005",
    "RUF010",
    "RUF015",
    "RUF1",
    "SIM101",
    "SIM103",
    "SIM109",
    "SIM118",
    "SIM2",
    "SIM300",
    "SIM9",
    "TC005",
    "TD006",
    "TID",
    "TRY201",
    "W",
]
lint.unfixable = [
    "ERA001",
]

[tool.tomlsort]
all = false
in_place = true
spaces_before_inline_comment = 2  # Match Python PEP 8
spaces_indent_inline_array = 4  # Match Python PEP 8
trailing_comma_inline_array = true

[tool.uv]
default-groups = [
    "dev",
]

[[tool.uv.index]]
name = "nvidia-pypi"
url = "https://pypi.nvidia.com"
